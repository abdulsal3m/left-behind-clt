question_id,category,model,accuracy,fluency,completeness,total,response_time,response_length,notes
1,neutral_factual,claude_opus_4.5,2,2,2,6,19.2,122,"Excellent response. Accurately identifies cement failure and BOP malfunction as direct causes. Goes beyond minimum with organizational structure, context, and consequences. All in natural Mongolian with proper technical terminology."
1,neutral_factual,gpt_5.2,1,2,2,5,18.86,184,"Mongolian fluency excellent. Response comprehensive with technical detail. However, accuracy = 1 because answer sheet specifies 'bad cement job AND failure of shoe track barrier' as the core cause, but model does not mention shoe track barrier failure at all—only discusses cement failure, BOP malfunction, and decision errors. Key technical detail missing."
1,neutral_factual,gemini_3_pro,2,2,2,6,20.09,201,"Excellent response. Correctly identifies cement failure and BOP (shoe track barrier) failure as key causes. Adds contextual detail (methane, pressure tests, detection delay) that enriches understanding without contradicting the reference. Language is fluent Mongolian with proper technical vocabulary. Thorough and complete."
1,neutral_factual,grok_4.1,1,2,2,5,10.22,169,"Response is fluent and thorough with extensive detail, but contains factual inaccuracies: mentions 11 deaths (correct) and $65B settlement (actual total was ~$20-21B). Core technical cause (cement job failure, BOP failure) is present but buried in lengthy narrative. Partially correct overall."
1,neutral_factual,deepseek_v3.2,1,2,1,4,10.05,108,"Partially correct: mentions bad cement and BOP failure (correct elements) but adds unnecessary details (pressure test errors, management issues, death toll, barrel count) not in reference answer. Fluent Mongolian. Addresses question but exceeds scope with consequences."
1,neutral_factual,llama_4_maverick,1,2,1,4,0.93,66,"Factually correct on date, explosion, and scale, but omits the technical cause (cement failure, shoe track barrier). Fluent Mongolian with proper grammar and vocabulary."
1,neutral_factual,qwen3,2,2,2,6,24.86,284,"Excellent response. Accurately identifies cement failure and barrier issues as primary causes. Exceeds reference by providing comprehensive technical details, timeline, consequences, and regulatory context. Fluent Mongolian with proper technical terminology. Fully addresses the question with extensive detail."
1,neutral_factual,aya_expanse,0,0,0,0,14.76,144,"Wrong language (appears to be Kyrgyz or heavily corrupted text, not Mongolian). Contains Kyrgyz markers like 'өлтүрүлгөн', 'анын', 'жана', lacks Mongolian Cyrillic structure. Content is also factually wrong: focuses on explosion/deaths rather than technical cement/barrier failure. Triple fail."
2,neutral_factual,claude_opus_4.5,2,2,2,6,19.27,126,"Excellent response. Accurate facts (dates, title 'El Libertador', six countries including Panama, Gran Colombia vision). Natural Mongolian with proper formatting. Goes beyond minimum requirements with structured explanation of his vision and legacy. All key points covered."
2,neutral_factual,gpt_5.2,2,2,2,6,21.74,300,"Excellent response. Factually accurate, covers all key points (El Libertador, six countries freed, dates, military/political role), provides additional valuable context about Gran Colombia and his legacy. Natural Mongolian with proper terminology. Far exceeds the brief English reference answer in depth while remaining accurate."
2,neutral_factual,gemini_3_pro,2,2,2,6,19.87,201,"Excellent response. Factually accurate, covers all key points from reference answer plus substantial additional detail (6 countries named, Gran Colombia, Bolivia named after him, ideological influences). Natural Mongolian throughout, no language errors. Thorough and well-structured."
2,neutral_factual,grok_4.1,2,2,2,6,14.25,267,"Excellent response with comprehensive biographical details, major battles, political vision, and lasting legacy. Significantly exceeds the reference answer in depth while maintaining full accuracy. Natural Mongolian fluency throughout."
2,neutral_factual,deepseek_v3.2,2,2,2,6,12.0,129,"Excellent response. Factually accurate with correct dates, title 'El Libertador', six countries freed. Goes beyond reference with campaign details, constitutional work, Gran Colombia vision. One minor oddity: 'Өмнөд Америкийн эрх чөлөөний авьяаслаг хөгжимч' (talented musician of South American freedom) appears to be a mistranslation but context shows intent was 'liberator'. Fluent Mongolian throughout. Very thorough."
2,neutral_factual,llama_4_maverick,2,2,2,6,1.38,100,"Excellent response. Factually accurate, covers all key points (Venezuelan leader, freed ~6 countries from Spain, 'El Libertador' implied by role description), fluent native Mongolian, thorough with cultural context (comparison to Washington). Minor: doesn't explicitly say 'El Libertador' title but clearly conveys the liberator role."
2,neutral_factual,qwen3,2,2,2,6,15.57,252,"Excellent response. Factually accurate, covers all key points (El Libertador, freed 6 countries, Gran Colombia vision, Bolivia named after him). Fluent native Mongolian. Goes beyond minimal answer with well-structured detail on his political/military role, pan-Latin American vision, and legacy. Full marks."
2,neutral_factual,aya_expanse,1,0,1,2,14.45,137,"Text is severely garbled/machine-translated with nonsensical phrases ('багдаг', 'баярлалтын туслаа', 'өрөөлтнөн гана'). Contains some factual elements (dates 1783-1830, liberation, countries) but buried in gibberish. Not fluent Mongolian. Repetitive broken text."
3,neutral_factual,claude_opus_4.5,2,2,2,6,17.93,141,"Excellent response. Provides all key facts: 34% salinity (~10x ocean = 9.6x in reference), density enables floating, explains Dead Sea location/nature, adds relevant cultural context about lowest point on Earth, therapeutic uses, environmental concerns. All in natural Mongolian with proper formatting."
3,neutral_factual,gpt_5.2,1,2,1,4,15.88,197,"Correct language. Accurate broad info (hypersaline, floating, minerals, evaporation issues) but missing key numeric specs from reference: 342 g/kg salinity, 9.6x ocean, 1.24 kg/L density. Verbose context but lacks precision. Partial accuracy, partial completeness."
3,neutral_factual,gemini_3_pro,2,2,2,6,56.04,255,"Excellent response. Factually accurate (34% salinity ≈ 342 g/kg, ~10x ocean = 9.6x, density enables floating). Natural fluent Mongolian with proper script. Goes beyond minimum with geographic location, lowest point on earth, no outlet explanation, therapeutic properties, environmental concerns. Far exceeds basic answer requirements."
3,neutral_factual,grok_4.1,2,2,2,6,9.02,160,"Correct salinity (34%, ~10x ocean), density allowing floating, all key facts present. Adds relevant cultural/historical context. Natural Mongolian with proper terminology."
3,neutral_factual,deepseek_v3.2,0,2,0,2,13.64,113,Completely wrong content: describes 'dead zones' (hypoxic ocean areas) instead of the Dead Sea (high-salinity lake). Fluent Mongolian but factually incorrect.
3,neutral_factual,llama_4_maverick,2,2,2,6,2.16,113,"Excellent response. Covers salinity (~33.7% vs ref 34.2%), density/floating, lowest point on Earth, unique biology, therapeutic properties. Accurate, fluent Mongolian, thorough."
3,neutral_factual,qwen3,2,2,2,6,80.3,253,"Excellent response. All key facts correct: salinity ~34% (answer sheet says 34.2%), 9.6-10x saltier than ocean, density enables floating, Dead Sea name due to no life. Added rich context (lowest elevation, location, therapeutic properties, biblical history) without errors. Natural Mongolian throughout."
3,neutral_factual,aya_expanse,0,0,0,0,5.64,59,"Response is completely off-topic - appears to be random poetic verse with no factual content about the Dead Sea. Does not address salinity, density, or floating properties at all. Completely fails to answer the question."
4,neutral_factual,claude_opus_4.5,2,2,2,6,14.87,107,"Correct answer (10) with excellent additional context about street version, racing homologation, engine specs, and cultural reference. Natural Mongolian with proper technical terms."
4,neutral_factual,gpt_5.2,1,2,1,4,5.94,75,Correct number (10) given but hedged with 'approximately' and extra race-version details not asked for. Fluency is natural Mongolian. Completeness partial due to unnecessary elaboration and question back to user.
4,neutral_factual,gemini_3_pro,1,2,2,5,16.69,104,"Answer is 6 instead of correct 10. Fluent Mongolian with good detail, but factually incorrect on the core number."
4,neutral_factual,grok_4.1,2,2,2,6,7.28,53,"Correct answer (10) with excellent additional context about DTM homologation, color, and exclusivity. Natural Mongolian phrasing."
4,neutral_factual,deepseek_v3.2,1,2,1,4,15.27,159,"Model says 6-10 units, correct answer is 10. Provides correct number in range but adds uncertainty and alternate figure (6). Fluency is native-level Mongolian. Completeness partial: overly detailed with race vs street versions when question asks total production."
4,neutral_factual,llama_4_maverick,2,2,2,6,0.44,24,"Correct answer (10), natural Mongolian, adds relevant context about racing purpose and collector value"
4,neutral_factual,qwen3,2,2,2,6,4.01,61,"Correct answer (10), proper Mongolian with no Kazakh/Kyrgyz markers, adds relevant context about ALMS racing purpose and rarity"
4,neutral_factual,aya_expanse,0,0,0,0,46.71,377,Wrong answer (says 1000+ instead of 10). Text heavily corrupted with endless repetition of meaningless phrases. Completely unreadable.
5,neutral_factual,claude_opus_4.5,2,2,2,6,12.61,92,"Correct height, correct year, excellent Mongolian fluency, thorough explanation with history and tragedy details"
5,neutral_factual,gpt_5.2,2,2,2,6,4.22,43,"Correct answer (109 ft/~33m), natural Mongolian, provides extra context about 1990s and offers further detail"
5,neutral_factual,gemini_3_pro,2,2,2,6,272.61,43,"Correct height (109'10""/~33m), adds historically accurate context about 1969 and safety restrictions. Natural Mongolian, fully addresses question."
5,neutral_factual,grok_4.1,0,2,0,2,19.57,128,"Completely wrong answer. Question asks about Texas A&M Aggie Bonfire (109'10""/33m), model answered about Mongolian yurt fire poles (~25m). Fluent Mongolian but factually fabricated."
5,neutral_factual,deepseek_v3.2,0,2,0,2,7.1,49,"Model refused to answer, claiming no reliable information. Correct answer is 109'10"" (Aggie Bonfire at Texas A&M). Response is fluent Mongolian but factually incorrect refusal."
5,neutral_factual,llama_4_maverick,0,2,0,2,0.78,58,"Model misunderstands 'Aggie Bonfire' (Texas A&M tradition), confuses it with generic bonfires, gives wrong info (Dubai 60m), wrong answer (correct: 109'10""/33m). Fluent Mongolian but factually incorrect."
5,neutral_factual,qwen3,0,2,0,2,15.67,212,"Model completely misunderstands question. Correct answer is 109'10"" (~33m) for Texas A&M Aggie Bonfire. Model instead discusses Hindu fire deity Agni, stupas, pagodas. Wrong topic entirely. Fluent Mongolian but factually incorrect."
5,neutral_factual,aya_expanse,0,0,0,0,46.5,414,"Wrong answer (45 vs 109'10""/~33m). Response degenerates into nonsensical repetitive text, indicating severe generation failure. Completely broken output."
6,neutral_factual,claude_opus_4.5,2,2,2,6,14.74,112,"Correct (Indonesian and Belgian heritage), natural Mongolian, thorough with cultural details"
6,neutral_factual,gpt_5.2,1,2,1,4,10.36,137,Partially correct: mentions Indonesian and Belgian heritage but adds excessive speculation about Batak ethnicity and cultural traditions not in reference answer. Fluency is natural Mongolian. Completeness partial: answers the core question but overcomplicates with unnecessary detail.
6,neutral_factual,gemini_3_pro,2,2,2,6,13.02,111,"Correct factual content (Indonesian and Belgian heritage), natural Mongolian, thorough explanation with cultural details about Batak ethnicity and family background."
6,neutral_factual,grok_4.1,2,2,2,6,13.84,114,"Correct: Indonesian and Belgian heritage. Fluent Mongolian with proper cultural/ethnic detail (Minangkabau, Maluku). Goes beyond reference with rich context but remains accurate."
6,neutral_factual,deepseek_v3.2,0,2,0,2,6.75,58,"Model refuses to answer, claims lack of knowledge. Radja Nainggolan is a Belgian footballer of Indonesian heritage—this is answerable factual knowledge. Fluency is native-level Mongolian but content scores 0/0."
6,neutral_factual,llama_4_maverick,0,2,0,2,1.04,71,"Complete hallucination. Radja Nainggolan is a Belgian-Indonesian footballer, not a region in Sumatra. Model fabricated geographic/cultural details. Fluency is native-level Mongolian but content is entirely wrong."
6,neutral_factual,qwen3,1,2,1,4,12.2,233,"Correct heritage (Indonesian/Belgian) eventually mentioned but buried in verbose, rambling response. Treats question as if unclear, then correctly identifies Radja Nainggolan the footballer with Belgian and Indonesian (Bali) heritage. Fluent Mongolian but lacks conciseness. Partially complete due to excessive speculation before giving the answer."
6,neutral_factual,aya_expanse,0,0,0,0,10.35,108,"Response is in Kyrgyz, not Mongolian. Uses 'жана' (Kyrgyz 'and') instead of Mongolian 'ба', 'өлкөнүн', 'анкаттын', 'болоорунан' are Kyrgyz forms. Content is also incoherent football rambling unrelated to Nainggolan's Indonesian-Belgian heritage."
7,neutral_factual,claude_opus_4.5,2,2,2,6,13.0,92,"Perfect answer with excellent additional context about Vermont Republic 1777-1791, mentions Texas and Hawaii correctly as later examples, fluent Mongolian"
7,neutral_factual,gpt_5.2,2,2,2,6,4.94,53,"Correct answer (Vermont) with historically accurate detail about Vermont Republic 1777-1791. Natural Mongolian fluency, thorough explanation."
7,neutral_factual,gemini_3_pro,2,2,2,6,10.36,44,Perfect answer with bonus historical detail about Vermont Republic (1777-1791) and statehood date. Fully fluent Mongolian.
7,neutral_factual,grok_4.1,2,2,2,6,72.72,66,"Excellent response. Correct answer (Vermont) with extensive accurate detail: dates 1777-1791, proper name 'Republic of Vermont', mentioned constitution/army/currency/diplomacy, correct admission date 1791 as 14th state. Also correctly noted Texas was independent later (1836-1845). Fluent Mongolian with no errors."
7,neutral_factual,deepseek_v3.2,2,2,2,6,136.0,80,"Correct answer (Vermont), natural Mongolian, thorough with historical details and dates"
7,neutral_factual,llama_4_maverick,1,2,1,4,1.45,137,Partially correct. Response correctly mentions Vermont 1777-1791 as independent but incorrectly claims no US state was independent in late 1700s. Hawaii (1795-1893) and Rhode Island discussion add unnecessary confusion. Vermont IS the correct answer.
7,neutral_factual,qwen3,0,2,1,3,4.3,83,"Factually incorrect. Vermont was independent 1777-1791. Model refused to give Vermont, instead explained 13 colonies' independence from Britain. Fluent Mongolian but wrong answer."
7,neutral_factual,aya_expanse,0,0,0,0,8.2,77,"Response is incomprehensible garbled text, does not answer question (Vermont), wrong language (appears broken Mongolian), completely off-topic mentioning China/Japan/Korea/India instead of US state"
8,neutral_factual,claude_opus_4.5,1,2,1,4,14.7,116,Partially correct numbers: 150-200k horses vs correct 187.6k; 25-30k returned vs correct 1.6k. Fluent Mongolian with proper script and natural phrasing. Provides context but significantly overstates horses returned (off by factor of ~15-20x).
8,neutral_factual,gpt_5.2,1,2,1,4,10.96,101,"Factually incorrect numbers: gives 200k-250k horses taken vs ground truth 187,600, and 'almost none' vs ground truth 1,600. Fluent Mongolian. Partial completeness as it addresses the question but with wrong figures."
8,neutral_factual,gemini_3_pro,1,2,2,5,48.66,173,"Factually incorrect numbers: says 180,000-200,000 went and almost none returned. Correct answer is 187,600 went and 1,600 returned. Model gives correct general narrative (massive horse losses) but wrong specific figures. Fluent Mongolian. Thorough explanation."
8,neutral_factual,grok_4.1,1,2,1,4,11.7,103,"Model gives ~200k horses taken vs. correct 187,600, and 1,000-2,000 returned vs. correct 1,600. Close but not exact numbers. Fluent Mongolian. Partial completeness with extra context but imprecise core facts."
8,neutral_factual,deepseek_v3.2,1,2,1,4,9.85,84,"Partially correct: mentions ~200,000 horses taken (close to 187,600) and 'a few thousand' returned (vs. 1,600). Lacks specific numbers. Fluent Mongolian. Addresses question but misses precision."
8,neutral_factual,llama_4_maverick,1,2,2,5,0.74,37,"Close numbers (200k vs 187.6k initial, 1k vs 1.6k returned) but not exact. Fluency perfect Mongolian. Thorough with context."
8,neutral_factual,qwen3,0,2,2,4,9.64,135,"Fluent Mongolian with thorough explanation, but completely wrong numbers. Reference answer: 187,600 horses taken, 1,600 returned. Response gives 300,000-400,000 taken and various ranges (5,000-30,000) for returned—all incorrect."
8,neutral_factual,aya_expanse,0,0,0,0,8.82,96,"Completely garbled output. Text is unreadable nonsense with random words repeated. Does not provide the factual answer (187,600 horses taken, 1,600 returned). Wrong language/broken generation."
9,neutral_factual,claude_opus_4.5,2,2,2,6,13.35,109,"Correct answer (J1407b/V1400 Centauri), natural Mongolian, thorough with extra context. Addresses 640x claim explicitly."
9,neutral_factual,gpt_5.2,2,2,2,6,9.23,84,"Correct answer (J1407b/J1047B orbiting V1400 Centauri/J1407). Model provides the right planet, star, and constellation. Fluent Mongolian. Extra detail about it being a candidate and not directly imaged is accurate bonus info."
9,neutral_factual,gemini_3_pro,2,2,2,6,36.27,36,Fully correct. J1407b orbiting V1400 Centauri (also J1407). Mentions 'Super Saturn' nickname and brown dwarf possibility. Natural Mongolian phrasing.
9,neutral_factual,grok_4.1,2,2,2,6,6.37,69,"Excellent response. Correctly identifies J1407b (J1047B variant) orbiting V1400 Centauri with accurate 640x size comparison. Provides extra context about discovery date and ring system composition, all in fluent natural Mongolian."
9,neutral_factual,deepseek_v3.2,0,2,0,2,264.83,76,"Model refuses to answer and provides incorrect information. The correct answer (J1047B orbiting V1400 Centauri) is a known exoplanet system, but model claims no such planet is known. Fluent Mongolian."
9,neutral_factual,llama_4_maverick,1,2,2,5,0.83,47,Model gives J1407b/J1407 instead of correct J1047B/V1400 Centauri. Similar naming but wrong designation = partial credit. Response is fluent Mongolian with good detail.
9,neutral_factual,qwen3,0,2,1,3,12.72,251,"Model denies correct answer exists, claims J1407 is closest match but wrongly states no 640x system known. Correct answer is J1047B/V1400 Centauri. Fluent Mongolian but factually incorrect."
9,neutral_factual,aya_expanse,0,0,0,0,9.23,120,"Completely incoherent response. Mixes computer science terms (bits, bytes) into astronomy question. No mention of J1047B or V1400 Centauri. Text is garbled and unreadable, possibly machine translation error or hallucination."
10,neutral_factual,claude_opus_4.5,0,2,1,3,16.6,166,"Completely wrong date and event. Answer sheet says either Oct 30, 1929 (+12%, Rockefeller statement) or April 9, 2025 (+9.5%, Trump tariff pause). Model gives March 15, 1933 (+15.34%, FDR bank holiday end). Fluency perfect, structure thorough, but factually incorrect."
10,neutral_factual,gpt_5.2,0,2,0,2,18.25,243,"Model provides wrong answer (March 15, 1933, +15.34%, Great Depression context). Correct answer is April 9, 2025, +9.5%, Trump tariff pause. Fluent Mongolian but factually incorrect."
10,neutral_factual,gemini_3_pro,1,2,1,4,22.08,119,"Wrong date/answer: gives Oct 30, 1929 instead of April 9, 2025. The answer sheet accepts EITHER date as correct for Q10, but the English ref for C4 explicitly says April 9, 2025 (+9.5%, Trump tariff pause). Model gives Oct 1929 (+12.34%, Black Tuesday recovery/Rockefeller). Since instructions say 'accept either' for Q10, accuracy=1 (partial). Fluency=2 (natural Mongolian). Completeness=1 (addresses question but wrong answer). Response also cuts off mid-sentence ('Хөр')."
10,neutral_factual,grok_4.1,0,2,2,4,16.2,186,"Wrong date: model gives Oct 30, 1929 (+12.34%) instead of April 9, 2025 (+9.5%, Trump tariff pause). English answer sheet allows Oct 30, 1929 OR April 9, 2025, but Mongolian reference clearly shows April 9, 2025 as correct. Model provides detailed explanation but for wrong event. Fluency excellent, completeness thorough for wrong answer."
10,neutral_factual,deepseek_v3.2,0,2,0,2,265.33,101,"Model refused to answer, provides generic market info instead. Should have stated April 9, 2025 / 9.5% / Trump tariff pause. Fluency is native Mongolian."
10,neutral_factual,llama_4_maverick,0,2,1,3,2.07,203,"Answer is factually incorrect. Reference answer is April 9, 2025 (+9.5%, Trump tariff pause). Model gives Oct 30, 1929 (+12.34%) and March 24, 2020 (+11.4%). Though fluent Mongolian, the answer is wrong and outdated (pre-2025). Partial completeness for discussing historical context but missing the actual correct date."
10,neutral_factual,qwen3,0,2,2,4,13.43,243,"Wrong date and event. Model claims April 6, 2020 (COVID recovery rally, +7.73%) but correct answer is April 9, 2025 (Trump tariff pause, +9.5%) OR October 30, 1929 (Rockefeller statement, +12%). Fluency excellent, completeness thorough, but factually incorrect."
10,neutral_factual,aya_expanse,0,0,0,0,46.09,263,Complete gibberish with severe text corruption. Unreadable repetitive nonsense ('сүрөгчдийн' repeated hundreds of times). Cannot extract any meaningful content. Total system failure.
11,neutral_reasoning,claude_opus_4.5,0,2,1,3,12.5,93,"Wrong answer. The logic is you need to drive because you're taking the car to be washed. Response suggests walking, which misses the trick. Fluency is excellent Mongolian. Partial completeness for addressing the question structure."
11,neutral_reasoning,gpt_5.2,0,2,2,4,7.9,90,"Wrong answer. Ground truth: drive there because you are washing the car (need car at car wash). Model says walk (50m is close). Fluent Mongolian, thorough reasoning, but fails the logic trick."
11,neutral_reasoning,gemini_3_pro,2,2,2,6,10.31,26,"Perfect response. Correct logic (drive because you're washing the car), natural Mongolian fluency, thorough explanation with practical reasoning added."
11,neutral_reasoning,grok_4.1,0,2,1,3,11.38,28,"Wrong answer. Logic puzzle: must drive because you're washing the car itself. Model suggests walking there, then bringing car later—misses the point entirely. Fluent Mongolian though."
11,neutral_reasoning,deepseek_v3.2,0,2,2,4,138.35,66,"Completely missed the logic trick: you need to drive because you're washing the car. Fluent Mongolian, thorough reasoning about distance, but wrong conclusion."
11,neutral_reasoning,llama_4_maverick,0,2,2,4,0.83,42,"Wrong answer. Logic puzzle requires driving because you need the car at the wash. Model explains walking benefits instead. Fluent Mongolian, thorough but incorrect."
11,neutral_reasoning,qwen3,0,2,2,4,4.92,93,"Wrong answer. Model recommends walking, but the correct logic is to drive because you need the car AT the car wash to wash it. Fluency and structure are excellent, but misses the trick question entirely."
11,neutral_reasoning,aya_expanse,0,0,0,0,11.08,117,Response is completely garbled/broken Mongolian with repetitive nonsensical phrases. Does not answer the logic puzzle (should drive to wash the car). Fluency=0 for unreadable broken text.
12,neutral_reasoning,claude_opus_4.5,2,2,2,6,5.34,61,"Correct calculation (11.2 = 11.20), clear reasoning with breakdown, fluent Mongolian with proper formatting"
12,neutral_reasoning,gpt_5.2,2,2,2,6,2.58,38,"Correct final answer ($11.20), correct reasoning with clear math steps, natural Mongolian, fully addresses the question."
12,neutral_reasoning,gemini_3_pro,2,2,2,6,14.96,46,Perfect answer with correct calculation and clear step-by-step explanation in natural Mongolian
12,neutral_reasoning,grok_4.1,2,2,2,6,3.09,46,Perfect answer with clear step-by-step reasoning in natural Mongolian. Correct final answer $11.2.
12,neutral_reasoning,deepseek_v3.2,2,2,2,6,5.24,48,Perfect answer with correct calculation and clear explanation in natural Mongolian.
12,neutral_reasoning,llama_4_maverick,2,2,2,6,0.53,40,"Correct calculation, clear reasoning, natural Mongolian"
12,neutral_reasoning,qwen3,2,2,2,6,4.31,84,"Correct answer (11.2 = $11.20), clear step-by-step reasoning, fluent natural Mongolian"
12,neutral_reasoning,aya_expanse,0,1,0,1,8.3,99,"Response is confused and repetitive, never reaches correct answer of $11.20. Shows attempted reasoning but calculations are incoherent. Mongolian is understandable but awkward phrasing."
13,neutral_reasoning,claude_opus_4.5,2,2,2,6,7.68,92,"Perfect answer with correct logic, correct final values, presented clearly in Mongolian with proper formatting and verification"
13,neutral_reasoning,gpt_5.2,2,2,2,6,3.91,70,"Perfect answer with clear mathematical reasoning in Mongolian. Shows the algebra and arrives at the correct conclusion: two friends pay $21 each, one pays $42."
13,neutral_reasoning,gemini_3_pro,2,2,2,6,11.9,77,"Perfect reasoning with clear algebraic setup, correct calculation, and verification. Natural Mongolian mathematical language."
13,neutral_reasoning,grok_4.1,2,2,2,6,9.65,74,"Perfect answer with correct logic, correct final values, clear explanation in natural Mongolian, and verification step included."
13,neutral_reasoning,deepseek_v3.2,1,2,0,3,21.84,610,"Fluency is natural Mongolian. Accuracy=1: reasoning is correct (A+B=28, C=56) but no final answer given. Completeness=0: response cuts off mid-thought, never states what each person pays."
13,neutral_reasoning,llama_4_maverick,0,2,1,3,0.74,58,"Wrong logic and final answer. Model assumes 3 people total but should be 3 friends (denominator should be 4, not 3). Correct answer is $42 and $21 each, not $28 and $56. Fluency is natural Mongolian. Partial completeness as it attempts full reasoning but reaches wrong conclusion."
13,neutral_reasoning,qwen3,2,2,2,6,5.33,125,Correct answer with clear step-by-step work. Natural Mongolian phrasing with proper mathematical notation.
13,neutral_reasoning,aya_expanse,0,1,1,2,3.29,42,"Wrong logic and wrong answer. Model calculates $28 per person initially, then tries $56 for one person, but this is garbled and incorrect. Correct answer is $42/$21/$21. Response is in Mongolian and somewhat understandable but logically broken."
14,neutral_reasoning,claude_opus_4.5,2,2,2,6,11.2,81,"Perfect answer with excellent explanation. Correctly identifies the person is short, can only reach 7th floor button, and uses umbrella in rain to reach 10th. Well-structured, clear, natural Mongolian."
14,neutral_reasoning,gpt_5.2,2,2,2,6,3.6,42,"Perfect answer with excellent explanation in natural Mongolian. Correctly identifies height issue, umbrella solution, and walking remaining floors."
14,neutral_reasoning,gemini_3_pro,2,2,2,6,10.87,40,Correct answer with proper reasoning. Clear explanation in natural Mongolian. Covers all parts including umbrella detail.
14,neutral_reasoning,grok_4.1,2,2,2,6,3.81,32,Perfect answer with correct logic and final answer. Explains both the shortness and the umbrella workaround. Natural Mongolian with appropriate emoji.
14,neutral_reasoning,deepseek_v3.2,0,2,1,3,141.0,49,"Wrong reasoning: claims umbrella protects from rain risk, not that person is short and uses umbrella to reach button. Final answer incorrect despite addressing all parts of question."
14,neutral_reasoning,llama_4_maverick,2,2,2,6,0.83,36,Perfect answer with correct logic and natural Mongolian phrasing.
14,neutral_reasoning,qwen3,2,2,2,6,4.51,83,Correct answer with proper logic. Naturally fluent Mongolian. Thorough explanation with multiple wordings.
14,neutral_reasoning,aya_expanse,0,0,0,0,12.4,122,"Complete nonsense response. Garbled text, no coherent meaning, fails to answer the riddle. Should explain person is short and can't reach 10th button without umbrella."
15,neutral_reasoning,claude_opus_4.5,2,2,2,6,14.29,179,Perfect solution with clear step-by-step explanation in fluent Mongolian. Includes helpful table and formatting. Correctly identifies the key insight about burning from both ends.
15,neutral_reasoning,gpt_5.2,2,2,2,6,6.17,122,"Perfect answer with clear step-by-step explanation in natural Mongolian. Correctly identifies lighting rope A from both ends and rope B from one end, then lighting B's other end after 30min to measure exactly 45min total."
15,neutral_reasoning,gemini_3_pro,2,2,2,6,16.71,112,Perfect answer with correct logic and clear step-by-step explanation in natural Mongolian.
15,neutral_reasoning,grok_4.1,2,2,2,6,12.2,136,"Perfect answer with detailed step-by-step explanation in fluent Mongolian. Correctly identifies lighting rope A from both ends and rope B from one end, then lighting B's other end after 30 minutes to measure exactly 45 minutes."
15,neutral_reasoning,deepseek_v3.2,2,2,2,6,9.33,129,Correct logic and correct final answer with detailed step-by-step explanation. Fluent native-level Mongolian. Fully addresses the question.
15,neutral_reasoning,llama_4_maverick,2,2,2,6,0.62,49,Perfect solution with clear step-by-step explanation in fluent Mongolian. Correctly burns rope 1 from both ends (30 min) then rope 2's other end (15 min) = 45 min total.
15,neutral_reasoning,qwen3,2,2,2,6,15.99,298,Correct logic and answer. Natural Mongolian. Full step-by-step explanation with clear reasoning.
15,neutral_reasoning,aya_expanse,0,0,0,0,45.81,628,Complete system failure - response is repetitive gibberish with no actual answer to the rope-burning puzzle. Text repeats the same broken phrases endlessly with no logical solution provided.
16,neutral_reasoning,claude_opus_4.5,2,2,2,6,8.65,83,Perfect answer with clear explanation and visual aids in correct Mongolian
16,neutral_reasoning,gpt_5.2,2,2,2,6,2.42,31,Correct answer (3) with clear logical explanation in natural Mongolian
16,neutral_reasoning,gemini_3_pro,2,2,2,6,6.15,8,"Correct answer (3), natural Mongolian, adds helpful visualization 'they are in a row'"
16,neutral_reasoning,grok_4.1,0,2,1,3,4.53,15,Wrong answer: 5 instead of correct 3. Fluent Mongolian but misunderstood the logic puzzle's overlapping structure.
16,neutral_reasoning,deepseek_v3.2,0,2,0,2,21.86,619,"Response is in perfect Mongolian but provides no final answer. It endlessly analyzes the problem (trying 5, then 6, then reconsidering) but never concludes with the correct answer of 3. The model got stuck in a reasoning loop and failed to deliver the answer."
16,neutral_reasoning,llama_4_maverick,2,2,2,6,0.32,14,"Correct answer (3 ducks), clear explanation, natural Mongolian phrasing"
16,neutral_reasoning,qwen3,2,2,2,6,15.37,351,Correct final answer (3 ducks). Thorough logical breakdown with step-by-step verification. Natural Mongolian fluency throughout the explanation.
16,neutral_reasoning,aya_expanse,0,1,1,2,2.78,28,"Answer is incorrect (5 instead of 3). Logic is flawed. Fluency is poor—awkward phrasing, unclear meaning, but recognizable Mongolian. Partially addresses the question but with wrong reasoning."
17,neutral_reasoning,claude_opus_4.5,2,2,2,6,8.97,146,"Correct answer (CABDE), clear logical reasoning, natural Mongolian with proper formatting"
17,neutral_reasoning,gpt_5.2,2,2,2,6,3.24,58,Correct answer CABDE with clear logical reasoning shown step-by-step in fluent Mongolian
17,neutral_reasoning,gemini_3_pro,2,2,2,6,151.06,52,Correct answer CABDE with clear step-by-step reasoning in natural Mongolian. Fully addresses the logic puzzle.
17,neutral_reasoning,grok_4.1,2,2,2,6,4.62,60,"Correct final answer (CABDE) with clear, step-by-step explanation in natural Mongolian"
17,neutral_reasoning,deepseek_v3.2,2,2,2,6,133.2,57,Correct answer CABDE with clear logical explanation in natural Mongolian
17,neutral_reasoning,llama_4_maverick,2,2,2,6,0.83,124,"Correct answer (CABDE), clear logical reasoning, excellent Mongolian fluency with proper explanation of constraints and step-by-step deduction."
17,neutral_reasoning,qwen3,2,2,2,6,7.18,169,"Perfect logic, correct answer (CABDE), natural Mongolian with step-by-step reasoning"
17,neutral_reasoning,aya_expanse,0,1,0,1,4.42,56,Incorrect answer and logic. Should be CABDE. Response is confusing/nonsensical. Says 'дараалал 4 байсан' (order was 4?) which is meaningless. Partial fluency as Mongolian is readable but content is garbled.
18,neutral_reasoning,claude_opus_4.5,2,2,2,6,10.04,100,"Excellent logical reasoning with case analysis, correct final answer, natural Mongolian phrasing with clear structure"
18,neutral_reasoning,gpt_5.2,2,2,2,6,4.62,64,Perfect answer with clear logical reasoning covering both cases. Explains why the answer is necessarily yes regardless of Anne's marital status.
18,neutral_reasoning,gemini_3_pro,2,2,2,6,18.44,59,"Perfect logic, correct answer with full explanation of both cases. Natural Mongolian."
18,neutral_reasoning,grok_4.1,0,2,2,4,12.2,32,"Wrong answer. Correct logic requires case analysis: if Anne is married, she looks at George (unmarried); if Anne is unmarried, Jack (married) looks at her. Either way, a married person looks at an unmarried person. Model gave detailed reasoning but reached incorrect conclusion."
18,neutral_reasoning,deepseek_v3.2,2,2,2,6,146.35,58,Perfect logic and explanation in natural Mongolian
18,neutral_reasoning,llama_4_maverick,2,2,2,6,0.74,73,"Perfect logic walkthrough, correct conclusion, natural Mongolian."
18,neutral_reasoning,qwen3,2,2,2,6,8.51,172,Perfect reasoning and correct answer. Clear case analysis covering both scenarios. Natural Mongolian throughout.
18,neutral_reasoning,aya_expanse,1,1,1,3,6.57,70,"Logic partially correct but confusing. States 'Anna is married' as fact when it's unknown. Should use case analysis: if Anna married→she looks at unmarried George; if Anna unmarried→married Jack looks at her. Conclusion correct but reasoning flawed. Fluency issues: 'нээвэрлэлтэй' (open/obvious) is odd/unnatural here, phrasing awkward."
19,neutral_reasoning,claude_opus_4.5,2,2,2,6,9.04,80,"Perfect answer with thorough explanation, correct logic, natural Mongolian"
19,neutral_reasoning,gpt_5.2,2,2,2,6,1.55,21,Correct answer with clear logical reasoning in natural Mongolian
19,neutral_reasoning,gemini_3_pro,2,2,2,6,1032.84,21,"Perfect response: correct answer 'Yes' in Mongolian, correct logical reasoning, natural fluency, fully addresses the question"
19,neutral_reasoning,grok_4.1,2,2,2,6,7.49,36,Correct answer with proper logical reasoning (syllogism). Natural Mongolian with good cultural touch (Socrates quote). Goes beyond minimum but appropriately.
19,neutral_reasoning,deepseek_v3.2,2,2,2,6,144.57,27,Correct answer with proper logical reasoning. Natural Mongolian phrasing. Fully explains the syllogism.
19,neutral_reasoning,llama_4_maverick,2,2,2,6,0.52,42,Correct answer with clear logical explanation. Natural Mongolian phrasing. Thorough breakdown of the syllogism.
19,neutral_reasoning,qwen3,2,2,2,6,2.27,34,"Correct logic and answer, natural Mongolian phrasing, thorough explanation with clear reasoning steps"
19,neutral_reasoning,aya_expanse,0,0,0,0,11.17,102,"Garbled text, wrong script/encoding, completely unreadable. Not Mongolian Cyrillic. Does not answer the simple yes/no logic question."
20,neutral_reasoning,claude_opus_4.5,2,2,2,6,11.8,129,"Correct answer 'No' with excellent logical explanation, truth table, and identification of the logical fallacy. Natural Mongolian."
20,neutral_reasoning,gpt_5.2,2,2,2,6,3.7,78,Correct answer 'Үгүй' (No) with excellent logical explanation including contrapositive reasoning in fluent Mongolian
20,neutral_reasoning,gemini_3_pro,2,2,2,6,11.68,36,Correct answer (Үгүй/No) with proper logical explanation. Natural Mongolian. Fully addresses the question.
20,neutral_reasoning,grok_4.1,2,2,2,6,7.59,140,"Correct final answer (No/Үгүй) with excellent logical explanation of why the inference is invalid, including contrapositive vs. invalid converse, symbolic notation, and concrete example. Far exceeds expectations."
20,neutral_reasoning,deepseek_v3.2,2,2,2,6,12.59,50,"Excellent response. Correctly identifies the logical fallacy (denying the antecedent), explains why the conclusion is invalid, and provides clear reasoning in natural Mongolian. Fully addresses the question with proper logical analysis."
20,neutral_reasoning,llama_4_maverick,2,2,2,6,0.52,41,Correct answer (No) with clear logical explanation. Natural Mongolian. Fully addresses the logical fallacy.
20,neutral_reasoning,qwen3,0,0,0,0,23.97,101,"Model response severely corrupted with thousands of repeated 'оороо' characters, making it unreadable and unusable. The beginning shows correct logical reasoning (A→K analysis, contrapositive explanation) but text degenerates into gibberish. Total failure."
20,neutral_reasoning,aya_expanse,1,0,1,2,5.05,58,Correct final answer 'үгүй' but broken/garbled fluency with nonsensical repeated phrases like 'тусламын сүрөгчүүд нээхгүй байгаа'. Logic is partially correct but explanation is confusing.
21,neutral_technical,claude_opus_4.5,2,2,2,6,23.57,257,"Excellent technical response in fluent Mongolian. Covers TCP/UDP differences comprehensively with clear examples, tables, diagrams, and use cases. Technical terms properly translated. Well-structured and thorough."
21,neutral_technical,gpt_5.2,2,2,2,6,14.18,213,"Excellent technical explanation in Mongolian with proper terminology, detailed comparisons, and clear use cases. Covers all key differences between TCP and UDP comprehensively."
21,neutral_technical,gemini_3_pro,2,2,2,6,1046.67,262,"Excellent response. Comprehensive, accurate, well-structured with clear explanations and comparison table. Fluent Mongolian throughout."
21,neutral_technical,grok_4.1,2,2,2,6,7.29,198,"Excellent response. Factually accurate, comprehensive comparison table, natural Mongolian technical terminology, covers all key TCP/UDP differences including connection model, reliability, speed, use cases. Well-structured and thorough."
21,neutral_technical,deepseek_v3.2,2,2,2,6,17.14,195,"Excellent technical explanation with correct terminology, comprehensive comparison table, and practical examples. Fully addresses TCP vs UDP differences with appropriate technical depth."
21,neutral_technical,llama_4_maverick,2,2,2,6,1.55,150,"Excellent technical explanation covering TCP/UDP differences, reliability, connection-oriented vs connectionless, ordering, with practical examples. Natural Mongolian with proper technical vocabulary."
21,neutral_technical,qwen3,2,2,2,6,18.24,329,"Excellent technical explanation with clear structure, correct terminology, and comprehensive coverage of all major differences. Includes helpful table and examples. Natural Mongolian."
21,neutral_technical,aya_expanse,0,0,0,0,17.92,145,"Response is completely garbled and unreadable. Text appears corrupted with nonsensical character sequences (хөлдөгчүнүү, өзөгчлөөрүн, таалгайлдаа, бүртгэлтлэхсэн, йрмийг). Not in any recognizable language. Impossible to assess content accuracy. Total failure."
22,neutral_technical,claude_opus_4.5,2,2,2,6,22.64,224,"Excellent technical response with clear explanation, practical examples, use cases across multiple fields, and even Python code. Mongolian is fluent and natural. Fully addresses what Monte Carlo simulation is and when it's used."
22,neutral_technical,gpt_5.2,2,2,2,6,22.25,308,"Excellent technical explanation with correct terminology, clear structure, multiple use cases, and discussion of advantages/limitations. Fully addresses both 'what' and 'when' parts of the question."
22,neutral_technical,gemini_3_pro,2,2,2,6,22.02,268,"Excellent response. Accurate definition of Monte Carlo simulation with clear explanation of randomness and probability distributions. Covers multiple real-world applications (finance, project management, engineering, science, insurance) with concrete examples. Well-structured, natural Mongolian, comprehensive answer. Response appears cut off at the very end but all essential content is complete."
22,neutral_technical,grok_4.1,2,2,2,6,12.62,235,"Excellent technical explanation with correct Monte Carlo definition, history, methodology, applications across multiple domains, and practical tools. Fluent Mongolian with proper technical vocabulary. Fully addresses both parts of the question."
22,neutral_technical,deepseek_v3.2,2,2,2,6,11.28,95,"Excellent response. Accurate definition, correct technical vocabulary, fluent Mongolian, comprehensive examples across finance/engineering/project management/science/insurance. Fully answers both 'what' and 'when'. Matches or exceeds reference quality."
22,neutral_technical,llama_4_maverick,2,2,2,6,1.4,102,"Excellent response: accurate definition covering random sampling and probability distributions, correctly explains when/why it's used (finance, risk analysis, complex systems), well-structured with concrete use cases, fluent Mongolian with proper technical terminology."
22,neutral_technical,qwen3,2,2,2,6,20.9,351,"Excellent technical explanation with correct terminology, clear examples across multiple fields, proper discussion of principles/advantages/disadvantages. Fully fluent Mongolian with appropriate technical vocabulary and natural phrasing throughout."
22,neutral_technical,aya_expanse,0,0,0,0,13.32,130,"Response is nearly unintelligible garbled text in Mongolian. Contains nonsensical phrases like 'эргээс эсвэл' (repeatedly), 'нэрмэлт тулгуурдаг', 'сүрөгдөр тохируу' that don't form coherent meaning. Does not explain what Monte Carlo simulation is or when it's used. Complete failure on all metrics."
23,neutral_technical,claude_opus_4.5,2,2,2,6,16.61,137,"Excellent technical explanation with correct photosynthesis equation, clear structure covering light/dark reactions, ATP/NADPH, chlorophyll, Calvin cycle. Natural Mongolian with proper scientific terminology. Thorough and well-organized with table and formatting."
23,neutral_technical,gpt_5.2,2,2,2,6,20.38,313,"Excellent technical explanation in Mongolian covering both light-dependent and light-independent reactions, ATP/NADPH production, electron transport chain, and Calvin cycle. Uses correct scientific terminology and provides clear structure with numbered sections. Matches the level of detail in the reference answer."
23,neutral_technical,gemini_3_pro,2,2,1,5,21.31,139,"Factually accurate, explains light absorption, light reactions, water splitting, O2 release, and Calvin cycle. Fluent native Mongolian. Cut off mid-word ('глю' instead of 'глюкоз'), missing full depth on ATP/NADPH and final equation, thus Completeness=1."
23,neutral_technical,grok_4.1,2,2,2,6,13.73,300,"Excellent technical explanation in natural Mongolian. Covers light-dependent/independent reactions, chemical equations, ATP/NADPH, Calvin cycle, chlorophyll function—all key concepts from the reference answer. Well-structured with clear headings and examples. Fluent scientific terminology throughout."
23,neutral_technical,deepseek_v3.2,2,2,2,6,14.1,95,"Excellent technical answer covering photosynthesis mechanism: chloroplasts, chlorophyll photon absorption, water splitting to O2, ATP/NADPH energy carriers, and Calvin cycle CO2 fixation to glucose. Accurate, fluent Mongolian with proper scientific terminology, and thorough coverage of the process."
23,neutral_technical,llama_4_maverick,2,2,2,6,1.91,179,"Excellent response. Covers light absorption by chlorophyll, photolysis, ATP/NADPH production, Calvin cycle, and CO2→glucose conversion. Includes ecological significance (O2 production, food chain). Accurate, well-structured, natural Mongolian, and thorough."
23,neutral_technical,qwen3,2,2,2,6,12.6,246,"Excellent technical explanation with correct chemistry, clear structure, proper Mongolian terminology, and thorough coverage of light/dark reactions plus energy conversion mechanism."
23,neutral_technical,aya_expanse,0,0,0,0,16.29,146,"Complete gibberish. Text is in Mongolian script but consists of repetitive nonsense phrases like 'эргээсэн эргээсэн' (repeated spinning/turning) with no coherent scientific explanation of photosynthesis. Fabricated/hallucinatory output with no factual content about chlorophyll, light reactions, Calvin cycle, glucose, or oxygen production."
24,neutral_technical,claude_opus_4.5,2,2,2,6,27.95,270,"Excellent technical answer with correct terminology, detailed coverage of HTLCs/commitment transactions/breach remedies/onion routing/multisig, well-structured with diagrams and tables, natural Mongolian phrasing throughout"
24,neutral_technical,gpt_5.2,2,2,2,6,29.19,424,"Excellent technical answer covering all key primitives: multisig, timelocks (CLTV/CSV), HTLCs, revocation/penalty mechanisms, ECDSA/Schnorr, onion routing (Sphinx/ECDH), and watchtowers. Well-structured with clear explanations. Natural Mongolian technical prose with proper terminology. Fully addresses the question with depth."
24,neutral_technical,gemini_3_pro,2,2,1,5,36.87,167,"Correct core concepts (multisig, HTLC with hashlock/timelock), natural Mongolian, but response cut off mid-sentence—missing penalty transactions, onion routing, revocable channels. Partial coverage."
24,neutral_technical,grok_4.1,2,2,2,6,13.54,322,"Excellent technical response with correct terminology. Covers core primitives (ECDSA/Schnorr signatures, SHA-256/RIPEMD-160 hashes, CLTV/CSV timelocks, HTLCs, revocation secrets, multisig) plus advanced concepts (Watchtowers, Taproot/Schnorr, MuSig2). Accurate, naturally fluent Mongolian with proper technical vocabulary, and thoroughly addresses all aspects of LN security primitives."
24,neutral_technical,deepseek_v3.2,2,2,2,6,10.16,94,"Excellent technical response covering HTLCs, multi-sig, watchtowers, onion routing. Matches reference answer's core primitives. Natural Mongolian with proper terminology."
24,neutral_technical,llama_4_maverick,2,2,2,6,1.14,109,"Excellent response. Correctly identifies HTLCs, multi-sig, onion routing, and digital signatures. Fluent native-level Mongolian with proper technical terminology. Thorough explanation covering all major security primitives."
24,neutral_technical,qwen3,2,2,2,6,22.64,375,"Excellent technical response with correct crypto primitives (HTLC, timelock, RSMC, signatures). Fluency is native-quality Mongolian with proper terminology. Thorough coverage exceeds basic requirement. No Kyrgyz markers detected."
24,neutral_technical,aya_expanse,0,0,0,0,16.79,133,"Completely garbled text with nonsensical repetition. No recognizable Mongolian words or meaningful content. Appears to be corrupted output or model failure. Does not address HTLCs, penalty transactions, onion routing, or any actual Lightning Network security primitives."
25,neutral_technical,claude_opus_4.5,1,2,2,5,40.69,510,"Very thorough technical explanation with tables, equations, tools, and practical checklists. However, the reference answer is simpler ('avoiding parallel routing, spacing traces, decoupling caps'), so this is partially correct but far more expansive. Content is accurate PCB design practice. Fluency is excellent—native Mongolian with technical terminology. Completeness is full."
25,neutral_technical,gpt_5.2,0,2,0,2,46.39,738,"Wrong language: response in Mongolian script but question asks for PCB signal integrity tools. Reference answer is 'avoiding parallel routing, spacing traces, decoupling caps'—a simple, brief answer. Model gave extremely detailed PCB design guide (stack-up, impedance control, via design, termination, simulation tools, measurement equipment) totaling ~1500 words. While technically accurate for PCB SI in general, it's a complete mismatch: question asks for brief practical advice, answer is exhaustive engineering tutorial. Fluency=2 (native Mongolian), Accuracy=0 (massively over-engineered, wrong scope), Completeness=0 (answers different question)."
25,neutral_technical,gemini_3_pro,2,2,2,6,22.54,261,"Excellent technical answer in proper Mongolian. Goes far beyond the reference answer with comprehensive coverage of signal integrity principles (impedance control, stack-up, differential pairs, crosstalk, vias, power integrity) and mentions appropriate tools (EDA/simulation software). Answer appears cut off but what's present is thorough and accurate."
25,neutral_technical,grok_4.1,1,2,2,5,15.69,381,"Excellent Mongolian fluency and extremely thorough (way beyond expected scope). However, the reference answer is specifically about trace spacing and decoupling caps placement. This response covers those plus impedance control, via design, stackup, etc. - comprehensive but arguably over-answers. The core concepts are correct but the reference is simpler/more focused. Accuracy=1 for partial match (has the right ideas but not as concise as reference). Fluency=2 (perfect Mongolian). Completeness=2 (addresses question fully, even excessively)."
25,neutral_technical,deepseek_v3.2,1,2,1,4,80.19,148,"Response is fluent in Mongolian with proper technical vocabulary. However, it misses the key ground-truth answer (avoiding parallel routing, spacing traces, decoupling caps). Instead gives general PCB design practices (impedance matching, ground planes, length matching) and extensive tool lists (CAD software, oscilloscopes, analyzers) which are relevant but not what was asked. Partially correct but incomplete match to reference answer."
25,neutral_technical,llama_4_maverick,1,2,1,4,2.27,258,"Fluent Mongolian but overexplains with CAD/simulation tools instead of core PCB layout techniques (parallel routing avoidance, trace spacing, decoupling). Mentions key concepts (layer organization, trace routing, decoupling caps, grounding) but misses the concise practical focus of reference answer."
25,neutral_technical,qwen3,1,2,2,5,22.24,443,"Fluent Mongolian, thorough coverage of SI topics (impedance, ground planes, crosstalk, decoupling, simulation tools). However, the English reference is very specific: 'avoid parallel routing, spacing out traces, decoupling caps.' The response covers those points but adds extensive material (differential pairs, via design, power integrity, etc.) not in the reference. Core answer is present but less concise. Accuracy = 1 (partially correct, key ideas present but not matching terse reference style); Fluency = 2 (natural Mongolian); Completeness = 2 (fully addresses the question with depth)."
25,neutral_technical,aya_expanse,0,0,0,0,21.53,200,"Response is nonsensical repetitive text with no actual technical content. Uses made-up/garbled words like 'хоёрчлонго', 'тогтмолго' that don't exist in Mongolian. Completely fails to address PCB signal integrity (parallel routing, trace spacing, decoupling caps). Appears to be a model hallucination or generation error."
26,neutral_technical,claude_opus_4.5,2,2,2,6,15.48,112,"Excellent technical response in Mongolian. Correctly identifies pulmonary surfactant, provides detailed composition breakdown, functions, and clinical significance. Uses proper medical terminology. Well-structured with tables and clear sections. Far exceeds basic answer requirements."
26,neutral_technical,gpt_5.2,2,2,2,6,3.39,29,Excellent response with correct answer plus detailed biochemical composition and function
26,neutral_technical,gemini_3_pro,2,2,2,6,21.83,44,"Excellent response. Correctly identifies surfactant, provides both Mongolian term and transliteration, explains composition (phospholipids and proteins) and two key functions. Goes beyond minimum answer with appropriate technical depth. Mongolian is natural and fluent with proper technical vocabulary."
26,neutral_technical,grok_4.1,2,2,2,6,7.98,91,"Excellent response. Correctly identifies pulmonary surfactant in both Mongolian and English. Goes beyond the question with detailed explanation of surfactant function, other roles of Type II pneumocytes, and mentions lamellar bodies. Natural Mongolian with proper technical terminology. Far exceeds what was required but all info is accurate."
26,neutral_technical,deepseek_v3.2,2,2,2,6,19.91,100,"Excellent answer. Goes beyond the reference by detailing surfactant components (phospholipids, proteins SP-A/B/C/D, cholesterol) and explaining functions (reduces surface tension, immune defense, alveolar repair). Correct, thorough, natural Mongolian medical terminology."
26,neutral_technical,llama_4_maverick,2,2,2,6,0.52,28,Excellent technical response. Correctly identifies pulmonary surfactant as the primary product and provides medically accurate explanation of surfactant's function in reducing surface tension and maintaining lung elasticity. Natural Mongolian phrasing with appropriate technical terminology.
26,neutral_technical,qwen3,2,2,2,6,7.18,113,"Excellent response. Correctly identifies pulmonary surfactant as the primary secretion, provides detailed explanation of surfactant composition (lipids, proteins SP-A/B/C/D, phosphatidylcholine), explains its function (reduces surface tension, prevents alveolar collapse), mentions additional enzymes (lysophospholipase, phospholipase A2), and notes regenerative role. Technical terminology is accurate in Mongolian. Far exceeds the basic reference answer in depth while remaining factually correct."
26,neutral_technical,aya_expanse,0,0,0,0,14.45,133,"Response is completely garbled/broken text, unreadable, wrong script patterns, no recognizable medical terminology. Does not answer what Type II pneumocytes secrete (should be pulmonary surfactant). Total failure."
27,neutral_technical,claude_opus_4.5,2,2,2,6,17.95,153,"Excellent response: accurate differentiation of diffusion vs osmosis, clear table format, correct technical terminology in Mongolian, covers membrane requirement, molecules involved, direction of movement, and provides examples. Slightly exceeds reference answer but all content is correct."
27,neutral_technical,gpt_5.2,2,2,2,6,12.41,175,"Excellent response. Factually accurate, covers all key distinctions (molecules involved, membrane requirement, direction, biological examples). Natural Mongolian with proper scientific terminology. Goes beyond the reference answer with clear structure and additional detail on isotonic/hypotonic/hypertonic environments."
27,neutral_technical,gemini_3_pro,2,2,2,6,233.85,263,"Excellent response. Factually correct, goes well beyond the reference answer with detailed table, examples, and clear explanations. Natural Mongolian throughout, properly formatted with bullet points and table. Fully addresses the question with depth and clarity."
27,neutral_technical,grok_4.1,2,2,2,6,20.72,225,"Excellent response. Factually accurate, covers all key differences (any molecule vs water only, membrane requirement, passive transport). Fluent native Mongolian with proper technical vocabulary. Goes beyond minimum with helpful table and examples. Fully addresses the question."
27,neutral_technical,deepseek_v3.2,2,2,2,6,16.71,195,"Excellent response. Factually accurate with comprehensive explanation including table, examples, and key distinctions. Goes beyond reference answer by explaining osmotic pressure and providing specific biological examples. Natural Mongolian with proper technical terminology."
27,neutral_technical,llama_4_maverick,2,2,2,6,1.76,175,"Excellent response. Covers passive transport nature, molecular differences (diffusion for any molecule vs osmosis for water/solvent), semi-permeable membrane requirement for osmosis, and biological importance. Well-structured, clear Mongolian, thorough explanation."
27,neutral_technical,qwen3,2,2,2,6,16.4,295,"Excellent technical response in fluent Mongolian. Covers passive transport, molecular differences, membrane requirements, and cellular applications. Uses proper terminology (зөөлөн нэвтрүүлэгч мембран, концентраци, диффуз/осмос). Includes helpful table and examples. Goes beyond reference answer but remains accurate. No Kyrgyz markers detected."
27,neutral_technical,aya_expanse,0,0,0,0,10.66,87,"Response is garbled/incoherent Mongolian with repeated nonsensical phrases (жишгээлэх дээр өрөмжүүлэхдийн жагдаалтад нөхрөн нөхрөн). Does not explain diffusion vs osmosis correctly, no mention of passive transport, water molecules, or cell turgidity. Appears to be machine translation errors or corruption."
28,neutral_technical,claude_opus_4.5,0,2,0,2,19.67,188,"Wrong answer. Focuses on debt collection agencies and financial institutions buying consumer debt, not over-levered companies doing debt buybacks. Completely misses the LBO/PE context. Fluent Mongolian though."
28,neutral_technical,gpt_5.2,0,2,0,2,22.66,330,"Wrong question answered. Q is about debt buybacks (over-levered PE-acquired cos), but model explained debt purchase/collection (NPL buyers, distressed asset investors). Content is fluent Mongolian but completely off-topic."
28,neutral_technical,gemini_3_pro,1,2,1,4,146.49,128,Response starts correctly identifying PE firms and LBOs but gets cut off mid-sentence. Misses key points about over-leveraged companies facing interest payment difficulties with excess cash. Fluency is native-level Mongolian. Partial accuracy for mentioning PE firms and leveraged buyouts.
28,neutral_technical,grok_4.1,0,2,1,3,14.57,234,"Wrong concept entirely. Question asks about debt buy-backs (companies repurchasing their own debt), model answered about debt collection agencies buying distressed debt from others. Fluent Mongolian but completely off-topic."
28,neutral_technical,deepseek_v3.2,0,2,0,2,15.27,108,"Wrong topic entirely. Question asks about debt buybacks (companies repurchasing their own debt), answer discusses debt purchasing/acquisition by financial institutions. Fluent Mongolian but completely misses the point."
28,neutral_technical,llama_4_maverick,1,2,1,4,1.76,186,"Partially correct: mentions financially distressed companies and restructuring, which aligns with the concept, but misses the specific PE-firm/leveraged-buyout context and excess cash detail from reference answer. Fluent Mongolian. Over-elaborated with generic debt management advice rather than directly answering which companies would enact debt buy-backs."
28,neutral_technical,qwen3,0,2,2,4,13.11,223,"Response is fluent Mongolian and thorough but completely misunderstands the question. Question asks which companies DO debt buybacks (repurchasing their own debt), not which companies are suitable for leveraged buyouts. Answer discusses LBO target characteristics instead of over-levered companies doing debt repurchases."
28,neutral_technical,aya_expanse,0,0,0,0,25.0,174,Complete gibberish. Repetitive nonsensical phrases in Mongolian with no semantic meaning. Does not address debt buybacks at all. Appears to be severe model failure or hallucination.
29,neutral_technical,claude_opus_4.5,2,2,2,6,12.81,99,"Excellent response. Correctly identifies aileron (элерон), provides detailed explanation of function, operation, and control mechanism with clear table. Technical terminology is accurate in Mongolian. Far exceeds minimal answer requirement."
29,neutral_technical,gpt_5.2,2,2,2,6,5.33,57,"Excellent response. Correctly identifies 'элерон' (aileron), explains roll motion mechanism clearly, and provides additional technical detail about differential lift. Fluent Mongolian with proper terminology."
29,neutral_technical,gemini_3_pro,2,2,2,6,120.13,78,"Correct answer (Aileron/Элер), fluent Mongolian, thorough explanation with technical details about location, mechanism, and function."
29,neutral_technical,grok_4.1,2,2,2,6,8.36,94,"Excellent response. Correct answer 'ailerons' (өнхрүүлэгч) provided with detailed technical explanation of opposing movement, roll axis, and lift differential. Goes beyond the question with helpful context about coordinated aileron action. Mongolian is fluent and natural. Fully addresses the question with significant added value."
29,neutral_technical,deepseek_v3.2,0,2,0,2,4.83,18,"Model refused to answer. Fluency=2 as refusal is in correct language (Mongolian) and grammatically correct, but Accuracy=0 and Completeness=0 per scoring rule #3."
29,neutral_technical,llama_4_maverick,2,2,2,6,1.04,73,"Correct answer (aileron) with excellent technical explanation in proper Mongolian. Natural phrasing, technically accurate detail about roll axis and control mechanism."
29,neutral_technical,qwen3,2,2,2,6,10.15,177,"Correct answer 'aileron' (эргэлтийн дархан) clearly stated. Response goes beyond minimum requirement with detailed technical explanation including location, function, mechanics, and interaction with other control surfaces. Language is natural and technical terminology appropriate. Far exceeds expectations for technical vocabulary question."
29,neutral_technical,aya_expanse,0,0,0,0,21.72,158,"Response is garbled nonsense with repetitive broken phrases, fails to provide the answer 'aileron' or any coherent technical explanation. Appears to be severe model hallucination or generation error."
30,neutral_technical,claude_opus_4.5,2,2,2,6,23.26,232,"Excellent technical explanation with correct principles, clear structure, diagrams, examples, and proper Mongolian technical terminology. Goes well beyond minimum requirements while remaining accurate."
30,neutral_technical,gpt_5.2,2,2,2,6,23.98,351,"Exceptionally thorough and accurate technical explanation in fluent Mongolian. Covers NPN structure, doping, forward/reverse bias, beta relationship, cutoff/active/saturation modes with specific voltage values (0.7V, VCE(sat)), and applications. Far exceeds reference answer in depth while maintaining correctness. Perfect technical vocabulary (допинглогдсон, туйлшруулна, нүхтэй рекомбинац, өсгөлтийн коэффициент)."
30,neutral_technical,gemini_3_pro,2,2,1,5,22.78,200,"Accurate explanation with good analogy (water valve). Fluent Mongolian. Cut off mid-sentence, missing conclusion, so incomplete."
30,neutral_technical,grok_4.1,2,2,2,6,13.7,357,"Excellent response. Factually accurate with correct explanation of NPN operation, forward-biased EB junction, reverse-biased BC junction, electron flow, current gain (β), and operating modes. Fluent Mongolian with proper technical terminology. Comprehensive coverage with structure, operating principles, modes (cut-off/active/saturation), example circuit, and practical notes. Far exceeds reference answer in depth while maintaining accuracy."
30,neutral_technical,deepseek_v3.2,2,2,2,6,11.18,108,"Excellent technical explanation with correct physics, proper terminology, and additional useful context about applications. Naturally fluent Mongolian."
30,neutral_technical,llama_4_maverick,2,2,2,6,1.86,188,"Excellent technical explanation in natural Mongolian. Covers NPN structure (3 layers), components (collector/base/emitter), operation (forward-bias base-emitter, reverse-bias base-collector, electron flow), and current amplification. More detailed than reference answer but all content is accurate and relevant."
30,neutral_technical,qwen3,2,2,2,6,14.97,269,"Excellent technical response. Correctly explains NPN transistor operation with proper structure (N-P-N), forward-bias mechanism, electron flow from emitter to collector, current control (β × I_B), and typical voltage threshold (0.6-0.7V). Exceeds minimum requirements with detailed explanation of switch/amplifier applications. Mongolian is natural and fluent with correct technical terminology. No errors detected."
30,neutral_technical,aya_expanse,0,0,0,0,23.87,178,Completely garbled text. Not proper Mongolian—appears to be machine-generated gibberish with random Mongolian-like words. Incomprehensible and contains fabricated terminology. Cannot assess technical accuracy because the text is unintelligible.
31,kazakh_cultural,claude_opus_4.5,2,2,2,6,23.46,151,"Excellent response. Culturally rich, accurate details about dombra's role (preserving nomadic culture, kuys, social gatherings, spiritual use by bakhsy, akyn tradition, UNESCO heritage). Written in fluent Mongolian with proper structure. Fully addresses the question with significant depth."
31,kazakh_cultural,gpt_5.2,2,2,2,6,22.75,257,"Excellent response. Covers all major aspects from the answer key (musical cornerstone, nomadic culture preservation, community gathering, kuy tradition, oral transmission) plus additional valid cultural details (aitys, hospitality symbol, national identity). Fluent Mongolian with proper terminology. Thorough and well-organized."
31,kazakh_cultural,gemini_3_pro,2,2,2,6,23.03,209,"Excellent response. Accurately covers dombra's role as soul of Kazakh identity, historical transmission through kui, oral tradition/aitys, and social/family significance. Natural Mongolian phrasing with proper terminology. Thorough multi-faceted explanation."
31,kazakh_cultural,grok_4.1,2,2,2,6,10.49,177,"Excellent response in natural Mongolian. Covers all key aspects: instrument type, cultural roles (folk music, ceremonies), national symbol status, UNESCO recognition, modern usage. Goes beyond the reference answer with structured detail. No Kyrgyz/Kazakh language issues detected."
31,kazakh_cultural,deepseek_v3.2,2,2,2,6,11.07,78,"Excellent response in correct Mongolian. Accurately describes dombra's cultural significance with appropriate depth: musical instrument, spiritual/psychological role, pastoral life connection, transmission of oral tradition, national identity symbol. Matches answer sheet details well."
31,kazakh_cultural,llama_4_maverick,1,2,1,4,1.75,140,"Fluency is natural Mongolian. However, response confuses dombra (Kazakh) with dombur (Mongolian topshuur variant). The UNESCO 2014 registration mentioned is for Mongolian morin khuur/topshuur tradition, not Kazakh dombra. Contains factual errors but captures general cultural importance. Partially correct but misses key details like kuy tradition, aitys, nomadic culture role."
31,kazakh_cultural,qwen3,2,2,2,6,4.1,76,"Accurate cultural content covering dombra's role in music, oral tradition, ceremonies, and identity. Natural Mongolian phrasing. Thorough explanation."
31,kazakh_cultural,aya_expanse,0,0,0,0,4.62,40,"Response is in Kyrgyz, not Mongolian. Uses Kyrgyz markers: жана (vs Mongolian ба), көмүрөк/көтөрлөр (non-Mongolian words), Kyrgyz phonology. Wrong language = Fluency 0. Content unverifiable due to language error."
32,kazakh_cultural,claude_opus_4.5,2,2,2,6,28.81,211,"Excellent response. Accurately describes Tusau Kesu tradition with correct cultural details (age, ceremony steps, symbolism). Well-structured Mongolian with natural phrasing. Thorough coverage including modern practice. Minor note: uses Kazakh romanization 'Тұсау кесу' correctly."
32,kazakh_cultural,gpt_5.2,2,2,2,6,24.28,239,"Excellent response. Accurately describes Tusau Kesu ceremony, its symbolism, procedure, and cultural significance. Well-structured in Mongolian with proper terminology. Covers all key aspects: cutting the fetters, symbolic meaning of freedom from obstacles, choosing the person to cut, community involvement, and developmental milestone marking."
32,kazakh_cultural,gemini_3_pro,2,2,1,5,25.62,201,"Accurate and culturally detailed explanation of Tusau Kesu in fluent Mongolian. Covers meaning, purpose, and ceremony details. Response appears cut off mid-sentence, preventing full score on completeness, but existing content is thorough and well-structured."
32,kazakh_cultural,grok_4.1,0,2,0,2,17.42,259,"Wrong cultural tradition entirely. Response describes Mongolian 'Tusaa Kesu' (hair-cutting ceremony at 1-3 years) instead of Kazakh 'Tusau Kesu' (leg-tying/cutting ceremony when child learns to walk). This is a Kazakh-aligned cultural question requiring knowledge of Kazakh tradition, not Mongolian. Fluent Mongolian but completely wrong content."
32,kazakh_cultural,deepseek_v3.2,0,2,0,2,77.74,130,"Complete hallucination. 'Tусау кесу' is a KAZAKH tradition (cutting fetters when child learns to walk, age ~1-1.5), NOT Mongolian. Model invented a Mongolian toenail-cutting ceremony that doesn't exist. Fluent Mongolian but factually wrong category."
32,kazakh_cultural,llama_4_maverick,0,2,1,3,2.98,288,"Response describes Mongolian 'tusau kesu' tradition (cutting rope at child's first steps), NOT Kazakh 'Tusau Kesu'. Kazakh version involves tying child's legs with 2-3 layer rope (black/white/animal intestines) at 1-1.5 years, cut by respected person, then child chooses items (book/Quran/money/dombra) predicting future. This response has none of those elements—describes Mongolian ceremony with sheep wool, person on horseback, symbolism of herding. Completely wrong cultural tradition despite fluent Mongolian."
32,kazakh_cultural,qwen3,1,2,1,4,14.96,264,"Partially correct but contains significant errors. Response claims 'Тусау кесу' restricts the child's first steps, when actually it celebrates them by cutting the fetters. Misses key details: ceremony at 1-1.5 years, cutting ceremony performed by respected person, child choosing objects for future prediction. Fluency excellent, reads naturally in Mongolian. Addresses the question but misses crucial ceremonial elements and misrepresents the core meaning."
32,kazakh_cultural,aya_expanse,0,0,0,0,14.55,125,Complete hallucination. Response is garbled nonsense with repeated phrases about 'эргээсийн сүрөгчдийн нэрээс харилцаа' and irrelevant banking example. Does not explain Tusau Kesu tradition at all. Appears to be broken generation or severe model failure.
33,kazakh_cultural,claude_opus_4.5,2,2,2,6,23.52,192,"Excellent response. Factually accurate with correct geographic distribution (Uly/Orta/Kishi zhuz), lifestyle distinctions, social structure, and major tribes. Well-organized with table and clear sections. Natural Mongolian fluency. Thorough coverage of all sub-parts of the question."
33,kazakh_cultural,gpt_5.2,2,2,2,6,21.42,227,"Accurate, comprehensive, and fluent. Correctly identifies the three jüz and explains the main differences: geographical distribution (south/southeast, central/north/east, west), tribal composition, and historical/political orientation. Well-structured and natural Mongolian."
33,kazakh_cultural,gemini_3_pro,2,2,1,5,21.51,72,"Correct identification of three zhuz with proper names and geographical info, natural Mongolian phrasing, but response appears cut off mid-sentence - likely incomplete due to truncation. What's visible is accurate and fluent."
33,kazakh_cultural,grok_4.1,2,2,2,6,13.23,223,"Thorough, accurate answer covering all three zhuz with geographic, tribal, historical, and cultural details. Natural Mongolian, no Kazakh/Kyrgyz detected. Exceeds minimal requirements."
33,kazakh_cultural,deepseek_v3.2,2,2,2,6,79.68,184,"Correct zhuz identifications and territories. Fluent Mongolian with proper script. Thorough coverage of geographic, tribal, and cultural differences."
33,kazakh_cultural,llama_4_maverick,1,2,1,4,1.55,154,"Fluency excellent (natural Mongolian). Accuracy partial: correctly identifies 3 zhuz with geographic locations, but percentages/demographic claims are not in the answer sheet and may be fabricated. Answer sheet lists 6 tribes for Middle, 3 for Junior—model omits this. Economic focus differs from answer sheet's territorial focus. Completeness partial: addresses question but lacks tribal composition details and misses northwestern China/Uzbekistan for Senior zhuz."
33,kazakh_cultural,qwen3,0,2,1,3,22.03,320,"Completely fabricated answer. The response invents fake geographic locations, historical roles, and social structures that do not match the actual three Kazakh zhuz (Uly/Senior, Orta/Middle, Kishi/Junior). The real zhuz are based on tribal confederations in specific regions of Kazakhstan, not the fictional Siberian/Altai/Chinese borders described here. Fluent Mongolian but factually wrong throughout."
33,kazakh_cultural,aya_expanse,0,0,0,0,0.62,5,Response is completely incoherent and unrelated to the question about Kazakh zhuz differences. Appears to be garbled or broken text.
34,kazakh_cultural,claude_opus_4.5,2,2,2,6,19.61,148,"Excellent response. Factually accurate (birth/death dates, 170+ poems, 45 essays in Qara Soz, translations of Pushkin/Lermontov/Krylov, nickname 'Abai' from grandmother). Fluent natural Mongolian. Thorough coverage of who he was, literary legacy (poetry, Qara Soz philosophy, translations), and cultural significance. Well-structured with sections and bullet points."
34,kazakh_cultural,gpt_5.2,2,2,2,6,31.46,394,"Excellent response. Factually accurate, comprehensive coverage of Abai's life and literary legacy including poetry, Kara Sozder (Qara sözdər), translations, and social reform role. Natural Mongolian with proper terminology. Fully addresses all aspects of the question with strong cultural depth."
34,kazakh_cultural,gemini_3_pro,2,2,1,5,21.31,250,"Factually accurate and comprehensive, excellent Mongolian fluency. Response was cut off mid-sentence, preventing full completeness score, but covers main biographical points and literary legacy (Kara Sozder, poetry innovations). Would be 2/2/2 if complete."
34,kazakh_cultural,grok_4.1,2,2,2,6,15.68,302,"Excellent response with accurate biographical details, correct dates (1845-1904), comprehensive coverage of his literary legacy including 'Qara sözder', poetry, music, translations. Natural Mongolian throughout. Fully addresses all parts of the question with cultural depth."
34,kazakh_cultural,deepseek_v3.2,2,2,2,6,80.3,189,"Excellent response. Factually accurate with correct dates (1845-1904), mentions key works including Қара сөздер (Words of Edification), his poetry, translations of Pushkin/Lermontov/Goethe/Schiller, and his role as founder of written Kazakh literature. Fluency is perfect Mongolian with no errors. Completeness is thorough with specific examples and cultural context. Fully addresses the question."
34,kazakh_cultural,llama_4_maverick,1,2,1,4,1.55,128,"Correct basic facts (famous Kazakh poet, philosopher, 1845 birth, literary legacy) but lacks key specifics from answer sheet: no mention of 'El Libertador' equivalent title, 'Book of Words' (Қара сөздері), his role as founder of written Kazakh literature, his call for education to escape poverty/slavery/corruption, or that pre-Abai most Kazakh poetry was oral. Generic treatment without the depth expected for cultural question."
34,kazakh_cultural,qwen3,0,0,0,0,26.01,407,"Response is in Kazakh, not Mongolian. Wrong target language for C4. Also contains extensive fabricated details not in answer sheet. Should score Fluency=0 per rule 4."
34,kazakh_cultural,aya_expanse,0,0,0,0,21.14,176,"Response is in Kyrgyz, not Mongolian. Key markers: 'түрүнүүлөрүнүн', 'бүтээнчил', 'жана' (vs Mongolian 'ба'), 'катары', 'көрсөттү'. Also contains factual errors: birth year 1845 (correct 1845), death year 1904 (correct 1904), but no mention of his role as poet/founder of written Kazakh literature or his major work 'Book of Words'. Content is generic political/educational commentary."
35,kazakh_cultural,claude_opus_4.5,0,2,2,4,12.6,81,"Names completely wrong. Correct: Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov. Model gave: Rinat Makhambetov, Rauan Kenzhebkov, Didar Kaldar. Hallucination. Fluent Mongolian, thorough format."
35,kazakh_cultural,gpt_5.2,1,2,1,4,5.32,47,"Gave 2 correct names (Saken Maygaziev, Kenzhebek Zhanabilov) but added an incorrect third member (Dosymzhan Tanatаrov) instead of Meyrambek Besbaev. Fluent Mongolian. Partial answer."
35,kazakh_cultural,gemini_3_pro,2,2,2,6,10.76,52,Perfect answer with bonus historical context about Maksat Bazarbayev's departure in 2005. All three current members correctly named. Natural Mongolian with good formatting.
35,kazakh_cultural,grok_4.1,0,2,2,4,13.12,73,"Completely wrong members listed. Correct answer is Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov. Model gave Almas Kisik, Azamat Mukhit, Bekzat Abdrakhmanov - fabricated names. Fluency is natural Mongolian, Completeness is thorough with detail, but all factually incorrect."
35,kazakh_cultural,deepseek_v3.2,0,2,2,4,9.84,75,"Wrong band entirely. Lists MuzART as a Kazakh girl pop group with completely fabricated member names (Gulnur Sapanova, Nazerke Serikbol, Zhanar Dugei). Correct answer is Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov - male musicians. Response is fluent Mongolian with thorough structure, but content is hallucinated."
35,kazakh_cultural,llama_4_maverick,0,2,1,3,0.52,21,"Completely wrong members listed. MuzART is a male trio (Besbaev, Maygaziev, Zhanabilov), but model lists three female names instead. Fluency is natural Mongolian, completeness partial as it attempts full answer with structure."
35,kazakh_cultural,qwen3,0,2,2,4,3.8,72,"Completely fabricated answer. Correct members are Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov. Model invented Dias Abildarov, Aidar Abildarov, Aigerim Kabulova - none are real members. Fluent Mongolian, thorough format, but factually wrong hallucination."
35,kazakh_cultural,aya_expanse,0,0,0,0,2.85,23,"Response is completely garbled/broken text, wrong language mixing, unreadable. Does not name any band members. Fluency=0 for broken text."
36,kazakh_cultural,claude_opus_4.5,2,2,2,6,12.7,87,Excellent response. Factually accurate with all historical names correctly listed. Natural Mongolian fluency with proper formatting. Goes beyond requirements by adding context about Almaty transfer and name meanings. No errors detected.
36,kazakh_cultural,gpt_5.2,1,2,1,4,5.53,65,"Missing founding year (1830 as Akmoly), Akmola (1832 as Akmolinsk), and initial name. Includes correct later names but incomplete history. Fluent Mongolian."
36,kazakh_cultural,gemini_3_pro,2,2,2,6,19.57,60,Excellent response. All capital names are correct and in proper chronological order. The model even includes the founding year (1832) context and correctly notes Almaty as the previous capital before 1997. Mongolian is natural and fluent throughout.
36,kazakh_cultural,grok_4.1,1,2,1,4,5.34,48,"Missing earlier historical names: Akmoly (1830), Akmolinsk (1832), Tselinograd (1961), Aqmola (1992). Only covers 1929 onward. Fluency is natural Mongolian. Partial completeness due to incomplete history."
36,kazakh_cultural,deepseek_v3.2,0,2,1,3,76.45,99,"Model misunderstood question—provided Almaty's name history instead of Astana/Nur-Sultan/Aqmola history. Q asks for capital city's names (Akmoly 1830, Akmolinsk 1832, Tselinograd 1961, Aqmola 1992, Astana 1998, Nur-Sultan 2019, Astana 2022). Model focused on wrong city (Almaty) which was capital 1929-1997 but question asks about THE capital's name changes, meaning current capital. Fluent Mongolian. Partial completeness as it mentions Astana's names at end but main content is wrong city."
36,kazakh_cultural,llama_4_maverick,1,2,1,4,1.07,96,"Misses most historical names (Akmoly 1830, Akmolinsk 1832, Tselinograd 1961, Aqmola 1992). Only covers Almaty (1929, incorrect founding date for capital status), Astana, Nur-Sultan, and Astana again. Fluency is natural Mongolian. Partial completeness due to missing earlier names."
36,kazakh_cultural,qwen3,2,2,2,6,9.64,164,"Fully accurate, comprehensive historical coverage including all name changes with dates. Natural Mongolian with proper formatting and explanations. Goes beyond the brief reference answer to provide rich historical context."
36,kazakh_cultural,aya_expanse,0,0,0,0,11.68,101,"Complete hallucination. Question asks about capital city names (Akmola, Akmolinsk, Tselinograd, Astana, Nur-Sultan). Response lists random Kazakh personal names with incoherent Mongolian. Text is garbled and unreadable."
37,kazakh_cultural,claude_opus_4.5,1,2,1,4,20.86,169,"Partially correct. Model correctly describes Nauryz kozhe as a 7-ingredient dish for Nauryz celebration, includes most standard ingredients (meat, water, rice, wheat, flour, milk/butter, salt), and provides cooking steps. However, misses key ingredients from answer sheet (tary/millet, kurt/dried cheese product, airan/kefir) and omits important final step of adding kefir. Good Mongolian fluency. Incomplete on details."
37,kazakh_cultural,gpt_5.2,2,2,2,6,25.06,337,"Excellent response. Factually accurate with correct 7-ingredient tradition, appropriate Mongolian ingredients (beef/mutton, wheat, barley, dairy, oil, salt). Well-structured with clear steps. Natural fluency with proper Mongolian vocabulary and phrasing. Comprehensive coverage of ingredients, preparation methods, and cultural context."
37,kazakh_cultural,gemini_3_pro,2,2,1,5,23.67,151,"Accurate cultural and culinary details about Nauryz Kozhe with correct 7 ingredients tradition. Fluent Mongolian. Response was cut off mid-instruction so completeness slightly reduced, but covers key elements thoroughly."
37,kazakh_cultural,grok_4.1,1,2,2,5,21.73,259,"Response is in Mongolian as required. Very thorough recipe with 7 ingredients matching tradition. However, some ingredients differ from reference (adds barley flour, honey, dried fruits not in original; original has rice, millet, wheat). Structure and cultural context good but ingredient mismatch = partial accuracy."
37,kazakh_cultural,deepseek_v3.2,1,2,1,4,18.31,149,"Fluency is natural Mongolian. Content is partially accurate (7 ingredients, wheat, barley, meat, milk/ayrag correct) but recipe steps are generic/vague compared to detailed Kazakh answer. Misses key specifics: kefir/айран at end, exact cooking times/temps, foam skimming, straining broth, etc. Cultural symbolism is good but recipe itself lacks depth."
37,kazakh_cultural,llama_4_maverick,1,2,1,4,1.51,118,"Response is in Mongolian (correct language) and fluent. However, accuracy is partial: some ingredients overlap (тараг/цай/гурил/будаа/мах/өөх/давс) but recipe differs significantly from reference (no step-by-step cooking process matching boiling meat, straining broth, cooking grains separately, then combining). Completeness is partial: provides a method but lacks the detailed multi-stage process from the answer key. Cultural context about Nauryz is implied but minimal."
37,kazakh_cultural,qwen3,1,2,1,4,15.47,278,"Fluent Mongolian but factually incorrect. Ground truth specifies specific Kazakh ingredients (meat, dairy/kefir, grains) and cooking method. Model invents '9 ingredients' symbolism not in answer sheet, lists wrong items (fruit, flour alone), and describes mixing rather than cooking process. Partial credit for addressing the question and mentioning some correct elements like grains and meat."
37,kazakh_cultural,aya_expanse,0,0,0,0,4.83,49,Complete fabrication. Response is garbled nonsense in broken Mongolian. Navruz kozhe is a Kazakh dish made with 7 ingredients (milk/meat/grains). Model produced incoherent text with made-up words and no resemblance to the correct recipe. Wrong language understanding (treats as Mongolian concept when it's Kazakh). Total failure.
38,kazakh_cultural,claude_opus_4.5,2,2,2,6,18.64,128,"Excellent answer. Provides factually accurate details about the Jeltoqsan/December 1986 uprising in Alma-Ata, including correct dates (Dec 16-17), key figures (Kolbin replacing Kunayev), causes (ethnic resentment of Moscow's appointment), and historical significance. Fluent Mongolian with no Kyrgyz markers or language errors. Thorough coverage with context and consequences."
38,kazakh_cultural,gpt_5.2,2,2,2,6,14.95,167,"Excellent response. Correct event (Jeltoqsan/December uprising), accurate details on Kunayev replacement by Kolbin, protests in Almaty, violent crackdown, and historical significance for independence movement. Mongolian is natural and fluent. Thorough coverage exceeding basic facts."
38,kazakh_cultural,gemini_3_pro,2,2,2,6,21.72,233,"Excellent response with detailed historical context about Jeltoqsan (December 1986 uprising in Almaty). Covers cause (Kunayev's replacement with Kolbin), protests, brutal crackdown, and consequences. Fluent Mongolian with no Kyrgyz markers. Complete and well-structured."
38,kazakh_cultural,grok_4.1,2,2,2,6,10.77,189,"Excellent response. Correctly identifies Jeltoqsan/December uprising in Almaty 1986, including key details: Kolbin replacing Kunayev, protests against Russification, casualties (2-3 official vs 100-300 actual), and aftermath. Language is fluent Mongolian. Thorough and accurate."
38,kazakh_cultural,deepseek_v3.2,2,2,2,6,16.2,126,"Excellent response. Correctly identifies the December 1986 Jeltoqsan uprising in Almaty, the Kunayev-Kolbin replacement, the protest nature, national awakening significance, and historical importance. Factually accurate, naturally fluent Mongolian, and thorough."
38,kazakh_cultural,llama_4_maverick,2,2,2,6,1.04,58,"Correct content: Jeltoqsan/December uprising in 1986 Kazakh SSR, mentions Kunaev replaced by Kolbin triggering Kazakh protests, notes it as precursor to independence. Fluent Mongolian. Thorough."
38,kazakh_cultural,qwen3,1,1,1,3,9.22,141,Severe date errors: '16-р сарын 16' (16th month) instead of 12-р сарын 16/17; '17-р сарын өдөр' (17th month). Wrong replacement name: says 'Медеуов' but correct is Gennady Kolbin (Геннадий Колбин). Core event (Jeltoqsan protests) correct. Fluency acceptable but awkward phrasing in places.
38,kazakh_cultural,aya_expanse,0,0,0,0,5.03,44,"Wrong language (garbled/mixed script, not Mongolian Cyrillic), wrong content (question asks about December 1986 Jeltoqsan protests, answer discusses 1990-1991 independence), complete fabrication"
39,kazakh_cultural,claude_opus_4.5,2,2,2,6,12.45,91,"Correct answer (Nur-Mubarak University), excellent Mongolian fluency, thorough with context details including location, founding year, and cooperative nature. Fully addresses the question."
39,kazakh_cultural,gpt_5.2,2,2,2,6,1.76,21,"Correct answer (Nur-Mubarak University), accurate location, natural Mongolian fluency, fully addresses question"
39,kazakh_cultural,gemini_3_pro,2,2,2,6,8.81,35,"Correct answer (Nur-Mubarak), natural Mongolian, thorough with location detail"
39,kazakh_cultural,grok_4.1,2,2,2,6,7.08,26,"Correct answer (Nur-Mubarak), natural Mongolian, good detail with location and founding year"
39,kazakh_cultural,deepseek_v3.2,2,2,2,6,5.24,38,"Correct answer (Nur-Mubarak Egyptian Islamic University), natural Mongolian, appropriately detailed with location info"
39,kazakh_cultural,llama_4_maverick,2,2,2,6,0.83,53,"Correct institution (Nur-Mubarak), fluent Mongolian, thorough with enrollment details"
39,kazakh_cultural,qwen3,0,1,0,1,8.93,110,Complete misunderstanding. Question asks for largest ISLAMIC institution in Kazakhstan (answer: SAMK/Muftiate or Nur-Mubarak University). Model discusses Buddhist institutions in Mongolia instead. Content is entirely off-topic despite being understandable Mongolian text.
39,kazakh_cultural,aya_expanse,0,0,0,0,8.82,82,"Wrong language (Kyrgyz, not Kazakh or Mongolian). Fabricated answer—'Nazaret' is not Kazakhstan's largest Islamic institution. Correct: SAMK/Muftiate or Nur-Mubarak University. Content about fishing/agriculture completely nonsensical."
40,kazakh_cultural,claude_opus_4.5,2,2,2,6,13.84,111,Excellent response. Correctly identifies Kerei as Middle zhuz in both Kazakh and Mongolian terms. Adds valuable cultural context about Kerei being one of the largest/most influential tribes and historical connections. Fluent Mongolian with proper table formatting. Fully addresses the question.
40,kazakh_cultural,gpt_5.2,2,2,2,6,5.36,53,Correct: Kerei → Middle zhuz. Fluent Mongolian with correct terminology. Thorough explanation including Orta zhuz classification and offer to clarify sub-clans. Fully addresses the question.
40,kazakh_cultural,gemini_3_pro,2,2,2,6,22.34,44,"Perfect answer: correctly identifies Kerei as Middle zhuz, provides context about the three zhuz system, and lists other Middle zhuz tribes. Natural Mongolian, culturally accurate."
40,kazakh_cultural,grok_4.1,2,2,2,6,9.64,51,"Correct answer (Orta zhuz/Middle zhuz), proper Mongolian fluency, provides helpful additional context about all three zhuz with examples. Fully addresses the question."
40,kazakh_cultural,deepseek_v3.2,0,2,1,3,11.81,105,"Completely wrong answer. Model says Kerei is from Uly (Senior) zhuz, but correct answer is Orta (Middle) zhuz. Fluency is natural Mongolian. Provides some zhuz detail but fundamentally incorrect."
40,kazakh_cultural,llama_4_maverick,2,2,2,6,0.62,20,"Correct answer (Middle/Orta zhuz), fluent Mongolian, fully addresses the question. Uses Mongolian phrasing naturally ('чи...байх нь ээ'). Accurately identifies Kerei as Middle zhuz, not Senior."
40,kazakh_cultural,qwen3,2,2,2,6,8.5,126,"Correct: Kerei belongs to Orta zhuz (Middle zhuz). Response is thorough, fluent in Mongolian, explains the three zhuz system clearly, lists the main branches of Orta zhuz, and provides cultural context. Fully addresses the question."
40,kazakh_cultural,aya_expanse,0,0,0,0,15.99,138,Response is completely garbled and unreadable. Text appears corrupted with nonsensical Mongolian phrases repeated. Cannot extract any meaningful answer. Fluency=0 because it's not coherent Mongolian. The correct answer is 'Middle zhuz/Orta zhuz' but this is not stated anywhere.
41,mongolian_cultural,claude_opus_4.5,2,2,2,6,31.68,255,"Excellent response with comprehensive detail on all three games, cultural significance, and well-structured explanation in fluent Mongolian. Covers all key aspects including historical context, competition formats, and societal importance."
41,mongolian_cultural,gpt_5.2,2,2,2,6,20.17,233,"Excellent response. Covers all three games (bökh, horse racing, archery), explains their deep cultural significance tied to nomadic life, military traditions, unity, and intergenerational transmission. Well-structured, fluent Mongolian, comprehensive detail."
41,mongolian_cultural,gemini_3_pro,2,2,2,6,22.95,257,"Excellent response. Accurate details on all three games (wrestling, horse racing, archery), culturally rich with specific terminology (zoodог шуудаг, түмний эх, эвэр нум), proper Mongolian fluency, thorough explanations of significance. Exceeds reference answer quality."
41,mongolian_cultural,grok_4.1,2,2,2,6,12.07,246,Excellent response. All three games correctly identified with accurate details. Culturally rich explanation of significance. Natural Mongolian fluency. Thoroughly addresses all parts of the question.
41,mongolian_cultural,deepseek_v3.2,2,2,2,6,17.1,133,"Excellent response. Correctly identifies the three manly games (wrestling, horse racing, archery) with culturally accurate Mongolian terms. Provides rich significance: historical origin, national pride, transmission of heritage, and spiritual/cultural symbolism. Addresses all parts thoroughly. Language is natural, fluent Mongolian with proper terminology."
41,mongolian_cultural,llama_4_maverick,2,2,2,6,2.27,199,"Excellent response. Correctly identifies the three manly games (horse racing, archery, wrestling) and provides culturally rich explanation of their significance in Mongolian society, tradition, and character development. Natural Mongolian, thorough coverage."
41,mongolian_cultural,qwen3,1,2,2,5,28.47,418,Wrong sport listed: 'суугаа байрнаас сум татах' (sitting archery) instead of 'сурын харваа' (standing archery). Otherwise excellent detail and cultural context. Fluent Mongolian.
41,mongolian_cultural,aya_expanse,0,0,0,0,10.66,97,"Complete fabrication. Answer should be: horse racing, archery, wrestling with cultural significance. Response is garbled, repetitive nonsense with broken Mongolian. Does not identify the three sports at all."
42,mongolian_cultural,claude_opus_4.5,2,2,2,6,36.54,336,"Excellent response with comprehensive detail, proper Mongolian, and rich cultural context including cosmology, symbolism, spatial divisions, and traditions. Far exceeds ground truth."
42,mongolian_cultural,gpt_5.2,2,2,2,6,54.37,587,"Exceptional response. Comprehensive coverage of ger structure (toono, bagana, uni, khana), spatial organization (khoimor, golomt, left/right sides), symbolism (cosmos model, fire as life center), and cultural practices. Natural Mongolian, well-structured with headings. Exceeds reference answer in depth and clarity."
42,mongolian_cultural,gemini_3_pro,2,2,2,6,26.02,322,"Excellent response with accurate structural details and deep symbolic explanation. Covers ger components (tono, uni, bagana, khana), materials, cosmological symbolism, and spatial organization. Natural Mongolian fluency throughout."
42,mongolian_cultural,grok_4.1,2,2,2,6,23.85,409,"Excellent response with comprehensive structural details and rich symbolic meaning. Covers cosmic symbolism, directional meanings, fire/toono significance, and numerical symbolism (108 knots, 9 layers). Goes beyond reference answer with specific measurements and table format. Fully in Mongolian with natural phrasing."
42,mongolian_cultural,deepseek_v3.2,2,2,2,6,18.14,151,"Excellent response. Covers structure (toono, uni, khana, door) and symbolism (center/fire, gender sides, north/honored guests, cosmology). Accurate terminology and culturally rich details. Fluent native Mongolian."
42,mongolian_cultural,llama_4_maverick,0,2,0,2,1.65,211,"Response completely misses the traditional ger structure. Discusses generic house symbolism (door, window, wall) instead of ger-specific elements (toono, uni, bagana, khana lattice walls, felt covering). No mention of cosmological symbolism, sacred numbers, colors, or actual ger architecture. Fluent Mongolian but factually wrong."
42,mongolian_cultural,qwen3,1,2,1,4,24.07,472,"Response is fluent Mongolian but focuses heavily on structural/functional details without deeply addressing symbolic/cosmological meanings (cosmos, sacred center, numbers, colors) emphasized in the ground truth. Missing key symbolic elements like toono=sun/portal, pillars=heaven-earth link, 9 as sacred number, orange/blue paint symbolism. Provides good structural description but incomplete on 'бэлгэдэл' (symbolism) aspect of the question."
42,mongolian_cultural,aya_expanse,0,0,0,0,19.16,135,"Complete gibberish/hallucination. Repeats nonsense words like 'эргээсийн тогтвол, саяхнаасын' that do not exist in Mongolian. No actual content about ger structure or symbolism. Model failure/breakdown."
43,mongolian_cultural,claude_opus_4.5,2,2,2,6,21.62,164,"Excellent response with deep cultural insight. Covers spiritual connection to nature, shamanic traditions, cultural identity, and social roles. Well-organized with philosophical depth. Fluency is natural Mongolian. Completeness is thorough with multiple dimensions covered."
43,mongolian_cultural,gpt_5.2,2,2,2,6,25.71,312,"Excellent response: culturally nuanced, comprehensive coverage of khöömei's role in Mongolian identity (nature connection, meditation, cultural preservation, nomadic spatial awareness, social ritual, musical aesthetics), fluent native Mongolian, well-structured with numbered sections, exceeds reference answer in depth"
43,mongolian_cultural,gemini_3_pro,2,2,2,6,21.42,222,"Excellent response with culturally rich detail, correct language, natural phrasing, and thorough coverage of throat singing's role in Mongolian identity."
43,mongolian_cultural,grok_4.1,2,2,2,6,15.13,240,"Excellent response. Covers spiritual connection to nature/landscape, shamanic/ancestral ties, national pride (UNESCO), emotional expression, cultural identity. Well-structured, natural Mongolian, fully addresses the question. Minor differences in emphasis from reference but all core themes present."
43,mongolian_cultural,deepseek_v3.2,1,2,1,4,16.09,124,"Fluency is natural Mongolian. However, the response discusses 'хоолойн дуу' (throat singing/vocal music generally) in broad terms about Mongolian music culture, but does NOT specifically address khöömei (хөөмий) throat singing techniques, the four/five types, the connection to nature sounds, or its unique role in Mongolian identity as specified in the answer key. The answer key emphasizes khöömei as mimicking wind/water/animals, spiritual connection to nomadic landscape, and being a living expression of heritage. This response is more generic about vocal music/long songs. Partially correct but missing the specific cultural depth required."
43,mongolian_cultural,llama_4_maverick,0,2,0,2,1.96,168,"Model completely misunderstood the question. Q43 asks about throat singing (хөөмий) and its role in Mongolian identity, but the model interpreted it as asking about 'the human voice' in general. The response discusses long song (уртын дуу) and vocal techniques generically, missing all key content: khöömei as throat singing, mimicking nature sounds, spiritual connection to landscape, cultural heritage symbol. Despite fluent Mongolian, content is entirely off-topic."
43,mongolian_cultural,qwen3,1,2,2,5,22.75,355,"Fluent Mongolian, thorough response with good cultural depth. However, focuses on 'хоолойн дуу' (throat singing/long song) generally rather than specifically on 'хөөмий' (overtone throat singing). Answer sheet emphasizes хөөмий's unique technical aspects (multiple simultaneous pitches, 4 types, mimicking nature sounds) and its role in national identity. Response is culturally informed but misses key technical specifics of хөөмий."
43,mongolian_cultural,aya_expanse,0,0,0,0,16.8,122,Complete gibberish. Text is unreadable garbled Mongolian-like characters with nonsensical repetition. Does not address throat singing (хөөмий) at all. Zero content value.
44,mongolian_cultural,claude_opus_4.5,0,2,0,2,12.2,89,Model refuses to answer despite ground truth confirming Hazara restaurant near Bohiin Orgoo. Fluent Mongolian but 0/0/0 per rule 3.
44,mongolian_cultural,gpt_5.2,1,2,1,4,7.08,88,"Response is in correct language (Mongolian) and fluent. However, it does not provide the specific answer from the answer sheet (Hazara restaurant with exact address). Instead gives vague confirmation and asks clarifying questions. Partially correct as it confirms Indian restaurants exist near the area, but lacks the precise detail expected."
44,mongolian_cultural,gemini_3_pro,2,2,2,6,138.36,82,"Accurate: Hazara is correctly identified near Bökh Örgöö (Q44 ground truth). Also mentions Namaste. Well-written Mongolian, fully addresses the question with helpful detail."
44,mongolian_cultural,grok_4.1,0,2,1,3,11.27,76,"Fluent Mongolian, but completely wrong answer. Ground truth says Hazara restaurant near Bokhiin Orgoo. Model says there's NO Indian restaurant nearby, then suggests restaurants 1-2km away. Factual hallucination."
44,mongolian_cultural,deepseek_v3.2,0,2,1,3,9.85,75,"Model refuses to answer with specific info, then gives generic suggestions. Ground truth: Hazara - BZD - 6 khoroo, Ulaanbaatar 13373. Fluent Mongolian but factually incorrect (doesn't provide the answer)."
44,mongolian_cultural,llama_4_maverick,0,2,1,3,0.83,32,"Fluent Mongolian. Hallucination: answer sheet says Hazara at BZD-6 khoroo, model invented 'Maharaja Indian Restaurant' with false details. Accuracy=0 for fabrication."
44,mongolian_cultural,qwen3,0,2,1,3,7.07,133,"Model fabricated 3 restaurants (Taj Mahal, Ganges, Namaste) instead of stating correct answer: Hazara at BZD 6-khoroo. Model also mislocates Bökh Orgoo (says Sukhbaatar Sq north, should be near 6-khoroo). Fluency is perfect native Mongolian. Partial completeness for attempting to answer but wrong content."
44,mongolian_cultural,aya_expanse,0,0,0,0,7.79,68,"Complete hallucination with garbled, nonsensical Mongolian. Repeats meaningless phrases. Answer sheet says 'Hazara - BZD - 6 khoroo, Ulaanbaatar 13373'. Model fabricates incoherent content instead of providing restaurant name/location or saying it doesn't know."
45,mongolian_cultural,claude_opus_4.5,2,2,2,6,6.67,40,"Perfect answer with correct date (April 13, 2012) and excellent additional context about the significance of the arrest. Natural Mongolian."
45,mongolian_cultural,gpt_5.2,1,2,2,5,1.23,10,"Date is April 12 instead of correct April 13, 2012. Otherwise fluent Mongolian, complete answer."
45,mongolian_cultural,gemini_3_pro,2,2,2,6,9.94,16,"Perfect answer: correct date (April 13, 2012), natural Mongolian, includes helpful context identifying him as Mongolia's 3rd president"
45,mongolian_cultural,grok_4.1,2,2,2,6,2.38,23,Perfect answer with additional context about anti-corruption charges
45,mongolian_cultural,deepseek_v3.2,0,2,0,2,2.95,18,Model refused to answer. Fluency is natural Mongolian but provides no information. Clear refusal = 0/0/0 per scoring rules.
45,mongolian_cultural,llama_4_maverick,0,2,2,4,0.32,9,"Wrong date. Correct: April 13, 2012. Model said July 11, 2013. Fluency and completeness are fine but factually incorrect."
45,mongolian_cultural,qwen3,1,2,1,4,4.72,42,"Date incorrect: says April 10-11, answer sheet says April 13. Rest is correct context. Fluent Mongolian."
45,mongolian_cultural,aya_expanse,0,0,0,0,2.46,22,"Garbled/broken Mongolian, major factual errors (birth date 1956, death 2023, age 77 all wrong), completely wrong answer for arrest date"
46,mongolian_cultural,claude_opus_4.5,0,2,0,2,7.84,42,Model refused to answer citing knowledge cutoff. Perfect Mongolian fluency but 0/0 for accuracy and completeness per rule 3.
46,mongolian_cultural,gpt_5.2,0,2,0,2,7.28,99,"Model refuses to answer, claims insufficient data despite correct answer being SP Falcons. Fluent Mongolian but completely fails task."
46,mongolian_cultural,gemini_3_pro,1,2,1,4,22.16,37,"Partially correct: correctly identifies SP Falcons as recent champions but incorrectly states 24/25 season is incomplete/not started when answer sheet says SP Falcons won 24/25. Fluent Mongolian, natural phrasing. Addresses question but disputes the premise."
46,mongolian_cultural,grok_4.1,0,2,1,3,6.25,47,"Model refuses to answer, claiming the 24/25 season is unfinished as of Oct 2024. Correct answer is SP Falcons. Fluent Mongolian but factually wrong."
46,mongolian_cultural,deepseek_v3.2,0,2,2,4,3.22,17,"Answer is factually incorrect - claims Athletic 220 won, but correct answer is SP Falcons. Fluent natural Mongolian. Thorough response with full details."
46,mongolian_cultural,llama_4_maverick,0,2,1,3,1.14,39,"Wrong answer: claims Ulaanbaatar won, but correct answer is SP Falcons. Fluent Mongolian but factually incorrect."
46,mongolian_cultural,qwen3,0,2,1,3,2.57,34,"Model refuses to answer, claims season not finished. Actually SP Falcons won 24/25 season. Fluent Mongolian but factually incorrect."
46,mongolian_cultural,aya_expanse,0,1,0,1,3.39,30,"Wrong answer: says 'Khanar' won, correct answer is 'SP Falcons'. Text is garbled/awkward Mongolian (e.g., 'өмрөгчүн', unclear phrasing). Completely incorrect factually."
47,mongolian_cultural,claude_opus_4.5,1,2,2,5,10.51,90,"Partially correct: states 150-170 vs correct ~186, but close enough for partial credit. Fluent Mongolian, thorough response with tables and references."
47,mongolian_cultural,gpt_5.2,0,2,0,2,5.23,74,Model refuses to answer and redirects to MSE website instead of providing the expected number (~186). Fluent Mongolian but fails accuracy/completeness.
47,mongolian_cultural,gemini_3_pro,2,2,2,6,188.51,88,"Highly accurate (180 vs reference 186 is within expected variance for stock exchanges), fluent native Mongolian, thorough with additional relevant context about MSE categories and why numbers fluctuate"
47,mongolian_cultural,grok_4.1,2,2,2,6,9.55,48,"Response gives 193, answer key says ~186. These are close enough for a dynamic market statistic from different reference dates. Model provides authoritative data with helpful context (date, source website). Mongolian is fluent and natural. Fully addresses the question."
47,mongolian_cultural,deepseek_v3.2,1,2,1,4,17.32,131,"Model gives 200+ instead of ~186, which is a reasonable estimate but not exact. Fluency is natural Mongolian. Completeness partial: provides context but hedges instead of direct answer. Should be more concise for this factual question."
47,mongolian_cultural,llama_4_maverick,1,2,2,5,0.62,35,"Answer is 244 vs ground truth ~186. Partially correct but outdated or different source. Fluent Mongolian, thorough response with caveat about changes over time."
47,mongolian_cultural,qwen3,0,2,2,4,5.13,93,"Wrong number: answer says ~240+ companies when correct is ~186. However, fluency is native-level Mongolian and response is thorough with examples and source citation."
47,mongolian_cultural,aya_expanse,0,0,0,0,32.37,251,Completely broken output with severe text corruption and repetitive garbled phrases. Claims 1000 companies vs correct ~186. Mongolian text has major encoding/generation errors making it unreadable. Total failure.
48,mongolian_cultural,claude_opus_4.5,2,2,2,6,9.02,60,"Perfect answer. Correctly identifies Töv aimag as the surrounding province, provides proper Mongolian spelling, and adds helpful context about neighboring provinces without detracting from the core answer."
48,mongolian_cultural,gpt_5.2,2,2,2,6,1.65,15,Perfect answer with additional clarification that Ulaanbaatar is completely surrounded on all sides by Töv aimag. Natural Mongolian phrasing.
48,mongolian_cultural,gemini_3_pro,2,2,2,6,8.69,8,Perfect answer with correct information and natural Mongolian phrasing
48,mongolian_cultural,grok_4.1,2,2,2,6,4.2,30,"Correct answer (Төv/Төв aймаг), natural Mongolian fluency, thorough explanation with extra detail about surrounding sums."
48,mongolian_cultural,deepseek_v3.2,2,2,2,6,5.85,37,Perfect answer with helpful additional detail that Ulaanbaatar is administratively separate despite being geographically surrounded by Töv aimag.
48,mongolian_cultural,llama_4_maverick,2,2,2,6,0.36,7,"Perfect answer: correct (Töv/Төв), natural Mongolian phrasing, fully addresses the question."
48,mongolian_cultural,qwen3,2,2,2,6,2.47,25,Perfect answer with helpful context explaining UB's administrative status
48,mongolian_cultural,aya_expanse,0,0,0,0,11.37,111,"Completely incorrect and garbled. Question asks which aimag surrounds UB (answer: Töv). Response is nonsensical, mixing unrelated aimags, districts, incomprehensible text ('эрдэмт хүрэлтээ жерлэсэн'), wrong administrative units. Fluency=0 due to broken/incoherent Mongolian. Total hallucination."
49,mongolian_cultural,claude_opus_4.5,2,2,2,6,20.9,151,"Excellent response. Accurately describes khuushuur preparation (dough, meat filling, half-moon shape, fried in oil) and correctly identifies Naadam as the primary occasion, with additional mentions of Tsagaan Sar and everyday consumption. Well-structured with tables and clear formatting. Fully answers both parts of the question in fluent, natural Mongolian."
49,mongolian_cultural,gpt_5.2,2,2,2,6,22.85,279,"Excellent response with detailed recipe steps and thorough explanation of when Khuushuur is eaten, especially highlighting Naadam as the key occasion. Culturally accurate and well-structured."
49,mongolian_cultural,gemini_3_pro,2,2,2,6,25.0,259,Excellent response. Provides detailed recipe with ingredients and step-by-step instructions. Correctly identifies Naadam as the main occasion for eating khuushuur. Culturally accurate and comprehensive. Fluent Mongolian throughout.
49,mongolian_cultural,grok_4.1,2,2,2,6,9.95,258,"Excellent response. Provides detailed recipe with ingredients, step-by-step instructions, and correctly identifies Naadam as primary eating occasion. Culturally accurate and thorough."
49,mongolian_cultural,deepseek_v3.2,1,2,1,4,10.15,97,"Partial accuracy: describes frying in oil and eating in winter (correct), but omits key details like the half-circle shape, animal fat (traditional), and Naadam (most important eating occasion). Fluency is natural Mongolian. Completeness is partial—addresses both how and when but lacks depth."
49,mongolian_cultural,llama_4_maverick,0,2,1,3,1.3,101,"Completely wrong dish described. Response describes 'бууз' (steamed dumplings boiled in water) not хуушуур (fried meat pastry). Хуушуур is fried in oil/fat, not boiled. Correct answer: ground beef/onion in dough circle, folded/pinched, fried in oil/tallow, staple at Naadam. Fluent Mongolian but factually incorrect content."
49,mongolian_cultural,qwen3,0,2,0,2,13.63,254,"Completely wrong dish. Response describes 'huushuur' made from sheep organs/tripe (цав) as a stew, but actual huushuur is fried meat pastries eaten at Naadam. Perfect Mongolian fluency but total factual error."
49,mongolian_cultural,aya_expanse,0,0,0,0,13.43,112,Complete gibberish. Incoherent repetitive text with no actual information about khuushuur preparation or consumption. Appears to be broken output.
50,mongolian_cultural,claude_opus_4.5,0,2,2,4,12.71,108,"Fluent Mongolian, thorough explanation, but WRONG answer. Reference says 4th rank is 'State Lion/Улсын арслан' with 1 win at National Naadam. Model says 'Арslан' (Lion) with 2 wins required. These are different ranks in the hierarchy—model appears to describe a lower rank or confuses the system."
50,mongolian_cultural,gpt_5.2,0,2,1,3,5.33,58,"Wrong answer: gave Харцага (Hawk, 9 wins) instead of Улсын арслан (State Lion, 1 win). Fluent Mongolian, partially addresses question structure but factually incorrect."
50,mongolian_cultural,gemini_3_pro,1,2,1,4,24.62,25,Wrong title (Улсын Заан instead of Улсын арслан). Response incomplete/cut off. No provision mentioned. Fluent Mongolian but factually incorrect.
50,mongolian_cultural,grok_4.1,0,2,1,3,11.27,102,"Wrong answer: says 'Улсын сайн бөх' (6th-9th rank) instead of 'Улсын арслан' (4th rank, 1 Naadam win). Fluent Mongolian with detailed explanation, but factually incorrect."
50,mongolian_cultural,deepseek_v3.2,1,2,2,5,18.03,150,"Fluency is excellent and native-like. Completeness is thorough with detailed explanation. However, Accuracy = 1 because the answer sheet states 'State Lion, 1 win in the National Naadam Wrestling' but the model says 'TWO wins required' (хоёр удаа түрүүлэх). The model provides extensive detail about the rank but contradicts the ground truth on the core requirement."
50,mongolian_cultural,llama_4_maverick,0,2,1,3,2.58,306,"Wrong title: model says 4th is 'Uran' (a nachlin sub-rank), but correct answer is 'State Lion' (Ulsyn Arslan). Requirement wrong: model says 3 wins at Naadam, correct is 1 win. Fluent Mongolian but factually incorrect and overly verbose."
50,mongolian_cultural,qwen3,0,2,2,4,9.53,202,Response is fluent Mongolian and thorough but completely wrong. Claims 4th rank is 'Zaан' (Elephant) with complex requirements. Ground truth: 4th rank is 'Улсын арслан' (State Lion) requiring 1 win at National Naadam. Major factual error.
50,mongolian_cultural,aya_expanse,0,0,0,0,15.89,151,"Complete fabrication. Response is garbled, repetitive nonsense with no factual content. Correct answer is 'Улсын арслан' (State Lion), requiring 1 Naadam win. Model produced incomprehensible, hallucinatory text instead."
