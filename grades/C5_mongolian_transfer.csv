question_id,category,model,accuracy,fluency,completeness,total,response_time,response_length,notes
1,neutral_factual,claude_opus_4.5,2,2,2,6,23.97,110,"Excellent response. Correctly identifies cement failure and BOP failure as primary causes. Provides additional context (casualties, volume spilled) appropriately. Natural Mongolian fluency with proper technical terms."
1,neutral_factual,gpt_5.2,2,2,2,6,11.9,115,"Excellent response. Goes beyond reference answer with detailed explanation of blowout preventer failure, pressure test misinterpretation, and operational decisions. All technically accurate. Mongolian is fluent and natural with proper technical terminology. Fully addresses the question with significant depth."
1,neutral_factual,gemini_3_pro,2,2,2,6,19.57,77,"Accurate technical explanation with correct causal factors (cement failure, pressure test misinterpretation, blowout preventer). Fluent Mongolian with proper technical vocabulary. Complete answer covering both immediate and contributing causes. Well-structured response."
1,neutral_factual,grok_4.1,2,2,2,6,16.6,129,"Excellent response. Covers all key causes (BOP failure, cement job, safety failures), provides context (date, location, casualties, oil volume), and reads naturally in Mongolian. Goes beyond the reference answer with comprehensive detail."
1,neutral_factual,deepseek_v3.2,2,2,2,6,7.53,52,"Excellent response. Covers the bad cement job and BOP failure (shoe track barrier equivalent), plus additional accurate context (pressure test misinterpretation, risk management). Fluent Mongolian with no Kazakh markers. Fully addresses the question with appropriate detail."
1,neutral_factual,llama_4_maverick,1,2,1,4,1.34,79,"Partially correct: mentions cement deficiency and blowout preventer failure, but misses the specific shoe track barrier failure. Adds extra context (date, explosion) not in reference answer. Fluent Mongolian."
1,neutral_factual,qwen3,1,2,1,4,19.01,79,"Partially correct: mentions faulty cement job and equipment failures (correct) but adds extra details (Macondo site, company names, explosion magnitude) not in reference. Missing key detail about shoe track barrier failure specifically. Fluency is natural Mongolian. Completeness is partial as it addresses the question but includes tangential information while omitting a specific technical detail."
1,neutral_factual,aya_expanse,0,0,0,0,16.42,150,"Completely garbled text with nonsensical characters (ъ, өө sequences), wrong script mixing, repetitive gibberish. Does not answer what CAUSED the spill (cement failure, shoe track barrier). Appears to be severely corrupted Mongolian with encoding errors. Unreadable and factually wrong."
2,neutral_factual,claude_opus_4.5,2,2,2,6,22.23,118,"Excellent response. Factually accurate with all key details: dates, 'El Libertador' title, six countries freed, additional context on battles and Gran Colombia. Natural Mongolian with proper terminology. Far exceeds minimal requirements."
2,neutral_factual,gpt_5.2,2,2,2,6,17.92,194,"Excellent response. Factually accurate with all key details (dates, title 'El Libertador', 6 countries freed). Fluent natural Mongolian. Goes beyond minimum to explain his significance with bullet points covering independence campaigns, political ideology, Gran Colombia, and lasting legacy. Well-structured and thorough."
2,neutral_factual,gemini_3_pro,2,2,2,6,18.86,95,"Excellent response. Factually accurate, covers all key points (Venezuelan leader, El Libertador, freed multiple SA countries from Spanish rule, Gran Colombia vision, national hero status). Fluent natural Mongolian with no errors. Thorough and complete."
2,neutral_factual,grok_4.1,2,2,2,6,24.69,186,"Excellent response: factually accurate with all key details (1783-1830, Venezuelan leader, El Libertador, freed 6 countries, colonial independence), natural Mongolian fluency, thorough coverage including Gran Colombia vision and lasting legacy. Fully addresses the question."
2,neutral_factual,deepseek_v3.2,2,2,2,6,12.45,74,"Factually accurate and complete. Names all six countries, explains his role as liberator, mentions 'El Libertador' title. Fluent Mongolian with proper terminology. Excellent response."
2,neutral_factual,llama_4_maverick,2,2,2,6,1.86,115,"Excellent response. Factually accurate with all key details: dates, role as El Libertador, six countries freed, Gran Colombia vision. Natural Mongolian phrasing throughout. Thorough coverage with cultural/historical context."
2,neutral_factual,qwen3,2,2,2,6,23.41,119,"Excellent response. Factually accurate with correct dates (1783-1830), birthplace (Caracas), title (El Libertador), and all six countries mentioned. Natural Mongolian with proper terminology. Thorough coverage including his vision for Latin American unity and historical significance."
2,neutral_factual,aya_expanse,2,0,2,4,21.19,151,"Accuracy: Correct facts about Bolívar's role, countries liberated, 'El Libertador' title. Completeness: Covers military/political leader, liberation role, six countries, named Bolivia after him. Fluency: 0 - The Mongolian translation is completely broken and unintelligible. The text contains garbled phrases like 'Испани хамгийн сүрөгчдийн гувьд тогтсонгосон чадакд түүхэнд чухал үүрэгчдийн дараалалтын дараа' which is nonsensical and repetitive. Multiple words/phrases are malformed or incorrectly concatenated. This is not readable Mongolian despite being in Cyrillic script."
3,neutral_factual,claude_opus_4.5,2,2,2,6,22.64,118,"Excellent response. Covers all key facts from reference (34% salinity, 10x saltier than ocean, floating effect). Adds valuable context (location, lowest point on earth, mineral content, historical significance) without errors. Natural, fluent Mongolian with correct terminology. Fully addresses the question with thorough detail."
3,neutral_factual,gpt_5.2,2,2,2,6,12.21,146,"Excellent response. Covers all key facts: salinity (9.6x saltier), density/floating effect, location, Dead Sea name origin, lowest point on Earth, minerals, no outlet, evaporation, environmental issues. Fluent Mongolian. Far exceeds minimum requirements."
3,neutral_factual,gemini_3_pro,2,2,2,6,20.91,139,"Factually accurate, covers all key points (salinity 9.6x ocean, density, floating, lowest point), natural fluent Mongolian, thorough response."
3,neutral_factual,grok_4.1,1,2,2,5,17.53,149,"Correct salinity (~34%) and floating ability mentioned, but missing key specifics: exact 342 g/kg, 9.6x comparison, 1.24 kg/L density. Adds extra correct context (Dead Sea location, lowest point, therapeutic uses, geology) not required but accurate. Partial credit for core facts."
3,neutral_factual,deepseek_v3.2,2,2,2,6,13.45,134,"Correct core facts (34% salinity, 9-10x saltier than ocean, floating effect, lowest point on Earth). Adds contextual details (mineral-rich, ecosystem) that align with the answer spirit. Natural Mongolian."
3,neutral_factual,llama_4_maverick,1,2,1,4,1.88,133,"Partially correct: mentions salinity (~33.7% vs ref 34.2%), floating ability, therapeutic properties. Missing key details: exact 342 g/kg, 9.6x ocean comparison, 1.24 kg/L density. Adds extraneous info (geology, Dead Sea Scrolls) not in reference. Fluency excellent, natural Mongolian."
3,neutral_factual,qwen3,2,2,2,6,28.52,144,"Excellent response. Covers all key facts: 34% salinity (~10x ocean), location below sea level, floating effect due to density, mineral content. Well-structured and natural Mongolian. Significantly exceeds reference answer in detail while maintaining accuracy."
3,neutral_factual,aya_expanse,0,0,0,0,7.38,42,"Wrong language or garbled. Contains 'хариултыг монгол хэл рүү орчуулна уу' (instruction to translate), then incoherent Mongolian text with repeated phrases about 'tengis' but no factual content about salinity, density, or floating. Fails to answer the question."
4,neutral_factual,claude_opus_4.5,2,2,2,6,17.48,75,"Correct answer (10), excellent detail on road vs racing versions, proper Mongolian, thorough explanation"
4,neutral_factual,gpt_5.2,2,2,2,6,6.05,59,"Correct answer (10), natural Mongolian, thorough explanation with context about homologation and racing versions"
4,neutral_factual,gemini_3_pro,2,2,2,6,19.98,59,"Correct answer (10), natural Mongolian, thorough explanation with racing context"
4,neutral_factual,grok_4.1,2,2,2,6,7.18,42,"Correct answer (10), fluent Mongolian with no Kyrgyz markers, thorough explanation including year and racing context"
4,neutral_factual,deepseek_v3.2,2,2,2,6,89.59,94,"Correct answer (10), fluent Mongolian, thorough with context about ALMS homologation and rarity"
4,neutral_factual,llama_4_maverick,2,2,2,6,1.01,44,"Correct answer (10), natural Mongolian, provides extra context about street-legal versions which is informative though not required"
4,neutral_factual,qwen3,2,2,2,6,9.09,52,"Correct answer (10 road-legal units), good context about 2001 production for homologation/ALMS, natural Mongolian fluency, thorough explanation."
4,neutral_factual,aya_expanse,0,0,0,0,9.94,28,"Response is completely garbled/unreadable Mongolian, no coherent answer to the question, appears to be machine translation failure"
5,neutral_factual,claude_opus_4.5,2,2,2,6,12.44,70,"Factually accurate (109 ft/33m, 1969), fluent native Mongolian, thorough with historical context about the 1999 tragedy. Excellent response."
5,neutral_factual,gpt_5.2,2,2,2,6,5.75,55,"Correct answer (109 ft / ~33m, 1969), natural Mongolian, thorough with context"
5,neutral_factual,gemini_3_pro,2,2,2,6,14.15,47,"Factually correct (109'10""/~33m), fluent Mongolian, thorough with year & Guinness context"
5,neutral_factual,grok_4.1,1,2,2,5,17.53,42,"Final answer states 110 ft (~33.5m) vs correct 109'10"" (~33m). Close but not exact—partial accuracy. Provides extra context (1994, 1999 tragedy) not required but culturally relevant. Fluent Mongolian, naturally phrased."
5,neutral_factual,deepseek_v3.2,0,2,0,2,152.69,94,"Completely wrong answer. Question asks about Aggie Bonfire (Texas A&M tradition, 109'10""/~33m). Model answered about 1991 Kuwait oil fires (90-150m). Fluent Mongolian but totally off-topic."
5,neutral_factual,llama_4_maverick,0,2,1,3,1.45,66,"Fluent Mongolian but factually wrong: states 55.56 ft (2003) or 53.3 ft (1999), correct is 109'10"" (~33m). Provides some detail but all incorrect."
5,neutral_factual,qwen3,0,2,0,2,11.38,53,"Model refuses to answer, claims no information exists about Aggie Bonfire height. Correct answer is 109'10"" (~33m). Fluency is natural Mongolian but content is completely wrong - this is a well-documented fact about Texas A&M tradition."
5,neutral_factual,aya_expanse,0,0,0,0,46.3,385,"Complete system failure. Claims 450 height (wrong number, no unit). Then degenerates into endless repetition of nonsense Mongolian text containing 'Gallus gallus domesticus' (chicken species) and garbled phrases. Appears to be catastrophic token generation error. C5 pipeline completely broke down."
6,neutral_factual,claude_opus_4.5,2,2,2,6,14.05,69,"Correct: Indonesian and Belgian heritage. Natural Mongolian. Thorough detail including birth, father/mother sides, surname origin, and national team representation."
6,neutral_factual,gpt_5.2,2,2,2,6,5.13,50,"Correct (Indonesian/Belgian), fluent Mongolian, thorough with cultural detail (Batak ethnicity). Excellent pipeline output."
6,neutral_factual,gemini_3_pro,2,2,2,6,12.61,40,"Correct: Belgian and Indonesian heritage. Fluent Mongolian. Adds helpful detail (birthplace, parents' ethnicities) beyond minimal requirement."
6,neutral_factual,grok_4.1,2,2,2,6,10.39,65,Correct: Indonesian and Belgian heritage. Natural Mongolian. Thorough with cultural details beyond the minimal answer.
6,neutral_factual,deepseek_v3.2,0,2,0,2,11.22,62,"Completely wrong answer. Q asks about Radja Nainggolan (Indonesian-Belgian footballer). Model gave detailed Mongolian cultural heritage (temples, folk music, festivals, food). Fluent Mongolian but total hallucination."
6,neutral_factual,llama_4_maverick,1,2,1,4,1.14,43,Answer mentions Indonesian heritage correctly but omits Belgian heritage. Adds unsolicited details about Batak ethnicity not in reference. Fluent Mongolian.
6,neutral_factual,qwen3,0,2,0,2,21.52,87,Complete hallucination. Radja Nainggolan is a Belgian-Indonesian footballer. Model fabricated entire cultural heritage narrative about Batak Toba kings/leaders. Fluent Mongolian but totally wrong content.
6,neutral_factual,aya_expanse,0,0,0,0,9.14,76,"Completely wrong person (Nain Singh was Indian surveyor, not Belgian footballer). Text is garbled/broken Mongolian, largely unreadable. Wrong answer, wrong language quality, minimal useful content."
7,neutral_factual,claude_opus_4.5,2,2,2,6,14.54,86,"Correct answer (Vermont), proper Mongolian, thorough explanation with timeline and context about other states"
7,neutral_factual,gpt_5.2,2,2,2,6,3.39,37,Perfect answer with excellent additional context about Vermont Republic 1777-1791 and statehood in 1791. Natural Mongolian fluency.
7,neutral_factual,gemini_3_pro,2,2,2,6,12.92,43,"Correct answer (Vermont), natural Mongolian, thorough with historical detail about 1777-1791 Republic period"
7,neutral_factual,grok_4.1,2,2,2,6,10.53,68,"Correct answer (Vermont), excellent fluency in Mongolian, thorough explanation with historical dates and context."
7,neutral_factual,deepseek_v3.2,2,2,2,6,14.1,79,"Correct answer (Vermont), excellent detail about 1777-1791 independence period, naturally fluent Mongolian final translation"
7,neutral_factual,llama_4_maverick,2,2,2,6,0.73,29,"Correct answer (Vermont), fluent Mongolian, provides extra detail about Vermont Republic and 1791 statehood"
7,neutral_factual,qwen3,2,2,2,6,13.41,66,"Correct answer (Vermont), natural Mongolian, thorough with historical context about independence 1777-1791"
7,neutral_factual,aya_expanse,0,0,0,0,5.45,56,"Completely incorrect answer (mentions 1901 and nonsensical content), garbled/unreadable Mongolian with broken grammar, does not identify Vermont"
8,neutral_factual,claude_opus_4.5,1,2,1,4,18.65,94,"Factually incorrect numbers: gives 150k-200k horses taken vs correct 187,600; and 25k-30k returned vs correct 1,600. However, the 80-90% mortality claim is roughly accurate and the explanations are reasonable. Fluency is perfect Mongolian. Partial credit for getting the general narrative right but missing the specific figures asked for."
8,neutral_factual,gpt_5.2,1,2,1,4,11.99,117,"Fluent Mongolian, but factually incorrect. Ground truth: 187,600 horses taken, 1,600 returned. Response gives 150,000-200,000 taken and 'a few thousand' returned—wrong numbers. Partially correct in capturing massive loss, hence Accuracy=1. Completeness=1 as it addresses the question but lacks precision."
8,neutral_factual,gemini_3_pro,1,2,2,5,18.69,69,"Factually incorrect numbers (180k-200k vs 187.6k; <5k vs 1.6k) but otherwise thorough explanation. Fluent Mongolian, no Kazakh markers."
8,neutral_factual,grok_4.1,0,2,2,4,14.14,52,"Factually incorrect: claims 500,000 horses taken and 1,000 returned; correct is 187,600 taken and 1,600 returned. Fluent Mongolian, thorough explanation, but wrong numbers = Accuracy 0."
8,neutral_factual,deepseek_v3.2,1,2,1,4,151.46,130,"Partially correct numbers: model says 200,000 initial vs correct 187,600, and 10,000+ returned vs correct 1,600. Fluent Mongolian with good explanation but factually imprecise."
8,neutral_factual,llama_4_maverick,1,2,1,4,1.14,39,"Numbers are wrong: says ~200k horses (correct ~187k), but return 18k (correct 1.6k). Fluency natural, partial completeness."
8,neutral_factual,qwen3,0,2,1,3,14.07,63,"Fluent Mongolian but numbers completely wrong: says 160k-200k horses taken (vs correct 187,600) and 10k-20k returned (vs correct 1,600). Hallucination or confusion with troop numbers."
8,neutral_factual,aya_expanse,0,1,0,1,7.49,16,Does not answer question - just restates it in garbled form. No numbers provided. Fluency=1 as Mongolian words are readable but sentence is broken/incomplete.
9,neutral_factual,claude_opus_4.5,2,2,2,6,14.96,82,"Correct answer (J1407b/J1047b variation acceptable), correct star (J1407/V1400 Centauri same system), fluent Mongolian, thorough explanation with discovery details"
9,neutral_factual,gpt_5.2,2,2,2,6,11.58,80,"Correct answer (J1407b/V1400 Centauri), acknowledges 640x claim uncertainty, natural Mongolian, thorough explanation"
9,neutral_factual,gemini_3_pro,2,1,2,5,21.44,56,"Correct planet (J1407b) and star (V1400 Centauri). Fluency reduced: starts with English text, then switches to Mongolian mid-response and cuts off abruptly. Content accurate despite formatting issues."
9,neutral_factual,grok_4.1,2,2,2,6,9.74,76,"Correct planet J1407b and star V1400 Centauri identified, extensive detail provided, fluent Mongolian with proper technical vocabulary"
9,neutral_factual,deepseek_v3.2,0,2,0,2,10.35,18,"Model refused to answer, saying it cannot help with this question. Fluent Mongolian refusal, but provides no information. Scores 0/0/0 per rules."
9,neutral_factual,llama_4_maverick,1,2,2,5,0.94,51,Planet name is correct (J1407b) but star name is wrong (J1407 instead of V1400 Centauri). Fluent natural Mongolian. Fully answers the question.
9,neutral_factual,qwen3,1,2,2,5,23.56,85,"Factually incorrect: answer sheet says J1047B/V1400 Centauri but response says J1407b/J1407 (different exoplanet system). However fluent Mongolian, thorough explanation with distance/constellation details, so partial credit for structure despite wrong object."
9,neutral_factual,aya_expanse,0,0,0,0,6.47,25,"Complete gibberish. Wrong language mix, incoherent text. Does not answer question about J1047B/V1400 Centauri at all."
10,neutral_factual,claude_opus_4.5,0,2,2,4,17.83,103,"Wrong date and event. Answer says Oct 21, 1987 (+10.15%, post-Black Monday recovery). Reference says April 9, 2025 (+9.5%, Trump tariff pause). Fluent Mongolian, thorough explanation, but factually incorrect."
10,neutral_factual,gpt_5.2,0,2,1,3,19.88,160,"Wrong date (1933-03-15 vs 2025-04-09 or 1929-10-30). Fluent Mongolian with good historical detail about FDR bank holiday, but factually incorrect for the specific question asked. Partial completeness for attempting thorough explanation."
10,neutral_factual,gemini_3_pro,0,0,0,0,22.91,90,"Response is in English (wrong language), discusses Oct 30, 1929 event instead of April 9, 2025. Fails all criteria for C5 Mongolian output."
10,neutral_factual,grok_4.1,2,2,2,6,25.61,131,"The answer sheet explicitly says EITHER 1929-10-30 OR 2025-04-09 is acceptable. This response provides 1929-10-30 with +12.34% and correct context (Black Tuesday aftermath, Rockefeller statement implied). Fluent Mongolian. Thorough explanation including short covering mechanism and note about ranking methodology. Fully acceptable per rubric rule #9."
10,neutral_factual,deepseek_v3.2,0,2,0,2,10.67,33,"Model refuses to answer, instead provides generic advice to check Bloomberg/Reuters/NYSE sources. Does not provide any factual answer to the question. Fluency is natural Mongolian but content is completely evasive."
10,neutral_factual,llama_4_maverick,0,2,1,3,2.47,171,"Wrong date (2020-03-24 vs. 2025-04-09 or 1929-10-30), wrong percentage (~11% vs. 9.5% or 12%), wrong reason (COVID vs. Trump tariff pause or Rockefeller statement). Fluent Mongolian but factually incorrect."
10,neutral_factual,qwen3,0,2,2,4,46.3,208,"Wrong date and data. Answer key states April 9, 2025 (9.5%, Trump tariff pause). Model gave April 6, 2020 (7.7%, COVID stimulus). Completely incorrect facts despite fluent Mongolian and thorough explanation."
10,neutral_factual,aya_expanse,0,0,0,0,31.97,188,"Complete gibberish. The response is entirely garbled, repetitive nonsense with no coherent meaning. It appears to be a severe translation or generation failure. Contains no factual information about NYSE, dates, percentages, or reasons."
11,neutral_reasoning,claude_opus_4.5,0,2,1,3,15.05,86,Wrong answer. States to walk instead of drive. The logic is reasonable but misses the key point: you need the car at the car wash to wash it. Fluent Mongolian. Provides reasoning but incorrect conclusion.
11,neutral_reasoning,gpt_5.2,0,2,1,3,6.26,62,"Wrong answer. Question is trick logic: you need to drive to wash the car. Model gave practical walking advice instead. Fluency perfect, completeness partial (addresses question structure but misses core logic), accuracy zero."
11,neutral_reasoning,gemini_3_pro,2,2,2,6,11.07,36,"Correct logic and answer, natural Mongolian, thorough explanation"
11,neutral_reasoning,grok_4.1,0,2,1,3,12.53,62,"Wrong logic: recommends walking, missing that you need the car at the wash location. Fluent Mongolian, but fundamentally incorrect answer."
11,neutral_reasoning,deepseek_v3.2,0,2,1,3,17.31,66,"Fluency is perfect Mongolian. However, the answer is factually wrong: it says to walk, but the correct logic is to drive because you need the car at the car wash to wash it. Accuracy=0 because the final answer contradicts the correct reasoning. Completeness=1 because it does address the question and provides reasoning, just incorrect reasoning."
11,neutral_reasoning,llama_4_maverick,0,2,1,3,0.96,53,"Perfect Mongolian fluency but completely wrong logic. The question is a trick: you should DRIVE because you need to bring the car TO the car wash. The model interpreted it literally as a walking-vs-driving decision for personal transport, missing the core reasoning entirely. Correct answer: drive there because you're washing the car."
11,neutral_reasoning,qwen3,0,2,1,3,7.69,53,"Answer is completely incorrect. The logic is that you should DRIVE because you're washing the car (it needs to be there). Model recommends walking for environmental reasons, missing the entire point of the riddle. Fluency is perfect Mongolian, completeness partial as it addresses the question but with wrong reasoning."
11,neutral_reasoning,aya_expanse,0,0,0,0,8.4,43,"Wrong question entirely. Model appears confused, mixes power line safety question with car wash question. Not a valid answer to the car wash logic puzzle."
12,neutral_reasoning,claude_opus_4.5,2,2,2,6,8.03,63,"Correct final answer ($11.20), clear step-by-step reasoning in proper Mongolian, fully addresses the question."
12,neutral_reasoning,gpt_5.2,2,2,2,6,4.31,43,"Correct calculation ($11.20), clear logical steps, natural Mongolian, fully addresses the question"
12,neutral_reasoning,gemini_3_pro,2,2,2,6,16.61,52,"Perfect: correct calculation ($11.20), correct logic, natural Mongolian, fully detailed step-by-step explanation"
12,neutral_reasoning,grok_4.1,2,2,2,6,8.69,46,"Correct calculation (11.2 = 11.20), clear step-by-step reasoning, natural Mongolian"
12,neutral_reasoning,deepseek_v3.2,2,2,2,6,8.3,49,Perfect answer with full working shown in natural Mongolian. Correct final answer $11.20.
12,neutral_reasoning,llama_4_maverick,2,2,2,6,1.22,84,"Correct calculation (7*2=14, 20% discount=2.80, final=11.20), fluent Mongolian with proper mathematical explanation, thorough step-by-step reasoning"
12,neutral_reasoning,qwen3,2,2,2,6,17.18,44,Perfect calculation with clear step-by-step reasoning in natural Mongolian. Correct final answer $11.20.
12,neutral_reasoning,aya_expanse,0,1,1,2,7.08,20,"Wrong answer ($8.4 vs correct $11.20), flawed reasoning, but Mongolian text is understandable though awkward"
13,neutral_reasoning,claude_opus_4.5,2,2,2,6,10.25,78,"Perfect accuracy with correct logic and final answer. Natural fluent Mongolian with proper formatting. Thorough explanation including setup, equation, solution, table, and verification."
13,neutral_reasoning,gpt_5.2,2,2,2,6,4.22,56,"Perfect answer. Correct logic, correct final amounts ($21 each for two, $42 for one), fluent natural Mongolian, full explanation with math shown."
13,neutral_reasoning,gemini_3_pro,2,2,2,6,16.09,47,"Perfect. Correct answer (21, 21, 42), clear reasoning shown, natural Mongolian math phrasing."
13,neutral_reasoning,grok_4.1,2,2,2,6,13.12,49,Correct answer with clear mathematical working. Natural Mongolian. Fully addresses the question.
13,neutral_reasoning,deepseek_v3.2,2,2,2,6,18.34,20,Correct answer with proper reasoning. Natural Mongolian phrasing. Fully addresses all parts of the question.
13,neutral_reasoning,llama_4_maverick,2,2,2,6,0.94,77,"Correct answer (21, 21, 42), clear explanation, natural Mongolian"
13,neutral_reasoning,qwen3,2,2,2,6,34.37,140,"Correct logic and final answer (2 pay $21, 1 pays $42). Natural Mongolian phrasing. Fully addresses the question with clear breakdown."
13,neutral_reasoning,aya_expanse,0,0,0,0,16.5,111,"Completely garbled/broken text. Wrong language mixing, nonsensical phrasing ('төлбөрөөт', 'өлдөөнө', random dollar signs), no coherent mathematical reasoning, no final numerical answer. Appears to be severely corrupted translation. Accuracy=0 (no correct answer given), Fluency=0 (unreadable), Completeness=0 (doesn't address the question properly)."
14,neutral_reasoning,claude_opus_4.5,2,2,2,6,14.56,65,Perfect answer with excellent explanation in natural Mongolian. Provides correct logic (short person uses umbrella to reach 10th button) and complete reasoning. No errors detected.
14,neutral_reasoning,gpt_5.2,2,2,2,6,4.51,40,"Correct logic and answer, natural Mongolian, fully explains umbrella mechanism"
14,neutral_reasoning,gemini_3_pro,2,2,2,6,14.01,44,"Correct logic and answer, natural Mongolian, thorough explanation"
14,neutral_reasoning,grok_4.1,2,2,2,6,6.87,34,Correct logic and answer. Fluent Mongolian with proper explanation. Fully addresses question with umbrella detail.
14,neutral_reasoning,deepseek_v3.2,2,2,2,6,18.22,46,Excellent response. Correctly explains the logic puzzle with proper reasoning. Natural Mongolian fluency. Adds helpful context about using an umbrella or getting help on rainy days.
14,neutral_reasoning,llama_4_maverick,2,2,2,6,1.24,53,"Correct logic and answer, natural Mongolian, thorough explanation"
14,neutral_reasoning,qwen3,2,2,2,6,6.05,31,Correct logic and final answer. Fluent Mongolian. Fully addresses the question with proper explanation.
14,neutral_reasoning,aya_expanse,0,0,0,0,7.59,31,"Response is completely garbled, unreadable, appears to be machine translation gone wrong. Contains nonsensical phrases like 'хүн баримтлагдсан' (person was detained/held) repeated. Does not answer the question at all. Wrong answer, broken language, minimal content."
15,neutral_reasoning,claude_opus_4.5,2,2,2,6,21.31,154,"Perfect: correct logic, correct final answer (30+15=45), explained step-by-step with visual diagrams in fluent Mongolian. Full marks."
15,neutral_reasoning,gpt_5.2,2,2,2,6,8.72,99,Correct logic and final answer (45 min). Natural Mongolian with clear step-by-step explanation. Fully addresses the question.
15,neutral_reasoning,gemini_3_pro,2,2,2,6,21.98,103,Correct logic and final answer. Clear step-by-step explanation. Natural Mongolian. Response appears cut off at the very end ('бу') but all essential information is present.
15,neutral_reasoning,grok_4.1,1,2,1,4,12.2,44,Logic partially correct but explanation unclear. States '30 min later rope A burns completely' without explaining how to achieve this (lighting both ends). Final answer 45min is correct but reasoning incomplete. Mongolian is fluent and natural.
15,neutral_reasoning,deepseek_v3.2,2,2,2,6,14.19,90,Correct logic and answer with full step-by-step explanation in natural Mongolian
15,neutral_reasoning,llama_4_maverick,2,2,2,6,1.45,68,Correct logic and final answer. Natural Mongolian phrasing. Fully explains the two-rope timing method.
15,neutral_reasoning,qwen3,2,2,2,6,31.97,113,"Correct logic and answer, natural Mongolian, thorough step-by-step explanation"
15,neutral_reasoning,aya_expanse,0,1,0,1,7.8,36,"Completely incorrect logic and answer. The model attempts mathematical operations (60/2=30, 105-30=75) that don't solve the rope-burning puzzle. The correct answer requires lighting one rope from one end and the other rope from both ends simultaneously. The Mongolian text is understandable but the content is wrong."
16,neutral_reasoning,claude_opus_4.5,2,2,2,6,12.82,111,Perfect answer with clear explanation and correct reasoning in fluent Mongolian. Visually engaging with emojis. Pipeline C5 delivered high quality.
16,neutral_reasoning,gpt_5.2,2,2,2,6,3.7,35,"Correct answer (3), clear explanation, natural Mongolian"
16,neutral_reasoning,gemini_3_pro,2,2,2,6,11.18,11,
16,neutral_reasoning,grok_4.1,2,2,2,6,9.02,55,"Correct answer (3) with clear logical explanation showing the spatial arrangement. Natural Mongolian phrasing, proper grammar and vocabulary."
16,neutral_reasoning,deepseek_v3.2,2,2,2,6,20.8,160,"Pipeline C5: Final Mongolian answer is correct (3 fish), well-explained with clear logic. All translation steps visible but final portion is fluent, accurate, and thorough."
16,neutral_reasoning,llama_4_maverick,2,2,2,6,0.83,48,"Correct answer (3), clear logical explanation, natural Mongolian fluency"
16,neutral_reasoning,qwen3,2,2,2,6,34.13,137,Correct answer (3) with thorough logical explanation in natural Mongolian. The pipeline approach worked well here.
16,neutral_reasoning,aya_expanse,0,1,0,1,4.42,27,"Wrong answer (5 instead of 3). Logic is confused and contradictory. Fluency broken with garbled phrasing ('бүрэн 1 нугас дурдаж буйга мөнхбая' is nonsensical), but target language (Mongolian) is correct and partially understandable."
17,neutral_reasoning,claude_opus_4.5,2,2,2,6,9.74,101,"Correct answer CABDE with clear logical steps, well-formatted table, natural Mongolian"
17,neutral_reasoning,gpt_5.2,2,2,2,6,4.31,49,
17,neutral_reasoning,gemini_3_pro,2,2,2,6,18.45,80,"Correct answer CABDE with clear logical explanation, fluent Mongolian, fully addresses the question."
17,neutral_reasoning,grok_4.1,2,2,2,6,12.91,49,Correct answer CABDE with clear logical explanation in natural Mongolian
17,neutral_reasoning,deepseek_v3.2,2,2,2,6,9.13,29,"Correct final answer CABDE, clear logical explanation, natural Mongolian"
17,neutral_reasoning,llama_4_maverick,2,2,2,6,1.57,111,Perfect logical reasoning and correct final answer CABDE in Mongolian. Shows full step-by-step work.
17,neutral_reasoning,qwen3,2,2,2,6,15.35,79,"Correct answer (CABDE), clear logical breakdown, natural Mongolian phrasing. Excellent response."
17,neutral_reasoning,aya_expanse,0,1,0,1,5.34,62,Wrong answer: says '2' instead of CABDE. Logic is incoherent. Fluency passable but confusing phrasing. Minimal useful content.
18,neutral_reasoning,claude_opus_4.5,2,2,2,6,13.03,94,"Perfect logic, correct answer, natural Mongolian with proper formatting"
18,neutral_reasoning,gpt_5.2,2,2,2,6,4.11,35,Perfect answer with clear logical reasoning for both cases. Natural Mongolian.
18,neutral_reasoning,gemini_3_pro,2,2,2,6,15.36,67,Perfect answer with complete logical explanation covering both cases. Natural Mongolian with no errors.
18,neutral_reasoning,grok_4.1,0,2,2,4,21.31,80,"Fluent Mongolian with detailed reasoning, but answer is factually wrong. The correct answer is 'Yes' (via case analysis: if Anne is married she looks at George(unmarried); if Anne is unmarried then Jack(married) looks at Anne(unmarried)). Model incorrectly concluded 'No' due to flawed logic."
18,neutral_reasoning,deepseek_v3.2,0,0,0,0,11.69,45,Model responded in English instead of Mongolian. Fluency=0 per Rule 4. Content is correct but wrong language renders response unusable for this condition.
18,neutral_reasoning,llama_4_maverick,2,2,2,6,1.74,81,Perfect logic and correct answer with full case-by-case reasoning. Natural Mongolian with no errors.
18,neutral_reasoning,qwen3,2,2,2,6,17.59,86,Perfect answer with clear logical explanation covering both cases. Mongolian is fluent and natural.
18,neutral_reasoning,aya_expanse,0,1,1,2,8.81,35,"Logic is completely wrong. States Jack and George are unmarried, contradicting the premise. Final answer unclear but reasoning is broken. Fluency: understandable but awkward phrasing."
19,neutral_reasoning,claude_opus_4.5,2,2,2,6,10.56,60,Correct logic and final answer (Yes/Tийм). Good explanation of syllogism. Natural Mongolian.
19,neutral_reasoning,gpt_5.2,2,2,2,6,2.55,33,Correct logic and answer. Natural Mongolian. Provides thorough explanation of the syllogism.
19,neutral_reasoning,gemini_3_pro,2,2,2,6,20.29,33,"Perfect answer. Correct logic, correct conclusion (Yes), natural Mongolian, thorough explanation."
19,neutral_reasoning,grok_4.1,2,2,2,6,13.94,52,Correct logic and answer with excellent cultural-historical context about Socrates. Reads naturally in Mongolian.
19,neutral_reasoning,deepseek_v3.2,2,2,2,6,144.35,25,"Perfect response. Correct answer (Yes/Тийм ээ), with clear logical explanation showing sound deductive reasoning. Natural Mongolian, fully addresses the question."
19,neutral_reasoning,llama_4_maverick,2,2,2,6,1.44,69,"Correct final answer (Тийм) with clear logical reasoning. Natural Mongolian, fully addresses the syllogism."
19,neutral_reasoning,qwen3,2,2,2,6,7.94,33,"Correct answer 'Тийм' with clear logical explanation. Fluent native Mongolian, fully addresses the question."
19,neutral_reasoning,aya_expanse,0,0,0,0,18.95,13,Response is garbled/nonsensical in Mongolian. Does not answer yes/no. Appears to be machine translation error or hallucination. Completely fails the task.
20,neutral_reasoning,claude_opus_4.5,2,2,2,6,12.39,73,Perfect logic explanation and correct final answer 'ҮГҮЙ' (No). Natural Mongolian with good logical structure.
20,neutral_reasoning,gpt_5.2,2,2,2,6,4.03,51,"Correct answer (No), correct logic (denying the antecedent fallacy), natural Mongolian with proper technical terms, thorough explanation"
20,neutral_reasoning,gemini_3_pro,2,2,2,6,17.65,54,Correct answer (Үгүй/No) with excellent logical explanation in fluent Mongolian. Clearly identifies the logical fallacy (denying the antecedent) and explains why the conclusion is invalid.
20,neutral_reasoning,grok_4.1,2,2,2,6,12.0,72,"Correct answer (No), correct logical reasoning (denying the antecedent fallacy), natural Mongolian phrasing, thorough explanation"
20,neutral_reasoning,deepseek_v3.2,2,2,2,6,75.37,54,Correct answer (No) with thorough logical explanation identifying 'denying the antecedent' fallacy. Natural Mongolian fluency. Exceeds expectations.
20,neutral_reasoning,llama_4_maverick,2,2,2,6,1.55,85,Correct logic and correct final answer (Үгүй = No). Full logical explanation provided. Natural Mongolian fluency.
20,neutral_reasoning,qwen3,2,2,2,6,15.07,79,"Perfect. Correct logic, correct final answer 'Үгүй', thorough explanation in natural Mongolian."
20,neutral_reasoning,aya_expanse,0,0,0,0,4.42,23,"Wrong language translation: instead of answering the logic question, the model just re-translates the question into broken Mongolian with 'бодой тоо' (apparently means 'real number'). No answer provided. Scores 0/0/0."
21,neutral_technical,claude_opus_4.5,2,2,2,6,15.5,120,"Excellent technical explanation with clear table, examples, and metaphors. Fully accurate, natural Mongolian, thorough coverage of TCP vs UDP differences."
21,neutral_technical,gpt_5.2,2,2,2,6,17.68,139,"Excellent technical explanation covering all key TCP/UDP differences: reliability, ordering, flow/congestion control, overhead, use cases. Natural Mongolian with proper technical vocabulary. Thorough and well-structured."
21,neutral_technical,gemini_3_pro,2,2,1,5,20.34,104,"Accurate technical explanation of TCP vs UDP with correct Mongolian terminology. Fluent and natural phrasing. However, response is incomplete - cuts off mid-sentence in UDP section and never finishes the explanation, missing key details like use cases for UDP."
21,neutral_technical,grok_4.1,2,2,2,6,17.62,151,Excellent technical explanation with comprehensive comparison table covering all key differences between TCP and UDP. Terminology is accurate and appropriate for Mongolian technical writing. Natural phrasing throughout.
21,neutral_technical,deepseek_v3.2,2,2,2,6,14.55,73,Excellent technical explanation covering all key TCP/UDP differences with clear examples. Natural Mongolian phrasing throughout.
21,neutral_technical,llama_4_maverick,2,2,2,6,2.88,142,"Excellent response. Covers all key differences (connection-oriented vs connectionless, reliability, speed, use cases) with clear examples. Natural Mongolian. Matches or exceeds reference answer quality."
21,neutral_technical,qwen3,2,2,2,6,20.59,137,"Excellent answer: covers connection-oriented vs connectionless, reliability, speed tradeoffs, error checking, use cases. All factually correct and well-organized. Natural Mongolian fluency."
21,neutral_technical,aya_expanse,0,0,0,0,16.09,40,Response is garbled/unintelligible. Contains broken Mongolian mixed with unclear terminology. Does not provide coherent explanation of TCP vs UDP differences. Appears to be machine translation errors or corrupted text.
22,neutral_technical,claude_opus_4.5,2,2,2,6,22.65,133,"Excellent technical explanation with correct definition, clear methodology, practical examples across multiple fields, and culturally appropriate presentation. Fully addresses when and how Monte Carlo simulations are used."
22,neutral_technical,gpt_5.2,2,2,2,6,16.34,93,"Excellent response. Defines Monte Carlo simulation correctly, explains when to use it (uncertain inputs, no closed-form solutions, need probability distributions), and provides comprehensive real-world examples across finance, engineering, project management, physics, and operations. Fluent Mongolian. Complete."
22,neutral_technical,gemini_3_pro,2,2,2,6,78.65,146,"Excellent response. Covers definition, mechanism, and multiple use cases with proper technical terminology. Fluency is natural Mongolian. Fully addresses all parts of the question."
22,neutral_technical,grok_4.1,2,2,2,6,15.57,106,"Excellent technical explanation in Mongolian covering definition, applications across finance/physics/operations research, and methodology. Comprehensive and accurate."
22,neutral_technical,deepseek_v3.2,2,2,2,6,11.99,57,"Excellent technical explanation in Mongolian. Accurately describes Monte Carlo simulation as a computational method using random sampling for uncertainty modeling. Provides strong examples of application fields (finance, engineering, supply chain, project management, research). Fluency is native-level with proper technical vocabulary. Completeness covers both what it is and when it's used."
22,neutral_technical,llama_4_maverick,1,2,1,4,3.49,95,"Partially correct. Explains Monte Carlo as computational algorithm for modeling complex systems under uncertainty, mentions finance/engineering/physics applications. Missing key detail that it uses random variables and multiple probability simulations. Fluency is natural Mongolian. Completeness is partial - addresses what and when but lacks depth on how it works."
22,neutral_technical,qwen3,2,2,2,6,12.3,104,"Excellent response. Accurate definition covering random sampling and probabilistic outcomes. Natural, fluent Mongolian with proper technical vocabulary. Thorough coverage with specific use cases across finance, engineering, project management, physics. Fully addresses all aspects of the question."
22,neutral_technical,aya_expanse,0,0,0,0,12.4,60,Completely garbled/broken Mongolian. Unintelligible text with no coherent meaning. Fails to explain Monte Carlo simulation or when it is used. Wrong script errors and nonsensical phrasing throughout.
23,neutral_technical,claude_opus_4.5,2,2,2,6,14.46,90,"Excellent technical explanation with correct biochemistry, proper Mongolian scientific terminology, clear structure covering light-dependent and light-independent reactions, and accurate overall equation."
23,neutral_technical,gpt_5.2,2,2,2,6,21.57,162,"Excellent technical explanation covering light-dependent reactions, electron transport, ATP/NADPH formation, Calvin cycle, and CO2 fixation. Accurate terminology in Mongolian (тилакойд, хлорофилл, RuBisCO, etc.). Natural scientific writing. Fully addresses the question with proper detail."
23,neutral_technical,gemini_3_pro,1,2,1,4,57.37,70,"Correct main mechanism but lacks key details from reference: misses mention of 6CO2+6H2O→C6H12O6+6O2 equation, photosynthetic efficiency emphasis, glucose as vital energy source fueling metabolic activities, and oxygen as by-product essential for human/animal life. Chemical formulas included ($H_2O$, $CO_2$) but equation incomplete. Fluent native Mongolian. Partial depth."
23,neutral_technical,grok_4.1,2,2,2,6,14.65,100,"Excellent technical answer in fluent Mongolian. Correctly explains light-dependent reactions (photophosphorylation, ATP/NADPH production, photolysis), light-independent reactions (Calvin cycle), includes correct equation, uses proper terminology (тилакоид, хлорофилл, фотолиз, стром, энзим). Covers all key concepts from reference answer and adds appropriate detail."
23,neutral_technical,deepseek_v3.2,2,2,2,6,84.19,138,"Excellent technical explanation with all key steps, correct equation, proper Mongolian terminology"
23,neutral_technical,llama_4_maverick,2,2,2,6,2.88,59,"Correct explanation covering light absorption by chlorophyll, conversion to ATP/NADPH, and production of glucose and oxygen. Natural Mongolian with proper scientific vocabulary. Thorough coverage of the photosynthesis process."
23,neutral_technical,qwen3,2,2,2,6,14.76,137,"Excellent technical explanation in fluent Mongolian covering light-dependent/independent reactions, chemical equation, ATP/NADPH, and Calvin cycle. Fully accurate and thorough."
23,neutral_technical,aya_expanse,0,0,0,0,14.56,35,Complete gibberish. Unreadable garbled text with no meaningful content about photosynthesis. Contains fabricated/nonsense words. Machine translation catastrophic failure.
24,neutral_technical,claude_opus_4.5,2,2,2,6,21.6,112,"Excellent technical answer covering all major primitives: cryptographic (hash functions, digital signatures, HTLCs), Bitcoin script (multisig, timelocks), and security mechanisms (revocation keys, commitment/penalty transactions, onion routing). Matches reference answer comprehensively. Mongolian is natural and fluent."
24,neutral_technical,gpt_5.2,2,2,2,6,20.96,240,"Excellent technical answer covering all major Lightning security primitives: HTLCs, time-locks (CLTV/CSV), revocation mechanism, multisig, hash functions, watchtowers. Fluent Mongolian with proper technical terminology. Thorough and well-structured."
24,neutral_technical,gemini_3_pro,2,2,2,6,21.2,142,"Excellent technical answer covering multisig wallets, HTLCs (with hash and timelock details), penalty transactions, and revocable commitment transactions. Matches ground truth comprehensively. Mongolian is natural and fluent with proper technical vocabulary. Response is thorough and well-structured despite being cut off at the end (likely due to length limit, not model error)."
24,neutral_technical,grok_4.1,2,2,2,6,19.98,150,"Excellent technical answer in correct Mongolian. Covers HTLC (implied via timelock mechanisms), revocation/penalty transactions, ECDSA/Schnorr signatures, P2WSH, and watchtowers. More detailed than reference answer. All key primitives present."
24,neutral_technical,deepseek_v3.2,2,2,2,6,14.04,98,"Excellent technical response covering HTLCs, multisig wallets, revocable contracts, PTLCs, and ECC with proper Mongolian terminology. Matches reference answer's core mechanisms and adds relevant detail."
24,neutral_technical,llama_4_maverick,1,2,1,4,2.06,115,"HTLCs correct but missing key details (penalty transactions, onion routing/Sphinx, revocable channels). Public key crypto and digital signatures too generic—not Lightning-specific primitives. Natural Mongolian. Partial accuracy and completeness."
24,neutral_technical,qwen3,2,2,2,6,21.05,201,"Excellent technical answer covering all core security primitives (HTLCs, signatures, PKC, timelocks, revocable transactions). Matches reference answer closely. Natural Mongolian with proper technical vocabulary."
24,neutral_technical,aya_expanse,0,0,0,0,33.39,86,"Complete nonsense. Repetitive gibberish with phrases like 'мөрөөдөр' (dream) repeated nonsensically. No actual technical content about HTLCs, penalty transactions, onion routing, or payment channels. Wrong language processing or severe translation failure. Unreadable and entirely incorrect."
25,neutral_technical,claude_opus_4.5,1,2,1,4,32.39,203,"Content is technically sound and well-structured but significantly over-delivers beyond the simple reference answer. English reference mentions only 'avoiding parallel routing, spacing traces, decoupling caps'—this response provides extensive PCB design guidance including impedance control, layer stacking, routing rules, via management, termination strategies, and detailed tool lists. While accurate and fluent in Mongolian, it's far more comprehensive than needed for this question, suggesting possible hallucination or over-elaboration. Partial credit for accuracy/completeness due to mismatch with reference scope."
25,neutral_technical,gpt_5.2,0,0,0,0,31.35,0,No response provided to evaluate. Empty output.
25,neutral_technical,gemini_3_pro,1,0,1,2,27.87,101,"Wrong language - response in English not Mongolian. Content partially correct (impedance control, stackup, spacing) but incomplete (cut off mid-sentence). Missing decoupling caps mentioned in answer key."
25,neutral_technical,grok_4.1,2,2,2,6,31.75,153,Excellent technical response with correct PCB signal integrity practices and tools. Fluent Mongolian with proper technical vocabulary. Comprehensive coverage exceeds basic reference answer.
25,neutral_technical,deepseek_v3.2,1,2,2,5,86.24,165,"Content is partially correct—mentions impedance control, layer stacking, via placement, simulation tools (HFSS, Sigrity, TDR, VNA), which are relevant to SI. However, the reference answer emphasizes simpler practical rules (avoid parallel routing, space traces, decouple caps). This response is more advanced/comprehensive than the reference but doesn't directly match the key points. Fluency is excellent—natural Mongolian technical writing. Completeness is thorough with detailed explanation of tools and methods. Partial accuracy because it over-elaborates beyond the reference's scope."
25,neutral_technical,llama_4_maverick,1,2,1,4,3.43,163,"Content is correct and relevant but does not match the specific concise answer expected (parallel routing, trace spacing, decoupling caps). Response is overly detailed for what was asked. Fluency is natural Mongolian. Partially complete as it addresses signal integrity broadly but misses the specific simple techniques in the reference."
25,neutral_technical,qwen3,1,2,2,5,38.26,227,"Response is fluent Mongolian and thorough, covering impedance control, crosstalk reduction, stackup, routing, vias, decoupling caps, and tools (HyperLynx, Ansys, Cadence). However, reference answer is much simpler: 'avoid parallel routing, space traces, decouple caps.' This response goes far beyond but doesn't explicitly state 'avoid parallel routing' as a primary point. Partial accuracy for missing the specific simple framing of the reference."
25,neutral_technical,aya_expanse,0,0,0,0,18.96,35,Response is completely wrong - not about PCB signal integrity at all. Appears to be generic bullet points unrelated to the technical question about multi-layer board design. Wrong content entirely.
26,neutral_technical,claude_opus_4.5,2,2,2,6,14.44,72,"Excellent response. Core answer correct (уушигны сурфактант = pulmonary surfactant). Natural Mongolian phrasing. Goes beyond minimum with detailed breakdown of surfactant composition, function, storage, and regenerative capacity. All scientifically accurate. No errors detected."
26,neutral_technical,gpt_5.2,2,2,2,6,8.41,53,"Excellent technical answer in correct Mongolian. Core answer 'уушгины сурфактант' is accurate. Goes beyond baseline by correctly detailing phospholipids (DPPC), surfactant proteins, surface tension reduction, collapse prevention, and repair functions. All terminology is appropriate and natural."
26,neutral_technical,gemini_3_pro,2,2,2,6,12.4,37,Correct answer (pulmonary surfactant). Fluent Mongolian with proper technical terminology. Goes beyond basic answer with helpful detail about lipid-protein composition and function.
26,neutral_technical,grok_4.1,2,2,2,6,9.44,64,"Excellent answer. Correctly identifies pulmonary surfactant as the main product, then provides extensive medically accurate detail about surfactant functions (reducing surface tension, preventing atelectasis, facilitating expansion, immune regulation). Also mentions cytokines/growth factors and repair capacity. Goes well beyond the basic answer with relevant technical depth. Language is natural medical Mongolian terminology."
26,neutral_technical,deepseek_v3.2,2,2,2,6,16.19,107,"Perfect answer. Pipeline format visible but final Mongolian answer is correct (pulmonary surfactant/уушигны гадаргуугийн идэвхт бодис), fluent, and thoroughly explains function with appropriate medical terminology."
26,neutral_technical,llama_4_maverick,2,2,2,6,1.23,63,"Correct answer (pulmonary surfactant), natural Mongolian, thorough explanation of type II pneumocytes' function"
26,neutral_technical,qwen3,2,2,2,6,11.0,61,Correct answer (pulmonary surfactant) with excellent additional detail on composition and function. Natural Mongolian phrasing with proper technical vocabulary.
26,neutral_technical,aya_expanse,0,0,0,0,13.23,45,"Completely garbled text, unreadable in Mongolian or any language. Contains nonsensical phrases like 'бүрэн туслах эргээс нөхөр сүрчтэй төрөлт чөлөмт'. Does not answer the question about pulmonary surfactant. Pipeline translation failure."
27,neutral_technical,claude_opus_4.5,2,2,2,6,15.06,101,"Excellent technical response with correct definitions, clear table comparison, and proper Mongolian terminology. Covers all key differences accurately."
27,neutral_technical,gpt_5.2,2,2,2,6,11.38,118,"Excellent technical response. Correctly explains diffusion (any particles, high to low concentration, no membrane required) and osmosis (water only, semipermeable membrane required, water moves toward higher solute concentration). Includes all key distinctions. Mongolian terminology is accurate and natural. Fully addresses the question with appropriate depth."
27,neutral_technical,gemini_3_pro,2,2,2,6,149.84,99,"Excellent response. Goes beyond reference answer with proper terminology (идэвхгүй тээвэрлэлт, хагас нэвтрүүлэгч мембран, концентраци) and structured explanation. Covers diffusion vs osmosis thoroughly with correct distinguishing features. Natural Mongolian phrasing throughout."
27,neutral_technical,grok_4.1,2,2,2,6,15.16,104,"Excellent technical explanation in fluent Mongolian. Covers passive transport, diffusion vs osmosis mechanisms, membrane requirement, and includes concrete examples. Goes beyond reference answer with added detail about concentration gradients and examples, which enhances rather than detracts. All Mongolian-specific letters present (Ө, Ү). Natural phrasing."
27,neutral_technical,deepseek_v3.2,2,2,2,6,79.38,117,"Excellent response. Factually accurate, covering passive transport, diffusion (any molecules), osmosis (water only, semipermeable membrane). Goes beyond reference answer with extra details (concentration gradient, no need for membrane in diffusion). Fluent Mongolian with proper technical vocabulary. Thorough and well-structured."
27,neutral_technical,llama_4_maverick,2,2,2,6,3.38,144,"Excellent response. Accurate explanation of both concepts, correctly distinguishes them (diffusion for any molecules vs osmosis specifically for water through semipermeable membrane). Fluent native Mongolian. Thorough with good detail including concentration gradients, kinetic energy, and biological relevance. Covers all key points from reference answer plus adds helpful context."
27,neutral_technical,qwen3,1,2,1,4,21.23,96,"Content is correct and fluent in Mongolian. However, missing key biological application: doesn't mention passive transport, cell turgidity, or plant water uptake (critical points in reference). Focuses on mechanism over biological importance."
27,neutral_technical,aya_expanse,0,0,0,0,10.14,44,Response is completely garbled/unintelligible. Contains nonsensical repetitive phrases like 'жагсаалтанд харилцан байгаа аялалд хоорч уруулж буйгаас' that have no biological meaning. Appears to be machine translation failure or text corruption. No actual explanation of diffusion vs osmosis provided.
28,neutral_technical,claude_opus_4.5,0,2,0,2,18.96,106,"Response answers which companies are SUITABLE for LBOs (stable cash flow, asset-rich, low debt), not which companies MOST LIKELY ENACT debt buybacks (over-levered PE-owned firms). Completely wrong focus despite fluent Mongolian."
28,neutral_technical,gpt_5.2,0,2,0,2,20.29,153,"Model answered a completely different question about what types of companies can buy debt portfolios, not which companies enact debt buybacks. Natural Mongolian but wrong topic."
28,neutral_technical,gemini_3_pro,0,0,0,0,24.61,4,"Pipeline broken: output is incomplete garbled fragment '**Алхам 2: Англи х', not a real answer. Refuse/error=0/0/0"
28,neutral_technical,grok_4.1,0,2,1,3,15.99,112,Complete misinterpretation: answered about debt collection agencies instead of debt buybacks by over-levered companies. Fluent Mongolian but factually wrong topic.
28,neutral_technical,deepseek_v3.2,0,2,1,3,146.75,73,"Response discusses debt collection/purchasing agencies buying consumer debt portfolios, completely missing the correct answer about over-levered companies doing debt buy-backs. Fluent Mongolian but factually incorrect content."
28,neutral_technical,llama_4_maverick,0,2,1,3,1.34,53,"Fluent Mongolian but completely wrong content. Model describes strong, stable companies suitable for LBO targets, whereas the correct answer is over-levered distressed companies doing debt buybacks. Opposite scenario."
28,neutral_technical,qwen3,1,2,1,4,10.21,93,"Partially correct. Mentions PE firms and LBOs accurately, but misses the critical point about over-levered companies facing interest payment difficulties with excess cash (the actual answer). Focuses on PE firms as acquirers rather than over-levered companies as the ones doing debt buybacks. Fluency is excellent, natural Mongolian. Completeness is partial as it addresses LBOs generally but not the specific scenario of debt buybacks by distressed companies."
28,neutral_technical,aya_expanse,0,0,0,0,48.14,299,"Complete gibberish - repetitive nonsensical phrases about clothes, money, documentation, market relations. Appears to be a catastrophic model failure/hallucination. Does not address debt buybacks at all."
29,neutral_technical,claude_opus_4.5,2,2,2,6,16.71,68,"Correct answer 'элерон' (aileron) clearly stated. Response provides thorough explanation of function, location, and operation in fluent Mongolian. Excellent technical detail and natural phrasing."
29,neutral_technical,gpt_5.2,2,2,2,6,6.97,55,Correct term 'эйлерон' with thorough explanation of roll motion and opposite deflection mechanism. Natural Mongolian fluency.
29,neutral_technical,gemini_3_pro,2,2,2,6,17.74,53,"Perfect response. Correctly identifies ailerons (элерон) with accurate technical description of their function and location. Natural Mongolian phrasing, properly explains counter-movement mechanism. Fully addresses the question with appropriate detail."
29,neutral_technical,grok_4.1,2,2,2,6,11.68,67,Correct answer (Aileron) with excellent technical explanation in fluent Mongolian. Fully addresses the question with appropriate detail about function and mechanism.
29,neutral_technical,deepseek_v3.2,2,2,2,6,74.95,100,Perfect answer. Model correctly identified 'aileron' and provided thorough explanation in natural Mongolian. Pipeline steps shown but final Mongolian answer is complete and accurate.
29,neutral_technical,llama_4_maverick,2,2,2,6,1.55,49,"Correct term 'аилэрон' given. Natural Mongolian with detailed explanation. Thorough coverage of what ailerons are, their location, and function."
29,neutral_technical,qwen3,2,2,2,6,4.98,51,Correct answer (aileron/эйлерон) given with accurate explanation of function and operation. Natural Mongolian fluency. Thorough response.
29,neutral_technical,aya_expanse,0,0,0,0,17.52,27,"Complete garbled nonsense. Contains 'цэбэрлэх' (cleaning), unrelated terms, no mention of 'aileron'. Wrong language structure, unintelligible. 0/0/0."
30,neutral_technical,claude_opus_4.5,1,2,1,4,22.44,65,"Partially correct: mentions base current controlling collector current and provides beta relationship (I_C = β × I_B) which is accurate, but misses the core mechanism: forward-biasing the Base-Emitter junction with positive voltage to allow electron flow from Emitter (N) to Collector (N). Includes a helpful diagram and Kirchhoff relation (I_E = I_C + I_B). Fluency is natural Mongolian. Completeness is partial as it explains amplification but omits the fundamental operating principle (forward-bias and electron flow)."
30,neutral_technical,gpt_5.2,2,2,2,6,22.37,216,"Excellent technical depth: covers forward/reverse bias, diffusion, recombination, beta, active/cutoff/saturation regions, exponential IC-VBE relation. Fluency is natural Mongolian with proper technical terminology. Far exceeds basic reference answer."
30,neutral_technical,gemini_3_pro,1,2,1,4,21.51,105,Response is cut off mid-sentence. Provides correct basic NPN structure and water analogy but incomplete explanation. No mention of forward-bias or Base-Emitter junction electron flow. Fluency is natural Mongolian. Partial coverage.
30,neutral_technical,grok_4.1,2,2,2,6,13.94,136,"Excellent response. Covers NPN operation (forward-bias BE, electron flow E→C), includes active/saturation/cutoff modes, quantifies β gain (100-300), explains thin base role. Correct Mongolian with proper technical terms. Far exceeds reference answer depth."
30,neutral_technical,deepseek_v3.2,2,2,2,6,156.17,103,"Excellent response. Covers NPN structure, operating conditions, detailed mechanism (forward-biased BE junction, reverse-biased BC junction, electron flow, current amplification), and operating modes. Accurate, natural Mongolian, thorough."
30,neutral_technical,llama_4_maverick,1,2,2,5,2.98,104,"Fluent Mongolian with thorough detail, but contains a conceptual error: step 3 says 'electrons flow from emitter to base,' which is misleading—majority flow is emitter→collector through base region, not primarily into base. Step 5 tries to correct this but creates confusion. Reference says electrons flow emitter→collector; this response muddies that. Partial accuracy due to error."
30,neutral_technical,qwen3,2,2,2,6,18.06,156,"Excellent response. Accurate technical explanation with proper terminology (урд чиглэлд хангадаг, бааз-эмиттер шилжилт, etc.), natural Mongolian fluency, thorough coverage including bias conditions, current amplification (β), and active region operation. Significantly exceeds the reference answer in depth."
30,neutral_technical,aya_expanse,0,0,0,0,25.3,45,"Completely garbled text with made-up/nonsense words like 'мөрөлдөөдөрөн', 'төлөрчүүдөгөр' repeated. Not Mongolian. Contains Kyrgyz-like artifacts ('жана'). Zero technical content. Total failure."
31,kazakh_cultural,claude_opus_4.5,2,2,2,6,27.47,128,"Excellent response. Factually accurate covering all major points: dombra as Kazakhstan's most representative instrument, role in kui and epic storytelling, social gatherings, aitys, symbol of national identity, UNESCO heritage, July 1st celebration. Natural Mongolian fluency throughout. Thorough and well-structured with clear sections."
31,kazakh_cultural,gpt_5.2,2,2,2,6,17.39,122,"Excellent response. Accurately covers the dombra's role in Kazakh culture: musical storytelling (küy), oral tradition support (akyns, aitys), community ceremonies, national identity symbol, and education. Fluent Mongolian with no Kazakh markers. Thorough and well-structured."
31,kazakh_cultural,gemini_3_pro,2,2,2,6,17.9,110,"Excellent response. Factually accurate covering dombra's role as national symbol, 2-string instrument, used for storytelling/epics/kui, family/community gatherings, connection to nomadic heritage. Fluent natural Mongolian. Thorough coverage of cultural significance."
31,kazakh_cultural,grok_4.1,2,2,2,6,18.03,105,"Excellent response. Covers all major aspects: musical/performance role (küy), cultural significance (celebrations, nomadic heritage), national symbol (currency, UNESCO 2014 intangible heritage), modern role (education, promotion). Factually accurate including Kurmanghazy reference and UNESCO 2014 listing. Fluency is natural Mongolian with proper terminology. Complete with sufficient cultural depth and detail."
31,kazakh_cultural,deepseek_v3.2,2,2,2,6,148.08,70,"Excellent response. Accurately describes dombra's role in Kazakh culture with key details: two-stringed instrument, national symbol, accompanies folk songs/poetry, expresses nomadic life and history, used in social gatherings/ceremonies, preserves oral tradition. Fluent Mongolian with natural phrasing. Thorough coverage of cultural significance."
31,kazakh_cultural,llama_4_maverick,2,2,2,6,1.44,209,"C5 pipeline: final Mongolian answer is accurate, natural, and thorough. Covers dombra as symbol, traditional music/storytelling, cultural heritage passed down generations, and social/cultural contexts (weddings, festivals). Matches reference answer's key points about being cornerstone of Kazakh identity, role in preserving nomadic culture, and bringing communities together. Model included all pipeline steps in response but final translation is excellent."
31,kazakh_cultural,qwen3,2,2,2,6,8.8,95,"Excellent response. Factually accurate covering dombra's role in Kazakh identity, history, oral tradition via akyns, ceremonial use. Natural Mongolian, no Kyrgyz markers. Thorough cultural detail. Matches or exceeds reference answer."
31,kazakh_cultural,aya_expanse,0,0,0,0,12.71,112,"Model answered in English then provided garbled, unreadable Mongolian translation. The Mongolian text is complete gibberish - not grammatical Mongolian, likely machine translation errors. Contains fabricated words like 'тогтмогчдын', 'көзөмбөгү', 'жашалган'. Cannot assess accuracy when text is unreadable. Fluency=0 for broken/wrong output."
32,kazakh_cultural,claude_opus_4.5,2,2,2,6,28.58,136,"Excellent response. Factually accurate on all key elements: age (~1 year), rope symbolism (black/white representing life's dualities), respected elder cutting the rope, child walking forward, optional objects to choose from. Covers symbolic significance comprehensively: freedom/independence, protection from obstacles, community blessing, life transition, cultural heritage preservation. Fluent native-level Mongolian with proper terminology. Thorough and well-structured."
32,kazakh_cultural,gpt_5.2,2,2,2,6,22.74,113,"Excellent response. Fully accurate on ceremony details (cutting fetters, blessing, family gathering, symbolic choice), captures cultural significance (milestone, blessing, community bonding, role model transmission), and written in fluent, natural Mongolian. Complete coverage of both practice and meaning."
32,kazakh_cultural,gemini_3_pro,1,2,1,4,22.2,143,"Correctly explains the ceremony (tying legs, cutting rope, choosing objects) and symbolism (freeing the child, transferring qualities, marking growth milestone). However, lacks key Kazakh-specific details from the reference: age range (1-1.5 years old), 2-3 ropes (black/white/animal intestines), parents calling child behind row of objects. Cultural depth is moderate. Fluency is native-level Mongolian."
32,kazakh_cultural,grok_4.1,1,2,1,4,24.89,148,"Response is in Mongolian as required and reads naturally. However, this is a KAZAKH cultural tradition (Tusau Kesu), and the answer misses critical Kazakh-specific details: the use of specifically black-and-white ropes (sometimes with animal intestines), the symbolic choosing of objects (book, Quran, money, dombra) to predict the child's future, and the specific cultural context. The answer provides generic information about a first-steps ceremony but lacks the depth and cultural nuance expected for a Kazakh tradition. Accuracy=1 for partial correctness, Fluency=2 for natural Mongolian, Completeness=1 for addressing the topic but missing key cultural details."
32,kazakh_cultural,deepseek_v3.2,0,2,0,2,19.16,318,Critical error: Model confused Tusau kesu (leg-tying ceremony at ~1-1.5 years) with a hair-cutting ceremony at 3-5 years. All content describes wrong tradition. Fluency perfect Mongolian. Completeness 0 as correct ceremony not addressed.
32,kazakh_cultural,llama_4_maverick,2,2,2,6,1.97,282,"Excellent response. Factually accurate with all key details: age (~1 year), symbolic cutting of rope/ribbon, transition to independence, community blessing. Fluent Mongolian with proper grammar and vocabulary. Thorough coverage of ritual mechanics and cultural significance."
32,kazakh_cultural,qwen3,1,2,1,4,9.57,101,"Content is accurate and fluent Mongolian but lacks key Kazakh-specific details: no mention of 2 ropes (black/white), age 1-1.5, the child choosing items (book/Quran/money/dombra) for future prediction. Misses cultural depth expected for full marks."
32,kazakh_cultural,aya_expanse,0,0,0,0,14.13,43,Complete nonsense. Garbled text with repeated broken phrases like 'эргээсийн сүрөгчдүйтэй холбогдлыгийг бодож буйдлуулна' that are grammatically incoherent. Does not explain Tusau Kesu ceremony (rope cutting for toddlers) at all. Appears to be severe translation corruption or hallucination.
33,kazakh_cultural,claude_opus_4.5,2,2,2,6,20.91,109,"Excellent answer with correct details on all three zhuz: location, economy, status, and major tribes. Fluent Mongolian. Comprehensive."
33,kazakh_cultural,gpt_5.2,2,2,2,6,156.78,218,"Excellent detailed answer covering geographic distribution, historical/political context, tribal composition, and social organization of the three Kazakh zhuz. Culturally nuanced and comprehensive. Natural Mongolian fluency."
33,kazakh_cultural,gemini_3_pro,2,2,2,6,19.04,153,Excellent response. Correctly identifies all three jüz with proper geographic locations and cultural/historical context. Fluent Mongolian with proper terminology. Addresses all key aspects comprehensively.
33,kazakh_cultural,grok_4.1,2,2,2,6,27.76,142,"Excellent response with accurate details on all three zhuz including locations, tribes, influences, and lifestyle patterns. The table format enhances clarity. Culturally nuanced and comprehensive."
33,kazakh_cultural,deepseek_v3.2,2,2,2,6,14.86,141,"Excellent response. Correctly identifies all three juz (Senior/Uly, Middle/Orta, Junior/Kishi), their geographic locations, explains tribal structure differences, mentions cultural/dialect variations, and historical-political roles. Fluent Mongolian with proper terminology. Fully addresses the question with good depth."
33,kazakh_cultural,llama_4_maverick,2,2,2,6,1.34,76,"Excellent response. Accurately identifies the three zhuz (Senior/Ulы, Middle/Orta, Junior/Kishi), correctly describes their geographic locations (SE, central/east, west Kazakhstan), and mentions tribal affiliations and cultural/political differences. Fluent Mongolian with no Kazakh interference. Fully addresses the question with appropriate detail."
33,kazakh_cultural,qwen3,2,2,2,6,27.6,159,"Excellent answer. Factually accurate, covers all three zhuz with correct geographic locations and cultural/historical distinctions. Natural Mongolian fluency. Thorough explanation addressing the question fully."
33,kazakh_cultural,aya_expanse,0,0,0,0,8.32,29,"Response is completely garbled and unreadable. Does not identify the three Kazakh zhuz (Uly/Senior, Orta/Middle, Kishi/Junior) or their geographic/tribal differences. Appears to be machine translation gone wrong with nonsensical Mongolian text. Wrong content, wrong structure, incomprehensible."
34,kazakh_cultural,claude_opus_4.5,2,2,2,6,27.66,135,"Excellent response. Factually accurate (dates, major works, cultural significance all correct), fluent natural Mongolian with no code-switching or errors, and thoroughly addresses all aspects of the question with appropriate detail. Correctly identifies him as founder of modern Kazakh literature, mentions Kara Sözder, translations, music, and cultural legacy."
34,kazakh_cultural,gpt_5.2,2,2,2,6,29.39,256,"Excellent response. Factually accurate covering Abai's life (1845-1904), his role as poet/philosopher/composer/educator, his literary works including poetry, Kara Sozder, translations, and music. Culturally appropriate depth. Fluent Mongolian with proper technical vocabulary. Complete coverage of all aspects of the question."
34,kazakh_cultural,gemini_3_pro,2,2,2,6,19.87,135,"Excellent response. Factually accurate covering Abai's role as poet, composer, philosopher, founder of modern Kazakh literature. Mentions Қара сөз (Words of Edification), poetry themes, translations of Pushkin/Lermontov/Goethe, and music. Fluent Mongolian with proper terminology. Complete coverage of his literary legacy."
34,kazakh_cultural,grok_4.1,1,2,1,4,20.9,77,"Fluency natural Mongolian. Accuracy partial: correctly identifies Kara Sözder (Mэргэн үгс) as key work and mentions poetry/prose, but misses core facts—does not explicitly state Abai was founder of written Kazakh literature, first classic, poet/composer/philosopher, or that his poetry grew from folk culture and was mostly oral before him. Completeness partial: gives some literary details but omits central role in Kazakh identity and foundational status."
34,kazakh_cultural,deepseek_v3.2,2,2,2,6,11.7,210,"Excellent answer with correct facts (1845-1904, founder of modern Kazakh lit, Kara Sozder/Book of Words, themes, translations). Final Mongolian translation is natural and fluent. All key points covered thoroughly."
34,kazakh_cultural,llama_4_maverick,1,2,1,4,1.65,178,"Correct basic facts (poet, philosopher, composer, 1845, importance to Kazakh literature) but missing key details from reference answer: he founded written Kazakh literature, his Book of Words, encouragement of education/literacy/moral character to escape poverty/corruption, exploration of 19th century Kazakh national life, transition from oral to written poetry, connection to nomadic culture. Fluency is natural Mongolian. Completeness partial due to lack of depth on his specific literary legacy and cultural impact."
34,kazakh_cultural,qwen3,2,2,2,6,13.1,110,"Excellent response. Factually accurate with correct dates (1845-1904), correctly identifies Abai as poet/philosopher/composer/cultural reformer, mentions key works ('Қара сөздер'), translations of Pushkin/Lermontov, and thematic emphasis on humanism/knowledge/justice. Fluent natural Mongolian with no Kyrgyz markers. Fully addresses all parts of the question with cultural depth."
34,kazakh_cultural,aya_expanse,0,0,0,0,18.95,44,"Response is in Kyrgyz, not Mongolian. Uses 'кылып', 'жаңылыгына', lacks Mongolian-specific particles. Should be Mongolian. Wrong language = Fluency 0. Content also generic/incomplete = Accuracy 0, Completeness 0."
35,kazakh_cultural,claude_opus_4.5,0,2,1,3,10.36,45,"Completely wrong members listed. Ground truth: Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov. Model gave: Erlan Kokeev, Baurzhan Ispanov, Madi Bayboldin, Hafiz Kuat. Fluent Mongolian but factually incorrect."
35,kazakh_cultural,gpt_5.2,1,2,2,5,4.11,25,"Lists 3 members fluently in Mongolian with good detail, but includes Qairat Baibosynov instead of Kenzhebek Zhanabilov—partially correct (2/3 members correct)."
35,kazakh_cultural,gemini_3_pro,2,2,2,6,11.65,21,"Correct members all named, natural Mongolian, fully addresses question"
35,kazakh_cultural,grok_4.1,0,2,1,3,16.74,53,"Completely wrong names. Reference says Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov. Model gives Almas Keshubaev, Isabek Kemertaliev, Erbolat Sarkulov, Adilet Oralbaev, Azamat Zhanbyrbaev. Appears to be hallucinated or outdated info. Fluent Mongolian prose with disclaimer about changes, hence C=1 not 0."
35,kazakh_cultural,deepseek_v3.2,0,2,1,3,6.94,40,"Wrong members named. Answer says Arsen Gitinov and Madi Zhumabayev, but correct members are Meyrambek Besbaev, Saken Maygaziev, and Kenzhebek Zhanabilov. Fluency is natural Mongolian. Provides some detail but factually incorrect."
35,kazakh_cultural,llama_4_maverick,0,2,2,4,0.93,32,"Completely incorrect information. Claims MuzART is three sisters (Dina, Alma, Kuralai) when correct answer is three male musicians (Besbaev, Maygaziev, Zhanabilov). Pure hallucination. Fluent Mongolian, thorough format, but factually wrong."
35,kazakh_cultural,qwen3,0,2,1,3,8.6,71,"Completely incorrect: names Aidos Sarsenov and Saltanat Sarsenova instead of Meyrambek Besbaev, Saken Maygaziev, Kenzhebek Zhanabilov. Fluent Mongolian with no Kyrgyz markers. Partial completeness as it discusses the band but with wrong members."
35,kazakh_cultural,aya_expanse,0,0,0,0,4.41,39,"Response is completely garbled/broken Mongolian, unreadable. Does not answer the question at all. No band member names provided. Appears to be machine translation artifacts or corrupted text."
36,kazakh_cultural,claude_opus_4.5,2,2,2,6,13.43,71,"Perfect response: all 6 historical names correct with dates and meanings, fully accurate translation into Mongolian, natural fluency, thorough coverage"
36,kazakh_cultural,gpt_5.2,1,2,1,4,5.0,21,"Missing earliest names: Akmoly (1830), Akmolinsk started 1832 not 1961. Lists only Soviet-era onward. Fluent Mongolian, partial info."
36,kazakh_cultural,gemini_3_pro,2,2,2,6,14.68,39,"Correct, fluent, thorough. Covers all historical names with dates matching answer sheet."
36,kazakh_cultural,grok_4.1,1,2,1,4,11.44,56,"Fluency excellent. Accuracy partial: includes correct names (Astana, Nur-Sultan) but misses early names (Akmola/Akmolinsk 1830-1997, Tselinograd 1961-1992) and incorrectly adds Orynbor/Kyzyl-Orda (those were Kazakhstan SSR capitals, not today's capital city's names). Completeness partial: addresses question but incomplete list."
36,kazakh_cultural,deepseek_v3.2,1,2,1,4,12.3,57,"Correct cities mentioned (Nur-Sultan/Astana, Almaty, Kyzylorda) but misses many historical names: Akmoly, Akmolinsk, Tselinograd, Aqmola. Dates partially wrong (Almaty was capital 1929-97 is correct, but omits earlier names). Fluency is natural Mongolian. Partial completeness due to missing key names."
36,kazakh_cultural,llama_4_maverick,2,2,2,6,1.35,83,"Correct, covers all major name changes (Akmolinsk, Tselinograd, Akmola, Astana, Nur-Sultan, back to Astana). Natural Mongolian. Thorough."
36,kazakh_cultural,qwen3,2,2,2,6,18.35,58,"Fully accurate with all major name changes (Akmolinsk, Tselinograd, Akmola, Astana, Nur-Sultan, back to Astana). Fluent natural Mongolian. Complete coverage."
36,kazakh_cultural,aya_expanse,0,0,0,0,8.21,12,"Response is in Kyrgyz, not Mongolian. Uses 'менен' (Kyrgyz) instead of Mongolian grammar. Wrong language = Fluency 0. Content vague/generic, doesn't list capital names = Accuracy 0, Completeness 0."
37,kazakh_cultural,claude_opus_4.5,0,2,0,2,21.93,109,"Wrong language - this is actually a Kazakh cultural dish (Nauryz kozhe), not Mongolian. The question asks how to make a Kazakh dish. The response is fluent Mongolian but describes a Kazakh recipe, not answering what was asked. Kazakh answer sheet shows detailed cooking instructions with appliance settings; this gives generic steps without cultural context or proper detail."
37,kazakh_cultural,gpt_5.2,1,2,1,4,28.61,187,"Response is in Mongolian as required. Content describes a generic fermented dairy soup with grains, which is conceptually related to Navruz köje but lacks key Kazakh-specific details: no mention of 7 ingredients (symbolic for Navruz), missing specific Kazakh dairy products like қурт or süzbe, no cultural context. Recipe steps are clear and natural but too generic. Partial accuracy due to missing cultural/symbolic significance and incomplete ingredient list."
37,kazakh_cultural,gemini_3_pro,1,0,1,2,19.68,106,"Answer is in ENGLISH, not Mongolian. Should be fluent Mongolian. Content partially correct (describes basic cooking steps) but incomplete—misses key ingredients (7 components: water, meat, millet, wheat, rice, fat, kefir, salt) and lacks cultural context. Fluency=0 due to wrong language. Final Mongolian fragment is cut off mid-sentence."
37,kazakh_cultural,grok_4.1,0,2,0,2,32.99,194,"Wrong dish entirely. Question asks for Kazakh 'Nauryz kozhe' (meat/grain soup with 7 ingredients), but response describes a sweet porridge/pudding with milk, sugar, dried fruits. Content is completely incorrect despite fluent Mongolian and thorough formatting."
37,kazakh_cultural,deepseek_v3.2,1,2,2,5,87.83,164,"Fluent Mongolian. Recipe is detailed and culturally appropriate, BUT the traditional Nauryz Kozhe recipe requires 7 specific ingredients (symbolizing completeness) and typically includes meat broth, dairy (kefir/kurt), and grains like millet, wheat, rice cooked together - not a soup with potatoes/carrots/vegetables. The reference emphasizes the symbolic '7 ingredients' and specific cooking method (soaking grains, cooking meat separately, combining with dairy). This response reads like a generic Central Asian soup recipe rather than the specific traditional Nauryz Kozhe, missing key cultural/preparation details."
37,kazakh_cultural,llama_4_maverick,2,2,2,6,1.25,73,"Correct recipe with all key elements (7 ingredients, cooking method, cultural significance). Fluent Mongolian. Thorough explanation covering preparation and symbolism."
37,kazakh_cultural,qwen3,0,2,0,2,33.73,107,"Wrong answer. Question asks for Kazakh 'Nauryz kozhe' recipe but response describes generic Mongolian tsuivan/budaatai huurga type dish. Completely misses key Nauryz kozhe ingredients (kefir/ayran added at end, specific 7 sacred ingredients). Fluency is native Mongolian. Critical failure: translated question correctly but generated wrong cultural content."
37,kazakh_cultural,aya_expanse,0,0,0,0,8.0,32,"Garbled nonsense text, not in proper Mongolian. Completely fails to answer how to make Nauryz kozhe. Wrong language quality and zero content."
38,kazakh_cultural,claude_opus_4.5,2,2,2,6,26.84,145,"Excellent response. Factually accurate with detailed coverage of the December 1986 Jeltoqsan uprising including dates, causes (Kolbin replacing Kunaev), protests, casualties, and significance. Fluent Mongolian with proper terminology. Thorough and complete."
38,kazakh_cultural,gpt_5.2,2,2,2,6,14.45,105,"Excellent response. Accurate historical details (December 1986 Jeltoqsan uprising, Kunaev's removal, Kolbin appointment, protests, casualties). Fluent Mongolian with proper terminology. Complete with context and significance. Correctly identifies event, location, causes, and consequences."
38,kazakh_cultural,gemini_3_pro,2,1,2,5,21.32,90,"Content is accurate and thorough, covering Jeltoqsan/December protests in correct detail. However, the response is in ENGLISH for the first paragraph, then switches to Mongolian mid-sentence with an incomplete cut-off. Since target language is Mongolian and the final paragraph is incomplete/truncated, Fluency=1. Accuracy and Completeness both merit 2 based on correct factual content provided."
38,kazakh_cultural,grok_4.1,2,2,2,6,14.55,94,"Excellent response. Covers Jeltoqsan, dates, location, cause (Kolbin replacing Kunayev), protests, casualties (both official and unofficial estimates), and significance. Natural Mongolian with no Kazakh markers."
38,kazakh_cultural,deepseek_v3.2,1,2,1,4,79.8,71,"Factually correct (Dec 1986 Almaty protests by Kazakh youth) but lacks key details like Dinmukhamed Kunaev's replacement by Gennady Kolbin as trigger, the violent crackdown, casualties, and the significance as Jeltoqsan/December uprising. Fluency is natural Mongolian. Partial completeness due to missing important context."
38,kazakh_cultural,llama_4_maverick,2,2,2,6,1.55,66,"Excellent answer. Correct event (Jeltoqsan), correct dates (Dec 16-19, 1986), correct city (Alma-Ata/Almaty), correctly identifies Kunaev's removal and Kolbin's appointment as the cause. Fluent Mongolian with no Kyrgyz/Kazakh confusion. Thorough and complete."
38,kazakh_cultural,qwen3,2,2,2,6,13.81,157,"Excellent response. Correctly identifies Jeltoqsan/December uprising, explains the Kunayev-Kolbin replacement trigger, mentions student protests in Almaty, notes official vs. unofficial death tolls, and recognizes it as a key moment in Kazakh national awakening. Fluent Mongolian throughout. Fully addresses all aspects of the question."
38,kazakh_cultural,aya_expanse,0,1,0,1,8.41,18,"Wrong answer: discusses 1991 independence, not Dec 1986 Jeltoqsan uprising. Fluency partial: readable but unnatural phrasing, garbled text ('түрүүгэ ашигтланыгынан', 'өмчлөгдөөн')."
39,kazakh_cultural,claude_opus_4.5,2,2,2,6,9.84,49,"Correct answer (Nur-Mubarak), proper Mongolian, thorough explanation with location and founding details"
39,kazakh_cultural,gpt_5.2,2,2,2,6,2.68,24,"Correct answer (Nur-Mubarak University), natural Mongolian phrasing, fully addresses question with institutional name and location"
39,kazakh_cultural,gemini_3_pro,2,2,2,6,10.42,42,"Correct institution named (Nur-Mubarak), fluent Mongolian, thorough explanation including location and role"
39,kazakh_cultural,grok_4.1,2,2,2,6,15.55,62,"Correct answer (Nur-Mubarak), natural Mongolian fluency, thorough explanation with founding year and programs. Answer sheet accepts this or SAMK."
39,kazakh_cultural,deepseek_v3.2,2,2,2,6,12.17,53,"Correct answer: Nur-Mubarak University. Response correctly identifies it, provides Kazakh transliteration variants, gives location (Almaty) and brief description. Fluent Mongolian. Fully addresses the question."
39,kazakh_cultural,llama_4_maverick,2,2,2,6,0.62,21,"Correct answer (Nur-Mubarak), natural Mongolian, fully addresses the question"
39,kazakh_cultural,qwen3,0,2,1,3,3.74,42,Fluent Mongolian but factually wrong. Named 'Abai Kazakh Islamic University' which does not exist. Correct answer is SAMK (Spiritual Admin of Muslims of Kazakhstan) or Nur-Mubarak University. Hallucinated institution name.
39,kazakh_cultural,aya_expanse,0,0,0,0,8.2,35,"Wrong language (English instead of Mongolian), completely wrong topic (answered about Kazakhstan's first satellite instead of largest Islamic institution), total hallucination"
40,kazakh_cultural,claude_opus_4.5,2,2,2,6,13.03,60,"Correct answer (Middle zhuz), fluent Mongolian, thorough with historical context"
40,kazakh_cultural,gpt_5.2,2,2,2,6,6.87,60,Correct: Kerei belongs to Middle zhuz. Fluent Mongolian with proper explanation and disclaimer about historical variations. Complete and thorough.
40,kazakh_cultural,gemini_3_pro,2,2,2,6,11.87,38,"Perfect response. Correctly identifies Керей as belonging to Middle zhuz (Дунд жүз/Орта жүз), provides culturally appropriate context about it being a major clan. Natural Mongolian phrasing, no Kazakh/Kyrgyz markers. Complete answer with supporting detail."
40,kazakh_cultural,grok_4.1,2,2,2,6,8.56,56,Perfect answer. Correctly identifies Kerei as Middle zhuz (Orta Juz) in fluent Mongolian with good cultural context.
40,kazakh_cultural,deepseek_v3.2,2,2,2,6,76.3,44,"Correct answer (Middle zhuz/Orta jüz), fluent Mongolian, includes helpful context about the three zhuz system"
40,kazakh_cultural,llama_4_maverick,2,2,2,6,0.83,38,"Correct (Middle zhuz/Orta zhuz), fluent Mongolian, fully addresses the question."
40,kazakh_cultural,qwen3,0,2,1,3,12.57,51,"Fluent Mongolian but factually wrong. Kerei belongs to Middle zhuz (Orta juz), not Senior zhuz (Uly juz/Том жүз). Answer states Том жүзэнд which is incorrect."
40,kazakh_cultural,aya_expanse,0,0,0,0,5.55,19,"Wrong answer (should be Middle/Orta zhuz for Kerei), wrong language (appears Kazakh not Mongolian), wrong format (lists unrelated names). Fluency=0 per rubric rule 4."
41,mongolian_cultural,claude_opus_4.5,2,2,2,6,27.02,132,"Excellent response. Accurately describes all three games (wrestling, horse racing, archery), their characteristics, and cultural significance. Provides additional historical context (Chinggis Khan era, Independence Day July 11-13) and connects to nomadic lifestyle and military training traditions. Well-structured, natural Mongolian, and thorough."
41,mongolian_cultural,gpt_5.2,2,2,2,6,14.86,108,"Excellent response. All three games correctly identified with rich cultural context. Covers nomadic heritage, warrior traditions, unity with horses, archival skills, and connection to independence celebrations. Natural Mongolian phrasing throughout."
41,mongolian_cultural,gemini_3_pro,2,2,2,6,29.08,161,"Excellent response. Correctly identifies the three games (wrestling, horse racing, archery) with culturally appropriate details. Explains historical military training significance and cultural importance. Natural Mongolian phrasing, no signs of wrong language or errors."
41,mongolian_cultural,grok_4.1,2,2,2,6,19.34,176,"Excellent response. Provides accurate details on all three Naadam sports (wrestling, horse racing, archery), explains their cultural significance, mentions UNESCO recognition, and includes rich cultural context about titles, distances, and traditions. Fluent Mongolian with proper terminology."
41,mongolian_cultural,deepseek_v3.2,2,2,2,6,17.62,84,"Excellent response. Correctly identifies all three manly games (horse racing, archery, wrestling), explains their significance in detail, connects them to nomadic heritage and national identity, and mentions UNESCO recognition. Fluent Mongolian with proper terminology. Fully addresses all parts of the question."
41,mongolian_cultural,llama_4_maverick,2,2,2,6,1.24,66,"Correct identification of the three manly games (archery, horse racing, wrestling). Provides good cultural context about skills demonstrated and their place in Mongolian tradition. Natural Mongolian phrasing throughout."
41,mongolian_cultural,qwen3,1,2,1,4,25.82,214,"Fluency is natural Mongolian. Accuracy: partially correct—lists бөх (wrestling), морины урилдаан (horse racing), and сур харваа (archery), which matches the reference. However, contains some factual errors: states archery allows both men and women but traditionally only men compete in 'эрийн гурван наадам' (wrestling, horse racing, archery are the three 'manly games'—women's archery is a separate modern addition). Completeness: addresses the question with cultural context but lacks depth on the symbolic/philosophical aspects mentioned in the reference (connection to nature, home-schooling transmission, respect for environment). Overall: good cultural overview but misses some nuance and has minor factual issues."
41,mongolian_cultural,aya_expanse,0,0,0,0,12.91,48,"Complete gibberish. Text is broken, repetitive, unintelligible. Contains fabricated words like 'бааримтнasan', 'жавхлантан'. Does not mention horse racing, wrestling, or archery at all. No meaningful content."
42,mongolian_cultural,claude_opus_4.5,2,2,2,6,27.89,167,"Excellent response. Comprehensive coverage of ger structure (toono, uni, khana, bagana, door, esgi) and symbolism (circular form=eternity, toono=sun/sky portal, gender divisions left/right, khoimor for elders, hearth=family heart, vertical axis linking earth/heaven/underworld). Well-organized table and bullet points. Native-level Mongolian fluency. Fully addresses both structure and symbolism as requested."
42,mongolian_cultural,gpt_5.2,2,2,2,6,36.16,256,"Excellent response. Covers structure (хана, хаалга, багана, тооно, унь, бүрээс, голомт) and symbolism (circular shape=unity, тооно=connection to sky, голомт=family center, direction/layout=social order, portability=nomadic adaptability). Matches reference answer's depth. Natural Mongolian with proper terminology. Fully addresses both structure and symbolic meaning."
42,mongolian_cultural,gemini_3_pro,2,2,2,6,20.43,117,"Excellent response covering structure (toono, uni, khana, bagana, door, covering) and symbolism (toono=sky/sun, floor=earth, cosmic representation). Matches reference answer's key elements including directional significance, materials, and philosophical meaning. Natural Mongolian, complete coverage."
42,mongolian_cultural,grok_4.1,2,2,2,6,32.06,181,"Excellent response with accurate structural details (door orientation, floor, furniture placement, assembly time/weight), rich symbolic meanings (circular shape=eternal cycle, toono=heaven/28 rafters=lunar mansions, directional colors, smoke hole=spiritual path), and mentions both Buddhist and shamanistic cosmology. Covers all major aspects thoroughly and fluently in Mongolian."
42,mongolian_cultural,deepseek_v3.2,2,2,2,6,15.37,95,"Excellent answer. Covers structure (round, wooden frame, felt cover, toono, direction), symbolism (cosmos, sacred hearth, spatial order by gender/age, harmony with nature). Natural Mongolian. Fully addresses all parts."
42,mongolian_cultural,llama_4_maverick,1,2,1,4,2.78,168,"Factually correct basics (frame, felt, door orientation, west side sacred) but lacks key symbolic details from answer sheet: toono as sun/portal, bagana pillars as heaven-earth link, golomt/hearth as family heart, rafter numbers (81=9x9), color symbolism (orange=sun/fire, blue=eternal sky). Fluent natural Mongolian. Addresses question but missing depth."
42,mongolian_cultural,qwen3,1,2,1,4,40.25,181,"Correct language (Mongolian). Describes ger structure accurately (khana, uni, toono, door, felt covering) with good technical vocabulary. However, missing key symbolic elements from reference: cosmos/universe representation, center/golomt (stove as heart), pillars as sacred earth-sky link, numbers/rafters significance, colors (orange=sun/fire, blue=eternal sky). Covers physical structure well but underdevelops spiritual/philosophical symbolism that reference emphasizes. Fluency excellent, completeness partial."
42,mongolian_cultural,aya_expanse,0,0,0,0,27.97,60,"Complete hallucination. Response is nonsensical Mongolian text about 'types of questions' and 'initiatives/sequences', totally unrelated to ger structure/symbolism. Wrong topic entirely."
43,mongolian_cultural,claude_opus_4.5,2,2,2,6,20.7,94,"Excellent response. Covers all key points: spiritual connection to nature, cultural heritage, worldview expression, national pride/UNESCO recognition, and nomadic lifestyle symbolism. Natural Mongolian throughout. Matches/exceeds reference answer depth."
43,mongolian_cultural,gpt_5.2,2,2,2,6,14.86,148,"Excellent response. Covers spiritual connection to nature/ancestors, cultural memory transmission, community bonding, and role as identity symbol both domestically and internationally. Fluent, natural Mongolian with proper terminology. Fully addresses the question with appropriate depth."
43,mongolian_cultural,gemini_3_pro,2,2,2,6,20.24,130,"Excellent response. Accurately describes khöömei's role in Mongolian identity: connection to nature (mimicking wind, water, birds), spiritual expression (respect for land spirits), and cultural identity (nomadic wisdom). Fluent Mongolian with proper vocabulary. Thorough coverage of all key aspects."
43,mongolian_cultural,grok_4.1,2,2,2,6,23.56,120,"Excellent response. Culturally rich, accurate details about throat singing's connection to nature, spirituality, nomadic identity. Natural Mongolian, thorough coverage of all symbolic dimensions."
43,mongolian_cultural,deepseek_v3.2,0,2,1,3,11.49,94,"Response is fluent Mongolian but completely generic about 'throat singing' as vocal music/oral literature. Misses ALL key facts: хөөмий technique, natural sound mimicry, 4 types (хархираа, исгэрээ, нармай, шахай), cultural/spiritual connection to nomadic landscape, Chandmani origins, groups like Altai Urag. Treats 'throat singing' as ordinary vocal expression rather than the unique overtone singing tradition. Accuracy=0 for failing to describe the actual phenomenon."
43,mongolian_cultural,llama_4_maverick,0,2,0,2,1.55,97,Complete hallucination. Question asks about throat singing (хөөмий) but response discusses vocal tone/intonation in social contexts. Fluent Mongolian but entirely wrong content.
43,mongolian_cultural,qwen3,1,2,1,4,6.05,58,"Correct language (Mongolian). Mentions throat singing (хөөмий) and long song (уртын дуу), connection to nature/spirituality, cultural identity - all accurate but lacks depth. Missing key details: mimicking nature sounds (wind/water/animals), nomadic heritage, spiritual connection to landscape, community bonding. Phrasing is natural but content is general/surface-level."
43,mongolian_cultural,aya_expanse,0,0,0,0,18.95,148,"Complete failure: garbled, repetitive nonsense text. Not coherent Mongolian. Does not address throat singing (хөөмий) or its cultural role. Pipeline breakdown or severe model malfunction."
44,mongolian_cultural,claude_opus_4.5,0,2,0,2,19.67,65,"Model refuses to answer, claiming lack of up-to-date info. Ground truth: Hazara restaurant at BZD-6 khoroo. Fluency is natural Mongolian but answer is wrong/incomplete."
44,mongolian_cultural,gpt_5.2,1,2,1,4,9.12,96,Answer is partially correct—confirms Indian restaurants exist near Bөхийн өргөө but fails to name the specific one (Hazara) given in answer sheet. Fluency is natural Mongolian. Completeness partial: addresses question but lacks key detail (the actual restaurant name/address).
44,mongolian_cultural,gemini_3_pro,2,2,2,6,14.14,45,"Correct: mentions Hazara near Bohiin Orgoo with location details. Adds Namaste as bonus. Natural Mongolian, thorough answer."
44,mongolian_cultural,grok_4.1,0,2,1,3,12.0,62,"Factually incorrect: says no Indian restaurant near Bökhiin Örgöö, but answer sheet clearly states Hazara restaurant is located there (BZD - 6 khoroo). Fluent Mongolian but wrong information."
44,mongolian_cultural,deepseek_v3.2,1,2,1,4,78.55,134,Partially correct: mentions generic Indian restaurants but misses the specific ground-truth answer 'Hazara - BZD'. Fluency is natural Mongolian. Completeness partial: provides general guidance but lacks the precise location from answer key.
44,mongolian_cultural,llama_4_maverick,0,2,0,2,0.98,54,"Model refused to answer the factual question, instead providing generic advice about using Google Maps. Ground truth specifies 'Hazara - BZD - 6-хороо, Улаанбаатар 13373, Монгол'. Response is fluent Mongolian but completely misses the actual answer."
44,mongolian_cultural,qwen3,0,2,1,3,4.58,43,"Answer is factually incorrect. Ground truth states Hazara restaurant at BZD 6-khoroo near Bökh Örgöö. Model claims no Indian restaurant nearby and names wrong restaurants (Everest, Namaste) in different areas. Fluency is native-level Mongolian. Completeness partial as it attempts to address the question but with wrong information."
44,mongolian_cultural,aya_expanse,0,0,0,0,5.33,26,"Complete nonsense. Wrong language structure, garbled text, doesn't answer the question. Answer sheet says 'Hazara - BZD - 6-хороо, Улаанбаатар 13373, Монгол'. This response is unreadable gibberish."
45,mongolian_cultural,claude_opus_4.5,2,2,2,6,12.2,50,"Perfect answer with correct date (April 13, 2012) and good contextual detail about corruption charges. Natural Mongolian fluency."
45,mongolian_cultural,gpt_5.2,2,2,2,6,1.99,16,"Perfect: correct date (April 13, 2012), natural Mongolian, fully addresses question"
45,mongolian_cultural,gemini_3_pro,2,2,2,6,10.34,16,"Perfect answer. Correct date (April 13, 2012), natural Mongolian phrasing, complete response."
45,mongolian_cultural,grok_4.1,2,2,2,6,9.84,29,"Perfect answer. Correct date (April 13, 2012), natural Mongolian, adds relevant context about corruption charges without being excessive."
45,mongolian_cultural,deepseek_v3.2,0,2,0,2,6.6,17,"Model refused to answer a factual historical question (Enkhbayar's arrest date: April 13, 2012). Response is fluent Mongolian but provides zero information. Refusal = 0/0/0 per rules."
45,mongolian_cultural,llama_4_maverick,0,2,2,4,0.62,21,"Wrong date: model says August 13, 2012; correct answer is April 13, 2012. Fluent Mongolian, complete sentence, but factually incorrect."
45,mongolian_cultural,qwen3,0,2,2,4,2.72,19,"Wrong date: gives July 29, 2012 instead of correct April 13, 2012. Fluent Mongolian, thorough answer with context, but factually incorrect."
45,mongolian_cultural,aya_expanse,0,0,0,0,3.5,17,"Response is the question itself repeated, not an answer. Wrong: English says 'born' not 'arrested'. Score 0/0/0."
46,mongolian_cultural,claude_opus_4.5,0,2,0,2,21.63,60,"Model refuses to answer, says it lacks 2024/25 season data. Correct answer is SP Falcons. Fluent Mongolian but no useful content."
46,mongolian_cultural,gpt_5.2,0,2,0,2,3.97,41,"Model refuses to answer, claims lack of current information. Fluent Mongolian but provides no useful information."
46,mongolian_cultural,gemini_3_pro,1,2,1,4,14.99,37,"Correct answer (SP Falcons) buried in hedged text claiming season unfinished. Actually 24/25 season ended, SP Falcons won. Partial credit for right team but wrong reasoning."
46,mongolian_cultural,grok_4.1,1,2,1,4,9.94,62,"Model states 24/25 season ongoing (Oct 2024 data), says SP Falcons leading but champion not yet determined. Answer sheet says SP Falcons won. Model has outdated info but mentions correct team; partial credit for Accuracy and Completeness. Fluency perfect."
46,mongolian_cultural,deepseek_v3.2,0,2,1,3,76.17,46,"Model refuses to answer, claiming no information available, when correct answer is SP Falcons. Mongolian is fluent and natural. Partial completeness for explaining how to find info, but fundamentally incorrect claim that data is unavailable."
46,mongolian_cultural,llama_4_maverick,0,2,0,2,0.78,21,Model refused to answer citing knowledge cutoff. Response is fluent Mongolian but provides no factual information. Correct answer: SP Falcons
46,mongolian_cultural,qwen3,0,2,1,3,5.54,28,"Factually incorrect. Answer sheet states SP Falcons won 24/25 season. Model claims season not finished. Fluent Mongolian, but wrong content."
46,mongolian_cultural,aya_expanse,0,0,0,0,10.56,24,"Wrong language (likely Kyrgyz or garbled), completely off-topic rambling about clubs from 2000-2001, does not answer which team won 24/25 MPL. Total failure."
47,mongolian_cultural,claude_opus_4.5,0,2,2,4,21.93,71,"Model claims ~330-340 companies listed on MSE as of 2024. Ground truth is ~186. The response is fluent in Mongolian and provides thorough detail about MSE history and sectors, but the core numerical answer is completely wrong—nearly double the correct figure. Accuracy=0 for factual error."
47,mongolian_cultural,gpt_5.2,0,2,0,2,6.96,78,"Model refuses to answer, claims it lacks real-time data, and redirects to check official MSE website. Ground truth is ~186 companies. Response is fluent Mongolian but provides zero factual content."
47,mongolian_cultural,gemini_3_pro,2,2,2,6,16.9,56,"Correct answer (~180 matches ground truth ~186 closely), natural Mongolian, thorough explanation with additional context about MSE classifications"
47,mongolian_cultural,grok_4.1,2,2,2,6,10.35,57,"Correct answer (~193 very close to ~186), fluent Mongolian, thorough explanation with source citation"
47,mongolian_cultural,deepseek_v3.2,1,2,2,5,11.69,52,"Answer says ~200 companies, reference says ~186. Close but not exact. Fluency is natural Mongolian. Completeness is thorough with caveat about changing numbers and suggestion to check official sources."
47,mongolian_cultural,llama_4_maverick,1,2,1,4,1.03,66,"Answer is 234, correct answer is ~186. Partially correct—in the right ballpark but wrong number. Fluency is natural Mongolian. Completeness is partial—provides context but the core number is off."
47,mongolian_cultural,qwen3,0,2,1,3,8.21,36,"Wrong number: says ~300 companies (and ~50-60 active), correct answer is ~186. Fluency is natural Mongolian. Completeness partial: provides some context about active vs listed but the core fact is incorrect."
47,mongolian_cultural,aya_expanse,0,0,0,0,13.53,30,"Completely garbled, unreadable Mongolian. No meaningful answer about stock exchange listings. Appears to be machine translation artifacts or corrupted text."
48,mongolian_cultural,claude_opus_4.5,2,2,2,6,17.11,50,"Perfect answer: correctly states Төв аймаг surrounds Ulaanbaatar, adds helpful context about geography and administrative status. Natural Mongolian, fully addresses the question."
48,mongolian_cultural,gpt_5.2,2,2,2,6,2.38,13,"Correct answer (Төв), natural Mongolian, fully addresses the question."
48,mongolian_cultural,gemini_3_pro,2,2,2,6,9.65,13,"Perfect answer: correctly identifies Töv as the province surrounding Ulaanbaatar, natural fluent Mongolian, complete response"
48,mongolian_cultural,grok_4.1,1,2,1,4,12.41,49,"Correct core answer (Töv) but adds incorrect info: UB is NOT surrounded by Selenge, Darkhan-Uul, or Bulgan—only Töv. Fluency is native-level Mongolian. Partial accuracy/completeness due to extraneous incorrect details."
48,mongolian_cultural,deepseek_v3.2,2,2,2,6,8.51,76,"Perfect answer. States Töv Province surrounds UB, adds helpful context about central location and no other borders. Pipeline steps visible but final Mongolian answer is complete, accurate, and fluent."
48,mongolian_cultural,llama_4_maverick,2,2,2,6,0.4,41,Correct answer (Töv/Төв). Pipeline steps visible but final Mongolian output is fluent and complete.
48,mongolian_cultural,qwen3,2,2,2,6,2.88,12,"Correct answer (Төв), natural Mongolian fluency, complete response"
48,mongolian_cultural,aya_expanse,0,0,0,0,13.49,30,"Completely wrong answer, garbled text. Question asks which province surrounds Ulaanbaatar (correct: Töv). Response is unintelligible gibberish listing random words (center, culture, sport, market, etc.) with no mention of Töv province. Fluency=0 for broken/unreadable Mongolian with nonsensical word salad."
49,mongolian_cultural,claude_opus_4.5,2,2,2,6,24.19,113,"Excellent response. Accurately describes khuushuur preparation with correct ingredients and steps. Correctly identifies Naadam (July 11-13) as the primary eating occasion. Fluent, natural Mongolian with no Kazakh contamination. Fully addresses both parts of the question."
49,mongolian_cultural,gpt_5.2,2,2,2,6,19.47,148,"Excellent response. Accurately describes khuushuur preparation (dough, ground meat filling, half-moon shape, deep frying) and when it's eaten (daily meals with tea, Naadam festival, celebrations). Natural Mongolian fluency, thorough coverage of both parts of the question."
49,mongolian_cultural,gemini_3_pro,2,2,2,6,25.4,93,"Excellent response. Accurately describes khuushuur preparation (dough, ground meat filling, folding and frying). Correctly identifies it's eaten year-round but especially at Naadam in July. Culturally appropriate, factually correct, and comprehensive."
49,mongolian_cultural,grok_4.1,0,2,0,2,24.28,205,"Wrong dish: describes BUUZ (steamed dumplings) not KHUUSHUUR (fried meat pancakes). Answer says steam 15-20 min, mentions Tsagaan Sar. Ground truth: khuushuur is fried in oil, eaten at Naadam. Fluency perfect, but completely wrong content."
49,mongolian_cultural,deepseek_v3.2,1,2,1,4,13.4,49,"Good fluency but contains major factual errors: says khushuur is steamed (15-20 min in air), when it's actually fried in oil. Also associates it with Tsagaan Sar instead of Naadam. Correct on meat+onion filling but wrong cooking method is critical. Partial credit for structure/some content."
49,mongolian_cultural,llama_4_maverick,1,2,1,4,1.36,63,"Fluency is natural. However, major factual errors: states khuushuur is 'often boiled but in Mongolia usually fried' (contradictory/confusing), claims it's eaten at Tsagaan Sar (incorrect—primarily Naadam). Answer sheet: khuushuur is fried in oil/animal fat, eaten often at restaurants but especially at Naadam. Missing key details about half-circle shape, pinching method, and Naadam as the main context. Partial accuracy for frying method but wrong cultural context."
49,mongolian_cultural,qwen3,1,2,1,4,8.62,82,"Fluent Mongolian. Accurate on basic preparation (ground meat, dough, fried) but misses key details: mixing flour with water/eggs, spreading into circle, pinching closed to form half-moon, frying in oil/animal fat. Crucially OMITS Naadam as the main occasion (answer sheet: 'Khuushuur makes its biggest appearance at Naadam, where it is a staple'). Mentions Tsagaan Sar and family gatherings (acceptable) but not Naadam (critical cultural context). Completeness partial due to missing preparation steps and Naadam."
49,mongolian_cultural,aya_expanse,0,0,0,0,9.29,22,"Response is completely off-topic. Lists unrelated words (document, scholarly, resource, variables/ideas) instead of explaining how to make khuushuur or when it is eaten. Does not address the question at all."
50,mongolian_cultural,claude_opus_4.5,0,2,1,3,18.54,72,"Wrong rank. Answer states 'Заан' (Elephant) is 4th highest, but correct answer is 'Улсын арслан' (State Lion). Fluency is perfect Mongolian. Partial completeness for structure but wrong content."
50,mongolian_cultural,gpt_5.2,0,2,2,4,8.41,83,"Wrong answer. States 4th rank is Khartsaga (Hawk, 6 wins). Correct is Ulsin Arslan (State Lion, 1 win). Fluent Mongolian, thorough explanation, but factually incorrect."
50,mongolian_cultural,gemini_3_pro,0,2,2,4,18.85,33,"Wrong answer. Q asks for 4th highest rank. Response lists Ulsan Zaan (Elephant) as 4th with 7 wins required. Correct answer is Ulsan Arslan (State Lion) with 1 win in National Naadam. Fluency is natural Mongolian, completeness addresses all parts of question with detail, but factually incorrect."
50,mongolian_cultural,grok_4.1,0,2,1,3,25.82,56,"Wrong rank. Answer describes requirements for a lower title (likely Hartsaga or Zaan). Q50 asks for 4th highest rank = State Lion (Улсын арслан), requiring only 1 win at National Naadam. This response lists multi-level requirements (provincial wins, 5th place, 32+ matches) that don't match State Lion. Fluent Mongolian but factually incorrect."
50,mongolian_cultural,deepseek_v3.2,0,2,1,3,10.74,58,Wrong title. Says 4th rank is 'Zaan' (Elephant) requiring 512 wins. Correct is 'Ulsyn Arslan' (State Lion) with 1 Naadam win. Fluent Mongolian but factually incorrect.
50,mongolian_cultural,llama_4_maverick,0,2,1,3,1.34,52,"Fluency perfect, but factually wrong. Claims 'Arslан' (3rd rank) instead of 'Улсын арслан' (4th rank = State Lion). Also wrong provision: says 3 Naadam wins or 3 top-8 finishes, but correct answer is 1 win at National Naadam. Accuracy=0 for wrong rank and wrong requirement."
50,mongolian_cultural,qwen3,0,2,1,3,15.27,69,Wrong title. Reference says 4th highest is 'Улсын арслан' (State Lion) requiring 1 win at National Naadam. Model says 'Шагд' (a lower provincial title). Fluent Mongolian but factually incorrect.
50,mongolian_cultural,aya_expanse,0,0,0,0,15.86,140,Completely garbled Mongolian text with repetitive nonsense phrases. Does not answer the question about the 4th highest wrestling rank (Улсын арслан) or its requirement (1 win at National Naadam). Pipeline failure producing unreadable output.
